{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f863a6-430a-447c-8bbd-80c8babadf0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37316f8-2de7-40b4-bfec-7b2937788db4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpsc_case_number</th>\n",
       "      <th>narrative</th>\n",
       "      <th>primary_mechanism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100145411</td>\n",
       "      <td>67 yof pt fell on the floor playing pickle bal...</td>\n",
       "      <td>Falls, trips, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100417928</td>\n",
       "      <td>63yof playing pickleball in the hot sun and pa...</td>\n",
       "      <td>Heat stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100417973</td>\n",
       "      <td>66yom strained lower leg playing pickle ball</td>\n",
       "      <td>Other mechanism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100417997</td>\n",
       "      <td>60yof pt playing pickle ball and fell sustaine...</td>\n",
       "      <td>Falls, trips, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100454409</td>\n",
       "      <td>70 yom pt injured knee while playing pickle ba...</td>\n",
       "      <td>Other mechanism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>200101825</td>\n",
       "      <td>68 yof tripped and fell while playing tennis. ...</td>\n",
       "      <td>Falls, trips, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>200102934</td>\n",
       "      <td>76yof was hit in the eye with a tennis ball dx...</td>\n",
       "      <td>Hit with various obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>200110467</td>\n",
       "      <td>61yof was playing tennis when she developed pa...</td>\n",
       "      <td>Undetermined/unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>200124689</td>\n",
       "      <td>70yof fell while playing tennis dx: strained u...</td>\n",
       "      <td>Falls, trips, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>200301553</td>\n",
       "      <td>76yom.playing tennis slipped.fell down.dx.lac....</td>\n",
       "      <td>Falls, trips, etc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1991 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cpsc_case_number                                          narrative  \\\n",
       "0            100145411  67 yof pt fell on the floor playing pickle bal...   \n",
       "1            100417928  63yof playing pickleball in the hot sun and pa...   \n",
       "2            100417973       66yom strained lower leg playing pickle ball   \n",
       "3            100417997  60yof pt playing pickle ball and fell sustaine...   \n",
       "4            100454409  70 yom pt injured knee while playing pickle ba...   \n",
       "...                ...                                                ...   \n",
       "1986         200101825  68 yof tripped and fell while playing tennis. ...   \n",
       "1987         200102934  76yof was hit in the eye with a tennis ball dx...   \n",
       "1988         200110467  61yof was playing tennis when she developed pa...   \n",
       "1989         200124689  70yof fell while playing tennis dx: strained u...   \n",
       "1990         200301553  76yom.playing tennis slipped.fell down.dx.lac....   \n",
       "\n",
       "         primary_mechanism  \n",
       "0       Falls, trips, etc.  \n",
       "1              Heat stroke  \n",
       "2          Other mechanism  \n",
       "3       Falls, trips, etc.  \n",
       "4          Other mechanism  \n",
       "...                    ...  \n",
       "1986    Falls, trips, etc.  \n",
       "1987  Hit with various obj  \n",
       "1988  Undetermined/unknown  \n",
       "1989    Falls, trips, etc.  \n",
       "1990    Falls, trips, etc.  \n",
       "\n",
       "[1991 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = '../data_to_model/keras_data/model_df_full_narrative.csv'\n",
    "train_df = pd.read_csv(train_path)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe842aa9-0933-4e49-aeef-83849831c8bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Falls, trips, etc.' 'Heat stroke' 'Other mechanism' 'Falls, trips, etc.'\n",
      " 'Other mechanism' 'Falls, trips, etc.' 'Falls, trips, etc.'\n",
      " 'Other mechanism' 'Other mechanism' 'Falls, trips, etc.'\n",
      " 'Hit with various obj' 'Falls, trips, etc.' 'Falls, trips, etc.'\n",
      " 'cardio/sync' 'Falls, trips, etc.' 'Other mechanism' 'Other mechanism'\n",
      " 'Other mechanism' 'Other mechanism' 'Falls, trips, etc.'\n",
      " 'Falls, trips, etc.' 'Hit with various obj' 'Other mechanism'\n",
      " 'Multi-sport' 'Falls, trips, etc.' 'Other mechanism' 'Falls, trips, etc.'\n",
      " 'Falls, trips, etc.' 'Falls, trips, etc.' 'Falls, trips, etc.']\n",
      "['Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other'\n",
      " 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other' 'Other'\n",
      " 'Other' 'Other' 'Other' 'Other' 'Other' 'Multi-sport' 'Other' 'Other'\n",
      " 'Other' 'Other' 'Other' 'Other']\n"
     ]
    }
   ],
   "source": [
    "text_np = np.array(train_df['narrative'])\n",
    "train_labels_np = np.array(train_df['primary_mechanism'])\n",
    "train_labels_np_bin = np.where(train_labels_np == 'Multi-sport', 'Multi-sport', 'Other')\n",
    "print(train_labels_np[0:30])\n",
    "print(train_labels_np_bin[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9c24b9-8bd5-49c8-a559-a28409bc5c42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#l_list = []\n",
    "#for txt in text_np:\n",
    "#    l_list.append( len(txt) )\n",
    "    \n",
    "#l_list[0:10]\n",
    "\n",
    "#max(l_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f6eef2f-32b1-4810-a477-40fa9fc91a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxlen = 207\n",
    "training_samples = 1491\n",
    "validation_samples = 500\n",
    "max_words = 100000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(text_np)\n",
    "sequences = tokenizer.texts_to_sequences(text_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df633e05-a798-4e41-bf87-d622c22f251c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1857 unique tokens.\n",
      "Shape of data tensor: (1991, 207)\n",
      "Shape of label tensor: (1991,)\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', train_labels_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e127fa0-3dca-4a02-8605-0f6dff47d340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "train_labels_np = train_labels_np[indices]\n",
    "x_train = data[:training_samples]\n",
    "y_train = train_labels_np[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = train_labels_np[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df544f1-1e1b-47c4-ba7d-736362f614c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_integer_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_integer_encoded = label_encoder.fit_transform(y_val)\n",
    "\n",
    "#y_train_integer_encoded\n",
    "#y_train_integer_encoded\n",
    "y_train_one_hot = to_categorical(y_train_integer_encoded, num_classes=7)\n",
    "y_val_one_hot = to_categorical(y_val_integer_encoded, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13659797-747c-4446-8422-2ce9de69ae48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 207, 8)            800000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1656)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 11599     \n",
      "=================================================================\n",
      "Total params: 811,599\n",
      "Trainable params: 811,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 8, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "303dc81f-656b-483c-ac7d-8ee93567778d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "47/47 [==============================] - 1s 21ms/step - loss: 0.3382 - accuracy: 0.4755 - val_loss: 0.3182 - val_accuracy: 0.4840\n",
      "Epoch 2/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3172 - accuracy: 0.4842 - val_loss: 0.3019 - val_accuracy: 0.4840\n",
      "Epoch 3/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.2963 - accuracy: 0.5017 - val_loss: 0.2800 - val_accuracy: 0.5040\n",
      "Epoch 4/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.2716 - accuracy: 0.5473 - val_loss: 0.2584 - val_accuracy: 0.5480\n",
      "Epoch 5/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.2473 - accuracy: 0.6117 - val_loss: 0.2370 - val_accuracy: 0.6840\n",
      "Epoch 6/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2259 - accuracy: 0.6720 - val_loss: 0.2181 - val_accuracy: 0.7100\n",
      "Epoch 7/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2075 - accuracy: 0.7009 - val_loss: 0.2016 - val_accuracy: 0.7080\n",
      "Epoch 8/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.1921 - accuracy: 0.7264 - val_loss: 0.1874 - val_accuracy: 0.7460\n",
      "Epoch 9/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.1787 - accuracy: 0.7485 - val_loss: 0.1800 - val_accuracy: 0.7460\n",
      "Epoch 10/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.1669 - accuracy: 0.7592 - val_loss: 0.1720 - val_accuracy: 0.7580\n",
      "Epoch 11/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.1563 - accuracy: 0.7834 - val_loss: 0.1618 - val_accuracy: 0.7800\n",
      "Epoch 12/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.1470 - accuracy: 0.7988 - val_loss: 0.1551 - val_accuracy: 0.7920\n",
      "Epoch 13/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.1383 - accuracy: 0.8122 - val_loss: 0.1513 - val_accuracy: 0.7960\n",
      "Epoch 14/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.1298 - accuracy: 0.8343 - val_loss: 0.1469 - val_accuracy: 0.8100\n",
      "Epoch 15/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.1224 - accuracy: 0.8457 - val_loss: 0.1408 - val_accuracy: 0.8240\n",
      "Epoch 16/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.1152 - accuracy: 0.8585 - val_loss: 0.1360 - val_accuracy: 0.8280\n",
      "Epoch 17/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.1087 - accuracy: 0.8732 - val_loss: 0.1340 - val_accuracy: 0.8300\n",
      "Epoch 18/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.1024 - accuracy: 0.8753 - val_loss: 0.1304 - val_accuracy: 0.8300\n",
      "Epoch 19/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0964 - accuracy: 0.8840 - val_loss: 0.1295 - val_accuracy: 0.8180\n",
      "Epoch 20/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0910 - accuracy: 0.9001 - val_loss: 0.1230 - val_accuracy: 0.8420\n",
      "Epoch 21/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0862 - accuracy: 0.8974 - val_loss: 0.1212 - val_accuracy: 0.8360\n",
      "Epoch 22/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0814 - accuracy: 0.9115 - val_loss: 0.1207 - val_accuracy: 0.8320\n",
      "Epoch 23/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0769 - accuracy: 0.9168 - val_loss: 0.1179 - val_accuracy: 0.8280\n",
      "Epoch 24/80\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0729 - accuracy: 0.9229 - val_loss: 0.1163 - val_accuracy: 0.8320\n",
      "Epoch 25/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0687 - accuracy: 0.9276 - val_loss: 0.1157 - val_accuracy: 0.8300\n",
      "Epoch 26/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0649 - accuracy: 0.9302 - val_loss: 0.1138 - val_accuracy: 0.8300\n",
      "Epoch 27/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0610 - accuracy: 0.9376 - val_loss: 0.1124 - val_accuracy: 0.8300\n",
      "Epoch 28/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0577 - accuracy: 0.9416 - val_loss: 0.1128 - val_accuracy: 0.8300\n",
      "Epoch 29/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0544 - accuracy: 0.9450 - val_loss: 0.1100 - val_accuracy: 0.8320\n",
      "Epoch 30/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0512 - accuracy: 0.9484 - val_loss: 0.1090 - val_accuracy: 0.8300\n",
      "Epoch 31/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0484 - accuracy: 0.9544 - val_loss: 0.1091 - val_accuracy: 0.8340\n",
      "Epoch 32/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0454 - accuracy: 0.9577 - val_loss: 0.1089 - val_accuracy: 0.8400\n",
      "Epoch 33/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0428 - accuracy: 0.9631 - val_loss: 0.1071 - val_accuracy: 0.8340\n",
      "Epoch 34/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0400 - accuracy: 0.9638 - val_loss: 0.1091 - val_accuracy: 0.8400\n",
      "Epoch 35/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0378 - accuracy: 0.9671 - val_loss: 0.1048 - val_accuracy: 0.8520\n",
      "Epoch 36/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0354 - accuracy: 0.9732 - val_loss: 0.1034 - val_accuracy: 0.8560\n",
      "Epoch 37/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0333 - accuracy: 0.9738 - val_loss: 0.1046 - val_accuracy: 0.8460\n",
      "Epoch 38/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0312 - accuracy: 0.9779 - val_loss: 0.1048 - val_accuracy: 0.8460\n",
      "Epoch 39/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0292 - accuracy: 0.9792 - val_loss: 0.1039 - val_accuracy: 0.8480\n",
      "Epoch 40/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0274 - accuracy: 0.9792 - val_loss: 0.1036 - val_accuracy: 0.8480\n",
      "Epoch 41/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0257 - accuracy: 0.9832 - val_loss: 0.1039 - val_accuracy: 0.8520\n",
      "Epoch 42/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0239 - accuracy: 0.9832 - val_loss: 0.1037 - val_accuracy: 0.8600\n",
      "Epoch 43/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0226 - accuracy: 0.9819 - val_loss: 0.1022 - val_accuracy: 0.8660\n",
      "Epoch 44/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0211 - accuracy: 0.9859 - val_loss: 0.1025 - val_accuracy: 0.8640\n",
      "Epoch 45/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0197 - accuracy: 0.9873 - val_loss: 0.1027 - val_accuracy: 0.8620\n",
      "Epoch 46/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0185 - accuracy: 0.9886 - val_loss: 0.1015 - val_accuracy: 0.8660\n",
      "Epoch 47/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0173 - accuracy: 0.9913 - val_loss: 0.1021 - val_accuracy: 0.8640\n",
      "Epoch 48/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0162 - accuracy: 0.9893 - val_loss: 0.1030 - val_accuracy: 0.8600\n",
      "Epoch 49/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0151 - accuracy: 0.9926 - val_loss: 0.1020 - val_accuracy: 0.8620\n",
      "Epoch 50/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0140 - accuracy: 0.9940 - val_loss: 0.1022 - val_accuracy: 0.8660\n",
      "Epoch 51/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0130 - accuracy: 0.9940 - val_loss: 0.1027 - val_accuracy: 0.8680\n",
      "Epoch 52/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0123 - accuracy: 0.9940 - val_loss: 0.1027 - val_accuracy: 0.8680\n",
      "Epoch 53/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.1019 - val_accuracy: 0.8680\n",
      "Epoch 54/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0105 - accuracy: 0.9953 - val_loss: 0.1032 - val_accuracy: 0.8660\n",
      "Epoch 55/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.1034 - val_accuracy: 0.8680\n",
      "Epoch 56/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.1051 - val_accuracy: 0.8680\n",
      "Epoch 57/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0085 - accuracy: 0.9966 - val_loss: 0.1034 - val_accuracy: 0.8720\n",
      "Epoch 58/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0078 - accuracy: 0.9966 - val_loss: 0.1034 - val_accuracy: 0.8660\n",
      "Epoch 59/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0073 - accuracy: 0.9966 - val_loss: 0.1042 - val_accuracy: 0.8700\n",
      "Epoch 60/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0067 - accuracy: 0.9973 - val_loss: 0.1060 - val_accuracy: 0.8680\n",
      "Epoch 61/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1071 - val_accuracy: 0.8680\n",
      "Epoch 62/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.1061 - val_accuracy: 0.8720\n",
      "Epoch 63/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.1059 - val_accuracy: 0.8720\n",
      "Epoch 64/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: 0.1062 - val_accuracy: 0.8720\n",
      "Epoch 65/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 0.1066 - val_accuracy: 0.8720\n",
      "Epoch 66/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0042 - accuracy: 0.9980 - val_loss: 0.1080 - val_accuracy: 0.8680\n",
      "Epoch 67/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0038 - accuracy: 0.9980 - val_loss: 0.1086 - val_accuracy: 0.8720\n",
      "Epoch 68/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0035 - accuracy: 0.9980 - val_loss: 0.1094 - val_accuracy: 0.8720\n",
      "Epoch 69/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0032 - accuracy: 0.9980 - val_loss: 0.1092 - val_accuracy: 0.8700\n",
      "Epoch 70/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: 0.1106 - val_accuracy: 0.8720\n",
      "Epoch 71/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9980 - val_loss: 0.1115 - val_accuracy: 0.8700\n",
      "Epoch 72/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 0.1122 - val_accuracy: 0.8720\n",
      "Epoch 73/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 0.1124 - val_accuracy: 0.8800\n",
      "Epoch 74/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 0.1133 - val_accuracy: 0.8720\n",
      "Epoch 75/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.1138 - val_accuracy: 0.8740\n",
      "Epoch 76/80\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.1155 - val_accuracy: 0.8720\n",
      "Epoch 77/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 0.1172 - val_accuracy: 0.8660\n",
      "Epoch 78/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 0.1159 - val_accuracy: 0.8780\n",
      "Epoch 79/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 0.1190 - val_accuracy: 0.8700\n",
      "Epoch 80/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0011 - accuracy: 0.9993 - val_loss: 0.1204 - val_accuracy: 0.8780\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train_one_hot,\n",
    "epochs=80,\n",
    "batch_size=32,\n",
    "validation_data=(x_val, y_val_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91d32b28-57cf-4497-9708-4531cc7885e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('../Model Objects/keras_outv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07bf2ef-cc32-4cbb-a4de-a4f1d1af825a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8b59762-1b60-43af-b3ea-51d91fc7507a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    my_dim = 8\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, my_dim, input_length=maxlen))\n",
    "    model.add(Flatten())\n",
    "#    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "653ed884-ce2a-4711-a343-d96a00fb2521",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "94/94 - 1s - loss: 1.5095 - accuracy: 0.4695 - val_loss: 1.3897 - val_accuracy: 0.4840\n",
      "Epoch 2/30\n",
      "94/94 - 1s - loss: 1.3636 - accuracy: 0.4930 - val_loss: 1.2377 - val_accuracy: 0.5360\n",
      "Epoch 3/30\n",
      "94/94 - 1s - loss: 1.1646 - accuracy: 0.5902 - val_loss: 1.0387 - val_accuracy: 0.6500\n",
      "Epoch 4/30\n",
      "94/94 - 1s - loss: 0.9838 - accuracy: 0.6975 - val_loss: 0.8879 - val_accuracy: 0.7300\n",
      "Epoch 5/30\n",
      "94/94 - 1s - loss: 0.8485 - accuracy: 0.7371 - val_loss: 0.7874 - val_accuracy: 0.7680\n",
      "Epoch 6/30\n",
      "94/94 - 1s - loss: 0.7422 - accuracy: 0.7713 - val_loss: 0.7097 - val_accuracy: 0.7960\n",
      "Epoch 7/30\n",
      "94/94 - 1s - loss: 0.6610 - accuracy: 0.7934 - val_loss: 0.6557 - val_accuracy: 0.8060\n",
      "Epoch 8/30\n",
      "94/94 - 1s - loss: 0.5923 - accuracy: 0.8216 - val_loss: 0.6050 - val_accuracy: 0.8280\n",
      "Epoch 9/30\n",
      "94/94 - 1s - loss: 0.5363 - accuracy: 0.8364 - val_loss: 0.5848 - val_accuracy: 0.8300\n",
      "Epoch 10/30\n",
      "94/94 - 1s - loss: 0.4876 - accuracy: 0.8571 - val_loss: 0.5466 - val_accuracy: 0.8380\n",
      "Epoch 11/30\n",
      "94/94 - 1s - loss: 0.4466 - accuracy: 0.8692 - val_loss: 0.5376 - val_accuracy: 0.8320\n",
      "Epoch 12/30\n",
      "94/94 - 1s - loss: 0.4109 - accuracy: 0.8846 - val_loss: 0.5111 - val_accuracy: 0.8360\n",
      "Epoch 13/30\n",
      "94/94 - 1s - loss: 0.3786 - accuracy: 0.8900 - val_loss: 0.5001 - val_accuracy: 0.8280\n",
      "Epoch 14/30\n",
      "94/94 - 1s - loss: 0.3485 - accuracy: 0.8987 - val_loss: 0.4773 - val_accuracy: 0.8320\n",
      "Epoch 15/30\n",
      "94/94 - 1s - loss: 0.3228 - accuracy: 0.9135 - val_loss: 0.4717 - val_accuracy: 0.8400\n",
      "Epoch 16/30\n",
      "94/94 - 1s - loss: 0.2981 - accuracy: 0.9229 - val_loss: 0.4580 - val_accuracy: 0.8380\n",
      "Epoch 17/30\n",
      "94/94 - 1s - loss: 0.2772 - accuracy: 0.9302 - val_loss: 0.4613 - val_accuracy: 0.8360\n",
      "Epoch 18/30\n",
      "94/94 - 1s - loss: 0.2571 - accuracy: 0.9329 - val_loss: 0.4568 - val_accuracy: 0.8400\n",
      "Epoch 19/30\n",
      "94/94 - 1s - loss: 0.2390 - accuracy: 0.9376 - val_loss: 0.4599 - val_accuracy: 0.8420\n",
      "Epoch 20/30\n",
      "94/94 - 1s - loss: 0.2215 - accuracy: 0.9437 - val_loss: 0.4406 - val_accuracy: 0.8480\n",
      "Epoch 21/30\n",
      "94/94 - 1s - loss: 0.2056 - accuracy: 0.9437 - val_loss: 0.4408 - val_accuracy: 0.8560\n",
      "Epoch 22/30\n",
      "94/94 - 1s - loss: 0.1911 - accuracy: 0.9497 - val_loss: 0.4453 - val_accuracy: 0.8440\n",
      "Epoch 23/30\n",
      "94/94 - 1s - loss: 0.1767 - accuracy: 0.9551 - val_loss: 0.4412 - val_accuracy: 0.8440\n",
      "Epoch 24/30\n",
      "94/94 - 1s - loss: 0.1647 - accuracy: 0.9571 - val_loss: 0.4421 - val_accuracy: 0.8440\n",
      "Epoch 25/30\n",
      "94/94 - 1s - loss: 0.1526 - accuracy: 0.9604 - val_loss: 0.4453 - val_accuracy: 0.8460\n",
      "Epoch 26/30\n",
      "94/94 - 1s - loss: 0.1416 - accuracy: 0.9651 - val_loss: 0.4355 - val_accuracy: 0.8600\n",
      "Epoch 27/30\n",
      "94/94 - 1s - loss: 0.1308 - accuracy: 0.9645 - val_loss: 0.4421 - val_accuracy: 0.8520\n",
      "Epoch 28/30\n",
      "94/94 - 1s - loss: 0.1199 - accuracy: 0.9712 - val_loss: 0.4341 - val_accuracy: 0.8600\n",
      "Epoch 29/30\n",
      "94/94 - 1s - loss: 0.1115 - accuracy: 0.9752 - val_loss: 0.4385 - val_accuracy: 0.8580\n",
      "Epoch 30/30\n",
      "94/94 - 1s - loss: 0.1037 - accuracy: 0.9765 - val_loss: 0.4441 - val_accuracy: 0.8520\n",
      "Epochs: 30, Batch size: 16, Validation accuracy: 0.8519999980926514\n",
      "Epoch 1/30\n",
      "47/47 - 1s - loss: 1.5380 - accuracy: 0.4675 - val_loss: 1.4325 - val_accuracy: 0.4840\n",
      "Epoch 2/30\n",
      "47/47 - 0s - loss: 1.4512 - accuracy: 0.4842 - val_loss: 1.3752 - val_accuracy: 0.4840\n",
      "Epoch 3/30\n",
      "47/47 - 0s - loss: 1.3710 - accuracy: 0.4970 - val_loss: 1.2874 - val_accuracy: 0.4940\n",
      "Epoch 4/30\n",
      "47/47 - 1s - loss: 1.2569 - accuracy: 0.5379 - val_loss: 1.1883 - val_accuracy: 0.5760\n",
      "Epoch 5/30\n",
      "47/47 - 0s - loss: 1.1398 - accuracy: 0.5835 - val_loss: 1.0643 - val_accuracy: 0.6120\n",
      "Epoch 6/30\n",
      "47/47 - 1s - loss: 1.0220 - accuracy: 0.6345 - val_loss: 0.9612 - val_accuracy: 0.7060\n",
      "Epoch 7/30\n",
      "47/47 - 0s - loss: 0.9150 - accuracy: 0.7015 - val_loss: 0.8821 - val_accuracy: 0.7400\n",
      "Epoch 8/30\n",
      "47/47 - 1s - loss: 0.8237 - accuracy: 0.7451 - val_loss: 0.8185 - val_accuracy: 0.7400\n",
      "Epoch 9/30\n",
      "47/47 - 0s - loss: 0.7469 - accuracy: 0.7673 - val_loss: 0.7602 - val_accuracy: 0.7880\n",
      "Epoch 10/30\n",
      "47/47 - 1s - loss: 0.6788 - accuracy: 0.7975 - val_loss: 0.7111 - val_accuracy: 0.7800\n",
      "Epoch 11/30\n",
      "47/47 - 1s - loss: 0.6198 - accuracy: 0.8182 - val_loss: 0.6659 - val_accuracy: 0.7960\n",
      "Epoch 12/30\n",
      "47/47 - 0s - loss: 0.5694 - accuracy: 0.8384 - val_loss: 0.6322 - val_accuracy: 0.8020\n",
      "Epoch 13/30\n",
      "47/47 - 0s - loss: 0.5228 - accuracy: 0.8538 - val_loss: 0.6005 - val_accuracy: 0.8120\n",
      "Epoch 14/30\n",
      "47/47 - 1s - loss: 0.4835 - accuracy: 0.8739 - val_loss: 0.5773 - val_accuracy: 0.8200\n",
      "Epoch 15/30\n",
      "47/47 - 1s - loss: 0.4461 - accuracy: 0.8779 - val_loss: 0.5453 - val_accuracy: 0.8340\n",
      "Epoch 16/30\n",
      "47/47 - 1s - loss: 0.4136 - accuracy: 0.8873 - val_loss: 0.5400 - val_accuracy: 0.8320\n",
      "Epoch 17/30\n",
      "47/47 - 0s - loss: 0.3860 - accuracy: 0.9001 - val_loss: 0.5171 - val_accuracy: 0.8440\n",
      "Epoch 18/30\n",
      "47/47 - 0s - loss: 0.3598 - accuracy: 0.9048 - val_loss: 0.5029 - val_accuracy: 0.8420\n",
      "Epoch 19/30\n",
      "47/47 - 0s - loss: 0.3348 - accuracy: 0.9095 - val_loss: 0.4938 - val_accuracy: 0.8360\n",
      "Epoch 20/30\n",
      "47/47 - 0s - loss: 0.3125 - accuracy: 0.9195 - val_loss: 0.4816 - val_accuracy: 0.8420\n",
      "Epoch 21/30\n",
      "47/47 - 0s - loss: 0.2933 - accuracy: 0.9242 - val_loss: 0.4741 - val_accuracy: 0.8460\n",
      "Epoch 22/30\n",
      "47/47 - 0s - loss: 0.2740 - accuracy: 0.9309 - val_loss: 0.4656 - val_accuracy: 0.8420\n",
      "Epoch 23/30\n",
      "47/47 - 0s - loss: 0.2569 - accuracy: 0.9370 - val_loss: 0.4573 - val_accuracy: 0.8440\n",
      "Epoch 24/30\n",
      "47/47 - 0s - loss: 0.2396 - accuracy: 0.9423 - val_loss: 0.4558 - val_accuracy: 0.8480\n",
      "Epoch 25/30\n",
      "47/47 - 0s - loss: 0.2247 - accuracy: 0.9403 - val_loss: 0.4484 - val_accuracy: 0.8360\n",
      "Epoch 26/30\n",
      "47/47 - 0s - loss: 0.2108 - accuracy: 0.9524 - val_loss: 0.4387 - val_accuracy: 0.8520\n",
      "Epoch 27/30\n",
      "47/47 - 0s - loss: 0.1976 - accuracy: 0.9544 - val_loss: 0.4279 - val_accuracy: 0.8600\n",
      "Epoch 28/30\n",
      "47/47 - 0s - loss: 0.1837 - accuracy: 0.9577 - val_loss: 0.4321 - val_accuracy: 0.8540\n",
      "Epoch 29/30\n",
      "47/47 - 0s - loss: 0.1732 - accuracy: 0.9618 - val_loss: 0.4279 - val_accuracy: 0.8600\n",
      "Epoch 30/30\n",
      "47/47 - 0s - loss: 0.1616 - accuracy: 0.9631 - val_loss: 0.4275 - val_accuracy: 0.8500\n",
      "Epochs: 30, Batch size: 32, Validation accuracy: 0.8500000238418579\n",
      "Epoch 1/30\n",
      "24/24 - 1s - loss: 1.5834 - accuracy: 0.4702 - val_loss: 1.4413 - val_accuracy: 0.4840\n",
      "Epoch 2/30\n",
      "24/24 - 0s - loss: 1.4728 - accuracy: 0.4842 - val_loss: 1.4200 - val_accuracy: 0.4840\n",
      "Epoch 3/30\n",
      "24/24 - 0s - loss: 1.4348 - accuracy: 0.4842 - val_loss: 1.3746 - val_accuracy: 0.4840\n",
      "Epoch 4/30\n",
      "24/24 - 0s - loss: 1.3835 - accuracy: 0.4856 - val_loss: 1.3242 - val_accuracy: 0.4840\n",
      "Epoch 5/30\n",
      "24/24 - 0s - loss: 1.3200 - accuracy: 0.5003 - val_loss: 1.2711 - val_accuracy: 0.5020\n",
      "Epoch 6/30\n",
      "24/24 - 0s - loss: 1.2474 - accuracy: 0.5292 - val_loss: 1.1967 - val_accuracy: 0.5440\n",
      "Epoch 7/30\n",
      "24/24 - 0s - loss: 1.1718 - accuracy: 0.5734 - val_loss: 1.1480 - val_accuracy: 0.6600\n",
      "Epoch 8/30\n",
      "24/24 - 0s - loss: 1.0972 - accuracy: 0.6251 - val_loss: 1.0809 - val_accuracy: 0.6840\n",
      "Epoch 9/30\n",
      "24/24 - 0s - loss: 1.0231 - accuracy: 0.6680 - val_loss: 0.9978 - val_accuracy: 0.6960\n",
      "Epoch 10/30\n",
      "24/24 - 0s - loss: 0.9541 - accuracy: 0.7042 - val_loss: 0.9523 - val_accuracy: 0.7020\n",
      "Epoch 11/30\n",
      "24/24 - 0s - loss: 0.8859 - accuracy: 0.7311 - val_loss: 0.8972 - val_accuracy: 0.7060\n",
      "Epoch 12/30\n",
      "24/24 - 0s - loss: 0.8281 - accuracy: 0.7451 - val_loss: 0.8549 - val_accuracy: 0.7260\n",
      "Epoch 13/30\n",
      "24/24 - 0s - loss: 0.7710 - accuracy: 0.7632 - val_loss: 0.8113 - val_accuracy: 0.7520\n",
      "Epoch 14/30\n",
      "24/24 - 0s - loss: 0.7196 - accuracy: 0.7867 - val_loss: 0.7813 - val_accuracy: 0.7620\n",
      "Epoch 15/30\n",
      "24/24 - 0s - loss: 0.6747 - accuracy: 0.8089 - val_loss: 0.7284 - val_accuracy: 0.7640\n",
      "Epoch 16/30\n",
      "24/24 - 0s - loss: 0.6321 - accuracy: 0.8169 - val_loss: 0.7055 - val_accuracy: 0.7680\n",
      "Epoch 17/30\n",
      "24/24 - 0s - loss: 0.5911 - accuracy: 0.8343 - val_loss: 0.6823 - val_accuracy: 0.7800\n",
      "Epoch 18/30\n",
      "24/24 - 0s - loss: 0.5553 - accuracy: 0.8484 - val_loss: 0.6490 - val_accuracy: 0.7920\n",
      "Epoch 19/30\n",
      "24/24 - 0s - loss: 0.5203 - accuracy: 0.8538 - val_loss: 0.6318 - val_accuracy: 0.7920\n",
      "Epoch 20/30\n",
      "24/24 - 0s - loss: 0.4902 - accuracy: 0.8605 - val_loss: 0.6134 - val_accuracy: 0.8020\n",
      "Epoch 21/30\n",
      "24/24 - 0s - loss: 0.4606 - accuracy: 0.8759 - val_loss: 0.5823 - val_accuracy: 0.8180\n",
      "Epoch 22/30\n",
      "24/24 - 0s - loss: 0.4352 - accuracy: 0.8786 - val_loss: 0.5754 - val_accuracy: 0.8080\n",
      "Epoch 23/30\n",
      "24/24 - 0s - loss: 0.4083 - accuracy: 0.8907 - val_loss: 0.5579 - val_accuracy: 0.8320\n",
      "Epoch 24/30\n",
      "24/24 - 0s - loss: 0.3849 - accuracy: 0.8987 - val_loss: 0.5518 - val_accuracy: 0.8200\n",
      "Epoch 25/30\n",
      "24/24 - 0s - loss: 0.3627 - accuracy: 0.9068 - val_loss: 0.5232 - val_accuracy: 0.8420\n",
      "Epoch 26/30\n",
      "24/24 - 0s - loss: 0.3436 - accuracy: 0.9088 - val_loss: 0.5272 - val_accuracy: 0.8240\n",
      "Epoch 27/30\n",
      "24/24 - 0s - loss: 0.3241 - accuracy: 0.9215 - val_loss: 0.5192 - val_accuracy: 0.8280\n",
      "Epoch 28/30\n",
      "24/24 - 0s - loss: 0.3082 - accuracy: 0.9215 - val_loss: 0.5044 - val_accuracy: 0.8300\n",
      "Epoch 29/30\n",
      "24/24 - 0s - loss: 0.2903 - accuracy: 0.9235 - val_loss: 0.4957 - val_accuracy: 0.8260\n",
      "Epoch 30/30\n",
      "24/24 - 0s - loss: 0.2759 - accuracy: 0.9309 - val_loss: 0.4939 - val_accuracy: 0.8260\n",
      "Epochs: 30, Batch size: 64, Validation accuracy: 0.8259999752044678\n",
      "Epoch 1/60\n",
      "94/94 - 1s - loss: 1.5095 - accuracy: 0.4748 - val_loss: 1.4026 - val_accuracy: 0.4840\n",
      "Epoch 2/60\n",
      "94/94 - 1s - loss: 1.3787 - accuracy: 0.4950 - val_loss: 1.2734 - val_accuracy: 0.4960\n",
      "Epoch 3/60\n",
      "94/94 - 1s - loss: 1.2020 - accuracy: 0.5775 - val_loss: 1.0878 - val_accuracy: 0.6920\n",
      "Epoch 4/60\n",
      "94/94 - 1s - loss: 1.0336 - accuracy: 0.6841 - val_loss: 0.9473 - val_accuracy: 0.7060\n",
      "Epoch 5/60\n",
      "94/94 - 1s - loss: 0.8951 - accuracy: 0.7317 - val_loss: 0.8508 - val_accuracy: 0.7620\n",
      "Epoch 6/60\n",
      "94/94 - 1s - loss: 0.7863 - accuracy: 0.7532 - val_loss: 0.7689 - val_accuracy: 0.7660\n",
      "Epoch 7/60\n",
      "94/94 - 1s - loss: 0.7017 - accuracy: 0.7726 - val_loss: 0.7080 - val_accuracy: 0.7800\n",
      "Epoch 8/60\n",
      "94/94 - 1s - loss: 0.6286 - accuracy: 0.7954 - val_loss: 0.6629 - val_accuracy: 0.8020\n",
      "Epoch 9/60\n",
      "94/94 - 1s - loss: 0.5692 - accuracy: 0.8243 - val_loss: 0.6266 - val_accuracy: 0.7940\n",
      "Epoch 10/60\n",
      "94/94 - 1s - loss: 0.5167 - accuracy: 0.8364 - val_loss: 0.5960 - val_accuracy: 0.8140\n",
      "Epoch 11/60\n",
      "94/94 - 1s - loss: 0.4700 - accuracy: 0.8565 - val_loss: 0.5820 - val_accuracy: 0.8260\n",
      "Epoch 12/60\n",
      "94/94 - 1s - loss: 0.4348 - accuracy: 0.8753 - val_loss: 0.5496 - val_accuracy: 0.8320\n",
      "Epoch 13/60\n",
      "94/94 - 1s - loss: 0.3986 - accuracy: 0.8840 - val_loss: 0.5450 - val_accuracy: 0.8340\n",
      "Epoch 14/60\n",
      "94/94 - 1s - loss: 0.3701 - accuracy: 0.8913 - val_loss: 0.5245 - val_accuracy: 0.8420\n",
      "Epoch 15/60\n",
      "94/94 - 1s - loss: 0.3414 - accuracy: 0.9121 - val_loss: 0.5196 - val_accuracy: 0.8360\n",
      "Epoch 16/60\n",
      "94/94 - 1s - loss: 0.3173 - accuracy: 0.9142 - val_loss: 0.5010 - val_accuracy: 0.8440\n",
      "Epoch 17/60\n",
      "94/94 - 1s - loss: 0.2954 - accuracy: 0.9209 - val_loss: 0.5028 - val_accuracy: 0.8360\n",
      "Epoch 18/60\n",
      "94/94 - 1s - loss: 0.2746 - accuracy: 0.9262 - val_loss: 0.4971 - val_accuracy: 0.8260\n",
      "Epoch 19/60\n",
      "94/94 - 1s - loss: 0.2543 - accuracy: 0.9336 - val_loss: 0.4966 - val_accuracy: 0.8320\n",
      "Epoch 20/60\n",
      "94/94 - 1s - loss: 0.2374 - accuracy: 0.9403 - val_loss: 0.4795 - val_accuracy: 0.8400\n",
      "Epoch 21/60\n",
      "94/94 - 1s - loss: 0.2209 - accuracy: 0.9423 - val_loss: 0.4821 - val_accuracy: 0.8360\n",
      "Epoch 22/60\n",
      "94/94 - 1s - loss: 0.2060 - accuracy: 0.9484 - val_loss: 0.4742 - val_accuracy: 0.8320\n",
      "Epoch 23/60\n",
      "94/94 - 1s - loss: 0.1907 - accuracy: 0.9531 - val_loss: 0.4817 - val_accuracy: 0.8320\n",
      "Epoch 24/60\n",
      "94/94 - 1s - loss: 0.1765 - accuracy: 0.9591 - val_loss: 0.4794 - val_accuracy: 0.8320\n",
      "Epoch 25/60\n",
      "94/94 - 1s - loss: 0.1654 - accuracy: 0.9604 - val_loss: 0.4734 - val_accuracy: 0.8360\n",
      "Epoch 26/60\n",
      "94/94 - 1s - loss: 0.1522 - accuracy: 0.9651 - val_loss: 0.4707 - val_accuracy: 0.8440\n",
      "Epoch 27/60\n",
      "94/94 - 1s - loss: 0.1424 - accuracy: 0.9671 - val_loss: 0.4670 - val_accuracy: 0.8440\n",
      "Epoch 28/60\n",
      "94/94 - 1s - loss: 0.1321 - accuracy: 0.9698 - val_loss: 0.4727 - val_accuracy: 0.8440\n",
      "Epoch 29/60\n",
      "94/94 - 1s - loss: 0.1227 - accuracy: 0.9732 - val_loss: 0.4666 - val_accuracy: 0.8480\n",
      "Epoch 30/60\n",
      "94/94 - 1s - loss: 0.1138 - accuracy: 0.9732 - val_loss: 0.4728 - val_accuracy: 0.8500\n",
      "Epoch 31/60\n",
      "94/94 - 1s - loss: 0.1053 - accuracy: 0.9745 - val_loss: 0.4726 - val_accuracy: 0.8440\n",
      "Epoch 32/60\n",
      "94/94 - 1s - loss: 0.0981 - accuracy: 0.9779 - val_loss: 0.4736 - val_accuracy: 0.8500\n",
      "Epoch 33/60\n",
      "94/94 - 1s - loss: 0.0907 - accuracy: 0.9805 - val_loss: 0.4722 - val_accuracy: 0.8520\n",
      "Epoch 34/60\n",
      "94/94 - 1s - loss: 0.0830 - accuracy: 0.9805 - val_loss: 0.4733 - val_accuracy: 0.8540\n",
      "Epoch 35/60\n",
      "94/94 - 1s - loss: 0.0775 - accuracy: 0.9839 - val_loss: 0.4772 - val_accuracy: 0.8500\n",
      "Epoch 36/60\n",
      "94/94 - 1s - loss: 0.0715 - accuracy: 0.9832 - val_loss: 0.4856 - val_accuracy: 0.8460\n",
      "Epoch 37/60\n",
      "94/94 - 1s - loss: 0.0653 - accuracy: 0.9859 - val_loss: 0.4774 - val_accuracy: 0.8560\n",
      "Epoch 38/60\n",
      "94/94 - 1s - loss: 0.0609 - accuracy: 0.9873 - val_loss: 0.4755 - val_accuracy: 0.8520\n",
      "Epoch 39/60\n",
      "94/94 - 1s - loss: 0.0552 - accuracy: 0.9906 - val_loss: 0.4830 - val_accuracy: 0.8540\n",
      "Epoch 40/60\n",
      "94/94 - 1s - loss: 0.0516 - accuracy: 0.9906 - val_loss: 0.4864 - val_accuracy: 0.8440\n",
      "Epoch 41/60\n",
      "94/94 - 1s - loss: 0.0470 - accuracy: 0.9933 - val_loss: 0.4916 - val_accuracy: 0.8460\n",
      "Epoch 42/60\n",
      "94/94 - 1s - loss: 0.0429 - accuracy: 0.9926 - val_loss: 0.4960 - val_accuracy: 0.8540\n",
      "Epoch 43/60\n",
      "94/94 - 1s - loss: 0.0401 - accuracy: 0.9940 - val_loss: 0.4968 - val_accuracy: 0.8600\n",
      "Epoch 44/60\n",
      "94/94 - 1s - loss: 0.0370 - accuracy: 0.9926 - val_loss: 0.4984 - val_accuracy: 0.8540\n",
      "Epoch 45/60\n",
      "94/94 - 1s - loss: 0.0333 - accuracy: 0.9946 - val_loss: 0.5010 - val_accuracy: 0.8500\n",
      "Epoch 46/60\n",
      "94/94 - 1s - loss: 0.0303 - accuracy: 0.9946 - val_loss: 0.5032 - val_accuracy: 0.8560\n",
      "Epoch 47/60\n",
      "94/94 - 1s - loss: 0.0282 - accuracy: 0.9960 - val_loss: 0.5121 - val_accuracy: 0.8560\n",
      "Epoch 48/60\n",
      "94/94 - 1s - loss: 0.0257 - accuracy: 0.9973 - val_loss: 0.5168 - val_accuracy: 0.8560\n",
      "Epoch 49/60\n",
      "94/94 - 1s - loss: 0.0238 - accuracy: 0.9973 - val_loss: 0.5195 - val_accuracy: 0.8540\n",
      "Epoch 50/60\n",
      "94/94 - 1s - loss: 0.0213 - accuracy: 0.9980 - val_loss: 0.5227 - val_accuracy: 0.8540\n",
      "Epoch 51/60\n",
      "94/94 - 1s - loss: 0.0193 - accuracy: 0.9980 - val_loss: 0.5245 - val_accuracy: 0.8540\n",
      "Epoch 52/60\n",
      "94/94 - 1s - loss: 0.0178 - accuracy: 0.9980 - val_loss: 0.5341 - val_accuracy: 0.8540\n",
      "Epoch 53/60\n",
      "94/94 - 1s - loss: 0.0163 - accuracy: 0.9987 - val_loss: 0.5322 - val_accuracy: 0.8540\n",
      "Epoch 54/60\n",
      "94/94 - 1s - loss: 0.0147 - accuracy: 0.9980 - val_loss: 0.5429 - val_accuracy: 0.8580\n",
      "Epoch 55/60\n",
      "94/94 - 1s - loss: 0.0132 - accuracy: 0.9987 - val_loss: 0.5489 - val_accuracy: 0.8560\n",
      "Epoch 56/60\n",
      "94/94 - 1s - loss: 0.0120 - accuracy: 0.9987 - val_loss: 0.5510 - val_accuracy: 0.8580\n",
      "Epoch 57/60\n",
      "94/94 - 1s - loss: 0.0108 - accuracy: 0.9993 - val_loss: 0.5593 - val_accuracy: 0.8540\n",
      "Epoch 58/60\n",
      "94/94 - 1s - loss: 0.0097 - accuracy: 0.9993 - val_loss: 0.5679 - val_accuracy: 0.8560\n",
      "Epoch 59/60\n",
      "94/94 - 1s - loss: 0.0088 - accuracy: 0.9993 - val_loss: 0.5732 - val_accuracy: 0.8560\n",
      "Epoch 60/60\n",
      "94/94 - 1s - loss: 0.0079 - accuracy: 0.9993 - val_loss: 0.5849 - val_accuracy: 0.8560\n",
      "Epochs: 60, Batch size: 16, Validation accuracy: 0.8560000061988831\n",
      "Epoch 1/60\n",
      "47/47 - 1s - loss: 1.5297 - accuracy: 0.4715 - val_loss: 1.4358 - val_accuracy: 0.4840\n",
      "Epoch 2/60\n",
      "47/47 - 0s - loss: 1.4497 - accuracy: 0.4842 - val_loss: 1.3749 - val_accuracy: 0.4840\n",
      "Epoch 3/60\n",
      "47/47 - 0s - loss: 1.3637 - accuracy: 0.4983 - val_loss: 1.2961 - val_accuracy: 0.4980\n",
      "Epoch 4/60\n",
      "47/47 - 0s - loss: 1.2527 - accuracy: 0.5372 - val_loss: 1.1586 - val_accuracy: 0.5640\n",
      "Epoch 5/60\n",
      "47/47 - 0s - loss: 1.1304 - accuracy: 0.5882 - val_loss: 1.0539 - val_accuracy: 0.6500\n",
      "Epoch 6/60\n",
      "47/47 - 0s - loss: 1.0192 - accuracy: 0.6573 - val_loss: 0.9728 - val_accuracy: 0.7120\n",
      "Epoch 7/60\n",
      "47/47 - 0s - loss: 0.9223 - accuracy: 0.7062 - val_loss: 0.8853 - val_accuracy: 0.7040\n",
      "Epoch 8/60\n",
      "47/47 - 0s - loss: 0.8368 - accuracy: 0.7344 - val_loss: 0.8132 - val_accuracy: 0.7360\n",
      "Epoch 9/60\n",
      "47/47 - 0s - loss: 0.7664 - accuracy: 0.7626 - val_loss: 0.7636 - val_accuracy: 0.7460\n",
      "Epoch 10/60\n",
      "47/47 - 0s - loss: 0.7046 - accuracy: 0.7867 - val_loss: 0.7250 - val_accuracy: 0.7840\n",
      "Epoch 11/60\n",
      "47/47 - 0s - loss: 0.6494 - accuracy: 0.8035 - val_loss: 0.6963 - val_accuracy: 0.7900\n",
      "Epoch 12/60\n",
      "47/47 - 0s - loss: 0.6032 - accuracy: 0.8263 - val_loss: 0.6569 - val_accuracy: 0.7940\n",
      "Epoch 13/60\n",
      "47/47 - 0s - loss: 0.5623 - accuracy: 0.8330 - val_loss: 0.6267 - val_accuracy: 0.8180\n",
      "Epoch 14/60\n",
      "47/47 - 0s - loss: 0.5248 - accuracy: 0.8504 - val_loss: 0.6135 - val_accuracy: 0.8120\n",
      "Epoch 15/60\n",
      "47/47 - 0s - loss: 0.4910 - accuracy: 0.8545 - val_loss: 0.6042 - val_accuracy: 0.8000\n",
      "Epoch 16/60\n",
      "47/47 - 0s - loss: 0.4605 - accuracy: 0.8679 - val_loss: 0.5773 - val_accuracy: 0.8260\n",
      "Epoch 17/60\n",
      "47/47 - 0s - loss: 0.4331 - accuracy: 0.8853 - val_loss: 0.5526 - val_accuracy: 0.8280\n",
      "Epoch 18/60\n",
      "47/47 - 0s - loss: 0.4071 - accuracy: 0.8900 - val_loss: 0.5317 - val_accuracy: 0.8320\n",
      "Epoch 19/60\n",
      "47/47 - 0s - loss: 0.3836 - accuracy: 0.8981 - val_loss: 0.5390 - val_accuracy: 0.8200\n",
      "Epoch 20/60\n",
      "47/47 - 0s - loss: 0.3604 - accuracy: 0.9021 - val_loss: 0.5255 - val_accuracy: 0.8340\n",
      "Epoch 21/60\n",
      "47/47 - 0s - loss: 0.3405 - accuracy: 0.9061 - val_loss: 0.5098 - val_accuracy: 0.8380\n",
      "Epoch 22/60\n",
      "47/47 - 0s - loss: 0.3210 - accuracy: 0.9168 - val_loss: 0.4952 - val_accuracy: 0.8460\n",
      "Epoch 23/60\n",
      "47/47 - 0s - loss: 0.3033 - accuracy: 0.9182 - val_loss: 0.4935 - val_accuracy: 0.8400\n",
      "Epoch 24/60\n",
      "47/47 - 0s - loss: 0.2850 - accuracy: 0.9249 - val_loss: 0.4899 - val_accuracy: 0.8380\n",
      "Epoch 25/60\n",
      "47/47 - 1s - loss: 0.2691 - accuracy: 0.9316 - val_loss: 0.4852 - val_accuracy: 0.8360\n",
      "Epoch 26/60\n",
      "47/47 - 0s - loss: 0.2525 - accuracy: 0.9396 - val_loss: 0.4719 - val_accuracy: 0.8420\n",
      "Epoch 27/60\n",
      "47/47 - 0s - loss: 0.2383 - accuracy: 0.9437 - val_loss: 0.4634 - val_accuracy: 0.8480\n",
      "Epoch 28/60\n",
      "47/47 - 0s - loss: 0.2238 - accuracy: 0.9437 - val_loss: 0.4630 - val_accuracy: 0.8520\n",
      "Epoch 29/60\n",
      "47/47 - 0s - loss: 0.2105 - accuracy: 0.9497 - val_loss: 0.4595 - val_accuracy: 0.8520\n",
      "Epoch 30/60\n",
      "47/47 - 0s - loss: 0.1982 - accuracy: 0.9564 - val_loss: 0.4572 - val_accuracy: 0.8500\n",
      "Epoch 31/60\n",
      "47/47 - 0s - loss: 0.1857 - accuracy: 0.9577 - val_loss: 0.4480 - val_accuracy: 0.8600\n",
      "Epoch 32/60\n",
      "47/47 - 0s - loss: 0.1739 - accuracy: 0.9591 - val_loss: 0.4530 - val_accuracy: 0.8580\n",
      "Epoch 33/60\n",
      "47/47 - 0s - loss: 0.1636 - accuracy: 0.9638 - val_loss: 0.4442 - val_accuracy: 0.8620\n",
      "Epoch 34/60\n",
      "47/47 - 0s - loss: 0.1533 - accuracy: 0.9665 - val_loss: 0.4470 - val_accuracy: 0.8440\n",
      "Epoch 35/60\n",
      "47/47 - 0s - loss: 0.1424 - accuracy: 0.9725 - val_loss: 0.4413 - val_accuracy: 0.8580\n",
      "Epoch 36/60\n",
      "47/47 - 0s - loss: 0.1337 - accuracy: 0.9752 - val_loss: 0.4523 - val_accuracy: 0.8380\n",
      "Epoch 37/60\n",
      "47/47 - 0s - loss: 0.1251 - accuracy: 0.9785 - val_loss: 0.4425 - val_accuracy: 0.8540\n",
      "Epoch 38/60\n",
      "47/47 - 0s - loss: 0.1166 - accuracy: 0.9805 - val_loss: 0.4367 - val_accuracy: 0.8640\n",
      "Epoch 39/60\n",
      "47/47 - 0s - loss: 0.1094 - accuracy: 0.9805 - val_loss: 0.4349 - val_accuracy: 0.8520\n",
      "Epoch 40/60\n",
      "47/47 - 0s - loss: 0.1014 - accuracy: 0.9839 - val_loss: 0.4279 - val_accuracy: 0.8580\n",
      "Epoch 41/60\n",
      "47/47 - 0s - loss: 0.0941 - accuracy: 0.9846 - val_loss: 0.4395 - val_accuracy: 0.8640\n",
      "Epoch 42/60\n",
      "47/47 - 0s - loss: 0.0881 - accuracy: 0.9852 - val_loss: 0.4294 - val_accuracy: 0.8620\n",
      "Epoch 43/60\n",
      "47/47 - 0s - loss: 0.0820 - accuracy: 0.9879 - val_loss: 0.4337 - val_accuracy: 0.8580\n",
      "Epoch 44/60\n",
      "47/47 - 0s - loss: 0.0759 - accuracy: 0.9899 - val_loss: 0.4382 - val_accuracy: 0.8560\n",
      "Epoch 45/60\n",
      "47/47 - 0s - loss: 0.0714 - accuracy: 0.9886 - val_loss: 0.4307 - val_accuracy: 0.8580\n",
      "Epoch 46/60\n",
      "47/47 - 0s - loss: 0.0655 - accuracy: 0.9926 - val_loss: 0.4374 - val_accuracy: 0.8620\n",
      "Epoch 47/60\n",
      "47/47 - 1s - loss: 0.0611 - accuracy: 0.9913 - val_loss: 0.4370 - val_accuracy: 0.8660\n",
      "Epoch 48/60\n",
      "47/47 - 0s - loss: 0.0562 - accuracy: 0.9940 - val_loss: 0.4332 - val_accuracy: 0.8660\n",
      "Epoch 49/60\n",
      "47/47 - 1s - loss: 0.0525 - accuracy: 0.9933 - val_loss: 0.4398 - val_accuracy: 0.8620\n",
      "Epoch 50/60\n",
      "47/47 - 0s - loss: 0.0485 - accuracy: 0.9940 - val_loss: 0.4356 - val_accuracy: 0.8600\n",
      "Epoch 51/60\n",
      "47/47 - 0s - loss: 0.0447 - accuracy: 0.9946 - val_loss: 0.4406 - val_accuracy: 0.8540\n",
      "Epoch 52/60\n",
      "47/47 - 0s - loss: 0.0413 - accuracy: 0.9966 - val_loss: 0.4490 - val_accuracy: 0.8560\n",
      "Epoch 53/60\n",
      "47/47 - 0s - loss: 0.0382 - accuracy: 0.9966 - val_loss: 0.4428 - val_accuracy: 0.8580\n",
      "Epoch 54/60\n",
      "47/47 - 0s - loss: 0.0347 - accuracy: 0.9966 - val_loss: 0.4505 - val_accuracy: 0.8680\n",
      "Epoch 55/60\n",
      "47/47 - 0s - loss: 0.0322 - accuracy: 0.9980 - val_loss: 0.4551 - val_accuracy: 0.8520\n",
      "Epoch 56/60\n",
      "47/47 - 0s - loss: 0.0298 - accuracy: 0.9987 - val_loss: 0.4602 - val_accuracy: 0.8520\n",
      "Epoch 57/60\n",
      "47/47 - 0s - loss: 0.0275 - accuracy: 0.9987 - val_loss: 0.4526 - val_accuracy: 0.8580\n",
      "Epoch 58/60\n",
      "47/47 - 0s - loss: 0.0250 - accuracy: 0.9987 - val_loss: 0.4561 - val_accuracy: 0.8660\n",
      "Epoch 59/60\n",
      "47/47 - 0s - loss: 0.0229 - accuracy: 0.9987 - val_loss: 0.4633 - val_accuracy: 0.8500\n",
      "Epoch 60/60\n",
      "47/47 - 0s - loss: 0.0210 - accuracy: 0.9987 - val_loss: 0.4578 - val_accuracy: 0.8740\n",
      "Epochs: 60, Batch size: 32, Validation accuracy: 0.8740000128746033\n",
      "Epoch 1/60\n",
      "24/24 - 1s - loss: 1.5679 - accuracy: 0.4601 - val_loss: 1.4585 - val_accuracy: 0.4840\n",
      "Epoch 2/60\n",
      "24/24 - 0s - loss: 1.4634 - accuracy: 0.4842 - val_loss: 1.4174 - val_accuracy: 0.4840\n",
      "Epoch 3/60\n",
      "24/24 - 0s - loss: 1.4254 - accuracy: 0.4842 - val_loss: 1.3733 - val_accuracy: 0.4840\n",
      "Epoch 4/60\n",
      "24/24 - 0s - loss: 1.3671 - accuracy: 0.4869 - val_loss: 1.3025 - val_accuracy: 0.5060\n",
      "Epoch 5/60\n",
      "24/24 - 0s - loss: 1.2985 - accuracy: 0.5091 - val_loss: 1.2420 - val_accuracy: 0.5000\n",
      "Epoch 6/60\n",
      "24/24 - 1s - loss: 1.2252 - accuracy: 0.5399 - val_loss: 1.1729 - val_accuracy: 0.5580\n",
      "Epoch 7/60\n",
      "24/24 - 0s - loss: 1.1478 - accuracy: 0.5855 - val_loss: 1.0988 - val_accuracy: 0.6620\n",
      "Epoch 8/60\n",
      "24/24 - 0s - loss: 1.0739 - accuracy: 0.6425 - val_loss: 1.0330 - val_accuracy: 0.6540\n",
      "Epoch 9/60\n",
      "24/24 - 0s - loss: 1.0008 - accuracy: 0.6868 - val_loss: 0.9872 - val_accuracy: 0.6740\n",
      "Epoch 10/60\n",
      "24/24 - 0s - loss: 0.9315 - accuracy: 0.7129 - val_loss: 0.9256 - val_accuracy: 0.7100\n",
      "Epoch 11/60\n",
      "24/24 - 0s - loss: 0.8672 - accuracy: 0.7324 - val_loss: 0.8715 - val_accuracy: 0.7380\n",
      "Epoch 12/60\n",
      "24/24 - 0s - loss: 0.8093 - accuracy: 0.7586 - val_loss: 0.8264 - val_accuracy: 0.7420\n",
      "Epoch 13/60\n",
      "24/24 - 0s - loss: 0.7545 - accuracy: 0.7793 - val_loss: 0.7872 - val_accuracy: 0.7620\n",
      "Epoch 14/60\n",
      "24/24 - 0s - loss: 0.7099 - accuracy: 0.7881 - val_loss: 0.7515 - val_accuracy: 0.7960\n",
      "Epoch 15/60\n",
      "24/24 - 0s - loss: 0.6661 - accuracy: 0.8062 - val_loss: 0.7239 - val_accuracy: 0.7900\n",
      "Epoch 16/60\n",
      "24/24 - 0s - loss: 0.6247 - accuracy: 0.8189 - val_loss: 0.6835 - val_accuracy: 0.8100\n",
      "Epoch 17/60\n",
      "24/24 - 0s - loss: 0.5910 - accuracy: 0.8317 - val_loss: 0.6635 - val_accuracy: 0.8160\n",
      "Epoch 18/60\n",
      "24/24 - 0s - loss: 0.5549 - accuracy: 0.8464 - val_loss: 0.6375 - val_accuracy: 0.8260\n",
      "Epoch 19/60\n",
      "24/24 - 0s - loss: 0.5244 - accuracy: 0.8491 - val_loss: 0.6285 - val_accuracy: 0.8380\n",
      "Epoch 20/60\n",
      "24/24 - 0s - loss: 0.4970 - accuracy: 0.8571 - val_loss: 0.6008 - val_accuracy: 0.8320\n",
      "Epoch 21/60\n",
      "24/24 - 0s - loss: 0.4718 - accuracy: 0.8672 - val_loss: 0.5867 - val_accuracy: 0.8300\n",
      "Epoch 22/60\n",
      "24/24 - 0s - loss: 0.4458 - accuracy: 0.8766 - val_loss: 0.5767 - val_accuracy: 0.8360\n",
      "Epoch 23/60\n",
      "24/24 - 0s - loss: 0.4221 - accuracy: 0.8826 - val_loss: 0.5752 - val_accuracy: 0.8440\n",
      "Epoch 24/60\n",
      "24/24 - 0s - loss: 0.4023 - accuracy: 0.8940 - val_loss: 0.5534 - val_accuracy: 0.8540\n",
      "Epoch 25/60\n",
      "24/24 - 0s - loss: 0.3810 - accuracy: 0.8987 - val_loss: 0.5351 - val_accuracy: 0.8520\n",
      "Epoch 26/60\n",
      "24/24 - 0s - loss: 0.3620 - accuracy: 0.9048 - val_loss: 0.5219 - val_accuracy: 0.8560\n",
      "Epoch 27/60\n",
      "24/24 - 0s - loss: 0.3442 - accuracy: 0.9081 - val_loss: 0.5093 - val_accuracy: 0.8580\n",
      "Epoch 28/60\n",
      "24/24 - 0s - loss: 0.3267 - accuracy: 0.9155 - val_loss: 0.5245 - val_accuracy: 0.8380\n",
      "Epoch 29/60\n",
      "24/24 - 0s - loss: 0.3115 - accuracy: 0.9235 - val_loss: 0.5065 - val_accuracy: 0.8480\n",
      "Epoch 30/60\n",
      "24/24 - 0s - loss: 0.2946 - accuracy: 0.9289 - val_loss: 0.4933 - val_accuracy: 0.8460\n",
      "Epoch 31/60\n",
      "24/24 - 0s - loss: 0.2806 - accuracy: 0.9302 - val_loss: 0.4960 - val_accuracy: 0.8420\n",
      "Epoch 32/60\n",
      "24/24 - 0s - loss: 0.2667 - accuracy: 0.9336 - val_loss: 0.4861 - val_accuracy: 0.8460\n",
      "Epoch 33/60\n",
      "24/24 - 0s - loss: 0.2547 - accuracy: 0.9410 - val_loss: 0.4796 - val_accuracy: 0.8520\n",
      "Epoch 34/60\n",
      "24/24 - 0s - loss: 0.2418 - accuracy: 0.9443 - val_loss: 0.4809 - val_accuracy: 0.8420\n",
      "Epoch 35/60\n",
      "24/24 - 0s - loss: 0.2295 - accuracy: 0.9477 - val_loss: 0.4698 - val_accuracy: 0.8440\n",
      "Epoch 36/60\n",
      "24/24 - 0s - loss: 0.2192 - accuracy: 0.9477 - val_loss: 0.4625 - val_accuracy: 0.8440\n",
      "Epoch 37/60\n",
      "24/24 - 0s - loss: 0.2078 - accuracy: 0.9551 - val_loss: 0.4689 - val_accuracy: 0.8440\n",
      "Epoch 38/60\n",
      "24/24 - 0s - loss: 0.1969 - accuracy: 0.9557 - val_loss: 0.4540 - val_accuracy: 0.8520\n",
      "Epoch 39/60\n",
      "24/24 - 0s - loss: 0.1866 - accuracy: 0.9537 - val_loss: 0.4603 - val_accuracy: 0.8420\n",
      "Epoch 40/60\n",
      "24/24 - 0s - loss: 0.1794 - accuracy: 0.9564 - val_loss: 0.4602 - val_accuracy: 0.8380\n",
      "Epoch 41/60\n",
      "24/24 - 0s - loss: 0.1686 - accuracy: 0.9604 - val_loss: 0.4457 - val_accuracy: 0.8480\n",
      "Epoch 42/60\n",
      "24/24 - 0s - loss: 0.1617 - accuracy: 0.9638 - val_loss: 0.4454 - val_accuracy: 0.8440\n",
      "Epoch 43/60\n",
      "24/24 - 0s - loss: 0.1519 - accuracy: 0.9671 - val_loss: 0.4394 - val_accuracy: 0.8520\n",
      "Epoch 44/60\n",
      "24/24 - 0s - loss: 0.1446 - accuracy: 0.9685 - val_loss: 0.4553 - val_accuracy: 0.8340\n",
      "Epoch 45/60\n",
      "24/24 - 0s - loss: 0.1374 - accuracy: 0.9718 - val_loss: 0.4490 - val_accuracy: 0.8340\n",
      "Epoch 46/60\n",
      "24/24 - 0s - loss: 0.1299 - accuracy: 0.9779 - val_loss: 0.4354 - val_accuracy: 0.8520\n",
      "Epoch 47/60\n",
      "24/24 - 0s - loss: 0.1236 - accuracy: 0.9738 - val_loss: 0.4340 - val_accuracy: 0.8480\n",
      "Epoch 48/60\n",
      "24/24 - 0s - loss: 0.1166 - accuracy: 0.9779 - val_loss: 0.4339 - val_accuracy: 0.8500\n",
      "Epoch 49/60\n",
      "24/24 - 0s - loss: 0.1108 - accuracy: 0.9779 - val_loss: 0.4323 - val_accuracy: 0.8480\n",
      "Epoch 50/60\n",
      "24/24 - 0s - loss: 0.1041 - accuracy: 0.9832 - val_loss: 0.4304 - val_accuracy: 0.8520\n",
      "Epoch 51/60\n",
      "24/24 - 0s - loss: 0.0986 - accuracy: 0.9832 - val_loss: 0.4299 - val_accuracy: 0.8540\n",
      "Epoch 52/60\n",
      "24/24 - 0s - loss: 0.0931 - accuracy: 0.9859 - val_loss: 0.4291 - val_accuracy: 0.8600\n",
      "Epoch 53/60\n",
      "24/24 - 0s - loss: 0.0880 - accuracy: 0.9852 - val_loss: 0.4266 - val_accuracy: 0.8560\n",
      "Epoch 54/60\n",
      "24/24 - 0s - loss: 0.0837 - accuracy: 0.9879 - val_loss: 0.4285 - val_accuracy: 0.8520\n",
      "Epoch 55/60\n",
      "24/24 - 0s - loss: 0.0788 - accuracy: 0.9879 - val_loss: 0.4381 - val_accuracy: 0.8440\n",
      "Epoch 56/60\n",
      "24/24 - 0s - loss: 0.0744 - accuracy: 0.9899 - val_loss: 0.4269 - val_accuracy: 0.8560\n",
      "Epoch 57/60\n",
      "24/24 - 0s - loss: 0.0703 - accuracy: 0.9906 - val_loss: 0.4302 - val_accuracy: 0.8560\n",
      "Epoch 58/60\n",
      "24/24 - 0s - loss: 0.0663 - accuracy: 0.9913 - val_loss: 0.4296 - val_accuracy: 0.8560\n",
      "Epoch 59/60\n",
      "24/24 - 0s - loss: 0.0622 - accuracy: 0.9926 - val_loss: 0.4288 - val_accuracy: 0.8540\n",
      "Epoch 60/60\n",
      "24/24 - 0s - loss: 0.0592 - accuracy: 0.9926 - val_loss: 0.4318 - val_accuracy: 0.8580\n",
      "Epochs: 60, Batch size: 64, Validation accuracy: 0.8579999804496765\n",
      "Epoch 1/90\n",
      "94/94 - 1s - loss: 1.5128 - accuracy: 0.4775 - val_loss: 1.4012 - val_accuracy: 0.4840\n",
      "Epoch 2/90\n",
      "94/94 - 1s - loss: 1.3781 - accuracy: 0.4896 - val_loss: 1.2609 - val_accuracy: 0.4960\n",
      "Epoch 3/90\n",
      "94/94 - 1s - loss: 1.1898 - accuracy: 0.5889 - val_loss: 1.0802 - val_accuracy: 0.6260\n",
      "Epoch 4/90\n",
      "94/94 - 1s - loss: 1.0068 - accuracy: 0.6982 - val_loss: 0.9248 - val_accuracy: 0.7160\n",
      "Epoch 5/90\n",
      "94/94 - 1s - loss: 0.8644 - accuracy: 0.7384 - val_loss: 0.8234 - val_accuracy: 0.7580\n",
      "Epoch 6/90\n",
      "94/94 - 1s - loss: 0.7565 - accuracy: 0.7673 - val_loss: 0.7346 - val_accuracy: 0.7680\n",
      "Epoch 7/90\n",
      "94/94 - 1s - loss: 0.6716 - accuracy: 0.7901 - val_loss: 0.6707 - val_accuracy: 0.7800\n",
      "Epoch 8/90\n",
      "94/94 - 1s - loss: 0.6035 - accuracy: 0.8055 - val_loss: 0.6356 - val_accuracy: 0.8080\n",
      "Epoch 9/90\n",
      "94/94 - 1s - loss: 0.5442 - accuracy: 0.8290 - val_loss: 0.5863 - val_accuracy: 0.8100\n",
      "Epoch 10/90\n",
      "94/94 - 1s - loss: 0.4936 - accuracy: 0.8498 - val_loss: 0.5540 - val_accuracy: 0.8220\n",
      "Epoch 11/90\n",
      "94/94 - 1s - loss: 0.4500 - accuracy: 0.8692 - val_loss: 0.5355 - val_accuracy: 0.8280\n",
      "Epoch 12/90\n",
      "94/94 - 1s - loss: 0.4111 - accuracy: 0.8773 - val_loss: 0.5138 - val_accuracy: 0.8460\n",
      "Epoch 13/90\n",
      "94/94 - 1s - loss: 0.3777 - accuracy: 0.8947 - val_loss: 0.5001 - val_accuracy: 0.8380\n",
      "Epoch 14/90\n",
      "94/94 - 1s - loss: 0.3473 - accuracy: 0.9021 - val_loss: 0.4815 - val_accuracy: 0.8400\n",
      "Epoch 15/90\n",
      "94/94 - 1s - loss: 0.3204 - accuracy: 0.9115 - val_loss: 0.4682 - val_accuracy: 0.8480\n",
      "Epoch 16/90\n",
      "94/94 - 1s - loss: 0.2952 - accuracy: 0.9215 - val_loss: 0.4579 - val_accuracy: 0.8520\n",
      "Epoch 17/90\n",
      "94/94 - 1s - loss: 0.2740 - accuracy: 0.9249 - val_loss: 0.4479 - val_accuracy: 0.8480\n",
      "Epoch 18/90\n",
      "94/94 - 1s - loss: 0.2524 - accuracy: 0.9323 - val_loss: 0.4468 - val_accuracy: 0.8520\n",
      "Epoch 19/90\n",
      "94/94 - 1s - loss: 0.2343 - accuracy: 0.9356 - val_loss: 0.4382 - val_accuracy: 0.8600\n",
      "Epoch 20/90\n",
      "94/94 - 1s - loss: 0.2161 - accuracy: 0.9423 - val_loss: 0.4363 - val_accuracy: 0.8600\n",
      "Epoch 21/90\n",
      "94/94 - 1s - loss: 0.2009 - accuracy: 0.9484 - val_loss: 0.4349 - val_accuracy: 0.8600\n",
      "Epoch 22/90\n",
      "94/94 - 1s - loss: 0.1863 - accuracy: 0.9544 - val_loss: 0.4325 - val_accuracy: 0.8640\n",
      "Epoch 23/90\n",
      "94/94 - 1s - loss: 0.1726 - accuracy: 0.9544 - val_loss: 0.4270 - val_accuracy: 0.8540\n",
      "Epoch 24/90\n",
      "94/94 - 1s - loss: 0.1605 - accuracy: 0.9591 - val_loss: 0.4295 - val_accuracy: 0.8580\n",
      "Epoch 25/90\n",
      "94/94 - 1s - loss: 0.1474 - accuracy: 0.9618 - val_loss: 0.4204 - val_accuracy: 0.8660\n",
      "Epoch 26/90\n",
      "94/94 - 1s - loss: 0.1373 - accuracy: 0.9678 - val_loss: 0.4245 - val_accuracy: 0.8600\n",
      "Epoch 27/90\n",
      "94/94 - 1s - loss: 0.1271 - accuracy: 0.9725 - val_loss: 0.4218 - val_accuracy: 0.8580\n",
      "Epoch 28/90\n",
      "94/94 - 1s - loss: 0.1181 - accuracy: 0.9732 - val_loss: 0.4183 - val_accuracy: 0.8620\n",
      "Epoch 29/90\n",
      "94/94 - 1s - loss: 0.1091 - accuracy: 0.9759 - val_loss: 0.4230 - val_accuracy: 0.8640\n",
      "Epoch 30/90\n",
      "94/94 - 1s - loss: 0.1002 - accuracy: 0.9785 - val_loss: 0.4251 - val_accuracy: 0.8600\n",
      "Epoch 31/90\n",
      "94/94 - 1s - loss: 0.0930 - accuracy: 0.9805 - val_loss: 0.4205 - val_accuracy: 0.8660\n",
      "Epoch 32/90\n",
      "94/94 - 1s - loss: 0.0852 - accuracy: 0.9819 - val_loss: 0.4220 - val_accuracy: 0.8660\n",
      "Epoch 33/90\n",
      "94/94 - 1s - loss: 0.0798 - accuracy: 0.9839 - val_loss: 0.4153 - val_accuracy: 0.8660\n",
      "Epoch 34/90\n",
      "94/94 - 1s - loss: 0.0738 - accuracy: 0.9866 - val_loss: 0.4215 - val_accuracy: 0.8660\n",
      "Epoch 35/90\n",
      "94/94 - 1s - loss: 0.0676 - accuracy: 0.9886 - val_loss: 0.4257 - val_accuracy: 0.8580\n",
      "Epoch 36/90\n",
      "94/94 - 1s - loss: 0.0625 - accuracy: 0.9893 - val_loss: 0.4228 - val_accuracy: 0.8600\n",
      "Epoch 37/90\n",
      "94/94 - 1s - loss: 0.0573 - accuracy: 0.9906 - val_loss: 0.4243 - val_accuracy: 0.8640\n",
      "Epoch 38/90\n",
      "94/94 - 1s - loss: 0.0527 - accuracy: 0.9920 - val_loss: 0.4280 - val_accuracy: 0.8640\n",
      "Epoch 39/90\n",
      "94/94 - 1s - loss: 0.0483 - accuracy: 0.9933 - val_loss: 0.4229 - val_accuracy: 0.8680\n",
      "Epoch 40/90\n",
      "94/94 - 1s - loss: 0.0445 - accuracy: 0.9933 - val_loss: 0.4347 - val_accuracy: 0.8620\n",
      "Epoch 41/90\n",
      "94/94 - 1s - loss: 0.0416 - accuracy: 0.9933 - val_loss: 0.4264 - val_accuracy: 0.8680\n",
      "Epoch 42/90\n",
      "94/94 - 1s - loss: 0.0379 - accuracy: 0.9953 - val_loss: 0.4347 - val_accuracy: 0.8660\n",
      "Epoch 43/90\n",
      "94/94 - 1s - loss: 0.0342 - accuracy: 0.9953 - val_loss: 0.4279 - val_accuracy: 0.8740\n",
      "Epoch 44/90\n",
      "94/94 - 1s - loss: 0.0316 - accuracy: 0.9946 - val_loss: 0.4350 - val_accuracy: 0.8680\n",
      "Epoch 45/90\n",
      "94/94 - 1s - loss: 0.0293 - accuracy: 0.9940 - val_loss: 0.4354 - val_accuracy: 0.8700\n",
      "Epoch 46/90\n",
      "94/94 - 1s - loss: 0.0267 - accuracy: 0.9960 - val_loss: 0.4507 - val_accuracy: 0.8640\n",
      "Epoch 47/90\n",
      "94/94 - 1s - loss: 0.0249 - accuracy: 0.9960 - val_loss: 0.4434 - val_accuracy: 0.8660\n",
      "Epoch 48/90\n",
      "94/94 - 1s - loss: 0.0220 - accuracy: 0.9966 - val_loss: 0.4469 - val_accuracy: 0.8660\n",
      "Epoch 49/90\n",
      "94/94 - 1s - loss: 0.0200 - accuracy: 0.9966 - val_loss: 0.4514 - val_accuracy: 0.8660\n",
      "Epoch 50/90\n",
      "94/94 - 1s - loss: 0.0185 - accuracy: 0.9966 - val_loss: 0.4532 - val_accuracy: 0.8640\n",
      "Epoch 51/90\n",
      "94/94 - 1s - loss: 0.0169 - accuracy: 0.9973 - val_loss: 0.4661 - val_accuracy: 0.8660\n",
      "Epoch 52/90\n",
      "94/94 - 1s - loss: 0.0151 - accuracy: 0.9973 - val_loss: 0.4570 - val_accuracy: 0.8660\n",
      "Epoch 53/90\n",
      "94/94 - 1s - loss: 0.0131 - accuracy: 0.9980 - val_loss: 0.4711 - val_accuracy: 0.8560\n",
      "Epoch 54/90\n",
      "94/94 - 1s - loss: 0.0120 - accuracy: 0.9987 - val_loss: 0.4613 - val_accuracy: 0.8660\n",
      "Epoch 55/90\n",
      "94/94 - 1s - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.4744 - val_accuracy: 0.8640\n",
      "Epoch 56/90\n",
      "94/94 - 1s - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.4772 - val_accuracy: 0.8680\n",
      "Epoch 57/90\n",
      "94/94 - 1s - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.4741 - val_accuracy: 0.8660\n",
      "Epoch 58/90\n",
      "94/94 - 1s - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.4896 - val_accuracy: 0.8600\n",
      "Epoch 59/90\n",
      "94/94 - 1s - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.4940 - val_accuracy: 0.8620\n",
      "Epoch 60/90\n",
      "94/94 - 1s - loss: 0.0065 - accuracy: 0.9993 - val_loss: 0.4911 - val_accuracy: 0.8680\n",
      "Epoch 61/90\n",
      "94/94 - 1s - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.4997 - val_accuracy: 0.8640\n",
      "Epoch 62/90\n",
      "94/94 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.8660\n",
      "Epoch 63/90\n",
      "94/94 - 1s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5198 - val_accuracy: 0.8660\n",
      "Epoch 64/90\n",
      "94/94 - 1s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.8660\n",
      "Epoch 65/90\n",
      "94/94 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.8680\n",
      "Epoch 66/90\n",
      "94/94 - 1s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.8660\n",
      "Epoch 67/90\n",
      "94/94 - 1s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.8700\n",
      "Epoch 68/90\n",
      "94/94 - 1s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.8680\n",
      "Epoch 69/90\n",
      "94/94 - 1s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5407 - val_accuracy: 0.8720\n",
      "Epoch 70/90\n",
      "94/94 - 1s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5512 - val_accuracy: 0.8680\n",
      "Epoch 71/90\n",
      "94/94 - 1s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5568 - val_accuracy: 0.8680\n",
      "Epoch 72/90\n",
      "94/94 - 1s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5696 - val_accuracy: 0.8700\n",
      "Epoch 73/90\n",
      "94/94 - 1s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5685 - val_accuracy: 0.8680\n",
      "Epoch 74/90\n",
      "94/94 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5669 - val_accuracy: 0.8700\n",
      "Epoch 75/90\n",
      "94/94 - 1s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5831 - val_accuracy: 0.8680\n",
      "Epoch 76/90\n",
      "94/94 - 1s - loss: 9.0746e-04 - accuracy: 1.0000 - val_loss: 0.5840 - val_accuracy: 0.8720\n",
      "Epoch 77/90\n",
      "94/94 - 1s - loss: 7.8587e-04 - accuracy: 1.0000 - val_loss: 0.5946 - val_accuracy: 0.8700\n",
      "Epoch 78/90\n",
      "94/94 - 1s - loss: 6.7204e-04 - accuracy: 1.0000 - val_loss: 0.6015 - val_accuracy: 0.8720\n",
      "Epoch 79/90\n",
      "94/94 - 1s - loss: 6.1998e-04 - accuracy: 1.0000 - val_loss: 0.6050 - val_accuracy: 0.8720\n",
      "Epoch 80/90\n",
      "94/94 - 1s - loss: 5.4560e-04 - accuracy: 1.0000 - val_loss: 0.6147 - val_accuracy: 0.8700\n",
      "Epoch 81/90\n",
      "94/94 - 1s - loss: 5.2389e-04 - accuracy: 1.0000 - val_loss: 0.6305 - val_accuracy: 0.8740\n",
      "Epoch 82/90\n",
      "94/94 - 1s - loss: 4.1618e-04 - accuracy: 1.0000 - val_loss: 0.6243 - val_accuracy: 0.8760\n",
      "Epoch 83/90\n",
      "94/94 - 1s - loss: 3.6611e-04 - accuracy: 1.0000 - val_loss: 0.6380 - val_accuracy: 0.8700\n",
      "Epoch 84/90\n",
      "94/94 - 1s - loss: 3.1802e-04 - accuracy: 1.0000 - val_loss: 0.6532 - val_accuracy: 0.8760\n",
      "Epoch 85/90\n",
      "94/94 - 1s - loss: 2.6221e-04 - accuracy: 1.0000 - val_loss: 0.6496 - val_accuracy: 0.8720\n",
      "Epoch 86/90\n",
      "94/94 - 1s - loss: 2.4375e-04 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.8720\n",
      "Epoch 87/90\n",
      "94/94 - 1s - loss: 2.0451e-04 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.8680\n",
      "Epoch 88/90\n",
      "94/94 - 1s - loss: 1.7565e-04 - accuracy: 1.0000 - val_loss: 0.6871 - val_accuracy: 0.8680\n",
      "Epoch 89/90\n",
      "94/94 - 1s - loss: 1.6458e-04 - accuracy: 1.0000 - val_loss: 0.6783 - val_accuracy: 0.8760\n",
      "Epoch 90/90\n",
      "94/94 - 1s - loss: 1.5341e-04 - accuracy: 1.0000 - val_loss: 0.6920 - val_accuracy: 0.8700\n",
      "Epochs: 90, Batch size: 16, Validation accuracy: 0.8700000047683716\n",
      "Epoch 1/90\n",
      "47/47 - 1s - loss: 1.5404 - accuracy: 0.4728 - val_loss: 1.4257 - val_accuracy: 0.4840\n",
      "Epoch 2/90\n",
      "47/47 - 1s - loss: 1.4390 - accuracy: 0.4842 - val_loss: 1.3528 - val_accuracy: 0.4840\n",
      "Epoch 3/90\n",
      "47/47 - 1s - loss: 1.3419 - accuracy: 0.4997 - val_loss: 1.2552 - val_accuracy: 0.5340\n",
      "Epoch 4/90\n",
      "47/47 - 0s - loss: 1.2226 - accuracy: 0.5513 - val_loss: 1.1434 - val_accuracy: 0.6760\n",
      "Epoch 5/90\n",
      "47/47 - 0s - loss: 1.0985 - accuracy: 0.6533 - val_loss: 1.0321 - val_accuracy: 0.6760\n",
      "Epoch 6/90\n",
      "47/47 - 1s - loss: 0.9891 - accuracy: 0.6989 - val_loss: 0.9490 - val_accuracy: 0.7260\n",
      "Epoch 7/90\n",
      "47/47 - 0s - loss: 0.8892 - accuracy: 0.7311 - val_loss: 0.8623 - val_accuracy: 0.7220\n",
      "Epoch 8/90\n",
      "47/47 - 0s - loss: 0.8088 - accuracy: 0.7505 - val_loss: 0.7997 - val_accuracy: 0.7460\n",
      "Epoch 9/90\n",
      "47/47 - 0s - loss: 0.7378 - accuracy: 0.7679 - val_loss: 0.7440 - val_accuracy: 0.7480\n",
      "Epoch 10/90\n",
      "47/47 - 0s - loss: 0.6750 - accuracy: 0.7827 - val_loss: 0.7058 - val_accuracy: 0.7920\n",
      "Epoch 11/90\n",
      "47/47 - 0s - loss: 0.6216 - accuracy: 0.8035 - val_loss: 0.6601 - val_accuracy: 0.7980\n",
      "Epoch 12/90\n",
      "47/47 - 0s - loss: 0.5731 - accuracy: 0.8236 - val_loss: 0.6294 - val_accuracy: 0.8040\n",
      "Epoch 13/90\n",
      "47/47 - 0s - loss: 0.5295 - accuracy: 0.8343 - val_loss: 0.5954 - val_accuracy: 0.8100\n",
      "Epoch 14/90\n",
      "47/47 - 0s - loss: 0.4907 - accuracy: 0.8592 - val_loss: 0.5724 - val_accuracy: 0.8200\n",
      "Epoch 15/90\n",
      "47/47 - 0s - loss: 0.4552 - accuracy: 0.8672 - val_loss: 0.5499 - val_accuracy: 0.8360\n",
      "Epoch 16/90\n",
      "47/47 - 0s - loss: 0.4260 - accuracy: 0.8766 - val_loss: 0.5392 - val_accuracy: 0.8320\n",
      "Epoch 17/90\n",
      "47/47 - 1s - loss: 0.3955 - accuracy: 0.8826 - val_loss: 0.5219 - val_accuracy: 0.8280\n",
      "Epoch 18/90\n",
      "47/47 - 0s - loss: 0.3698 - accuracy: 0.8907 - val_loss: 0.5119 - val_accuracy: 0.8380\n",
      "Epoch 19/90\n",
      "47/47 - 0s - loss: 0.3447 - accuracy: 0.9014 - val_loss: 0.4941 - val_accuracy: 0.8440\n",
      "Epoch 20/90\n",
      "47/47 - 0s - loss: 0.3233 - accuracy: 0.9088 - val_loss: 0.4938 - val_accuracy: 0.8340\n",
      "Epoch 21/90\n",
      "47/47 - 0s - loss: 0.3023 - accuracy: 0.9188 - val_loss: 0.4798 - val_accuracy: 0.8340\n",
      "Epoch 22/90\n",
      "47/47 - 0s - loss: 0.2825 - accuracy: 0.9222 - val_loss: 0.4666 - val_accuracy: 0.8500\n",
      "Epoch 23/90\n",
      "47/47 - 0s - loss: 0.2656 - accuracy: 0.9289 - val_loss: 0.4572 - val_accuracy: 0.8520\n",
      "Epoch 24/90\n",
      "47/47 - 0s - loss: 0.2487 - accuracy: 0.9343 - val_loss: 0.4582 - val_accuracy: 0.8400\n",
      "Epoch 25/90\n",
      "47/47 - 0s - loss: 0.2332 - accuracy: 0.9383 - val_loss: 0.4488 - val_accuracy: 0.8480\n",
      "Epoch 26/90\n",
      "47/47 - 0s - loss: 0.2173 - accuracy: 0.9477 - val_loss: 0.4533 - val_accuracy: 0.8360\n",
      "Epoch 27/90\n",
      "47/47 - 0s - loss: 0.2047 - accuracy: 0.9504 - val_loss: 0.4454 - val_accuracy: 0.8400\n",
      "Epoch 28/90\n",
      "47/47 - 0s - loss: 0.1916 - accuracy: 0.9517 - val_loss: 0.4378 - val_accuracy: 0.8460\n",
      "Epoch 29/90\n",
      "47/47 - 0s - loss: 0.1795 - accuracy: 0.9557 - val_loss: 0.4341 - val_accuracy: 0.8420\n",
      "Epoch 30/90\n",
      "47/47 - 0s - loss: 0.1685 - accuracy: 0.9645 - val_loss: 0.4282 - val_accuracy: 0.8480\n",
      "Epoch 31/90\n",
      "47/47 - 0s - loss: 0.1579 - accuracy: 0.9651 - val_loss: 0.4247 - val_accuracy: 0.8480\n",
      "Epoch 32/90\n",
      "47/47 - 0s - loss: 0.1475 - accuracy: 0.9705 - val_loss: 0.4280 - val_accuracy: 0.8440\n",
      "Epoch 33/90\n",
      "47/47 - 0s - loss: 0.1381 - accuracy: 0.9759 - val_loss: 0.4180 - val_accuracy: 0.8480\n",
      "Epoch 34/90\n",
      "47/47 - 0s - loss: 0.1294 - accuracy: 0.9765 - val_loss: 0.4149 - val_accuracy: 0.8560\n",
      "Epoch 35/90\n",
      "47/47 - 0s - loss: 0.1211 - accuracy: 0.9772 - val_loss: 0.4157 - val_accuracy: 0.8520\n",
      "Epoch 36/90\n",
      "47/47 - 0s - loss: 0.1136 - accuracy: 0.9799 - val_loss: 0.4097 - val_accuracy: 0.8540\n",
      "Epoch 37/90\n",
      "47/47 - 1s - loss: 0.1057 - accuracy: 0.9826 - val_loss: 0.4151 - val_accuracy: 0.8560\n",
      "Epoch 38/90\n",
      "47/47 - 0s - loss: 0.0986 - accuracy: 0.9832 - val_loss: 0.4061 - val_accuracy: 0.8560\n",
      "Epoch 39/90\n",
      "47/47 - 0s - loss: 0.0918 - accuracy: 0.9859 - val_loss: 0.4080 - val_accuracy: 0.8640\n",
      "Epoch 40/90\n",
      "47/47 - 0s - loss: 0.0862 - accuracy: 0.9879 - val_loss: 0.4107 - val_accuracy: 0.8520\n",
      "Epoch 41/90\n",
      "47/47 - 0s - loss: 0.0802 - accuracy: 0.9859 - val_loss: 0.4052 - val_accuracy: 0.8660\n",
      "Epoch 42/90\n",
      "47/47 - 0s - loss: 0.0747 - accuracy: 0.9886 - val_loss: 0.4032 - val_accuracy: 0.8640\n",
      "Epoch 43/90\n",
      "47/47 - 1s - loss: 0.0698 - accuracy: 0.9893 - val_loss: 0.4072 - val_accuracy: 0.8620\n",
      "Epoch 44/90\n",
      "47/47 - 1s - loss: 0.0646 - accuracy: 0.9899 - val_loss: 0.4102 - val_accuracy: 0.8540\n",
      "Epoch 45/90\n",
      "47/47 - 0s - loss: 0.0599 - accuracy: 0.9920 - val_loss: 0.4107 - val_accuracy: 0.8560\n",
      "Epoch 46/90\n",
      "47/47 - 0s - loss: 0.0561 - accuracy: 0.9913 - val_loss: 0.4111 - val_accuracy: 0.8580\n",
      "Epoch 47/90\n",
      "47/47 - 0s - loss: 0.0521 - accuracy: 0.9933 - val_loss: 0.4128 - val_accuracy: 0.8580\n",
      "Epoch 48/90\n",
      "47/47 - 0s - loss: 0.0480 - accuracy: 0.9933 - val_loss: 0.4159 - val_accuracy: 0.8560\n",
      "Epoch 49/90\n",
      "47/47 - 0s - loss: 0.0448 - accuracy: 0.9933 - val_loss: 0.4096 - val_accuracy: 0.8580\n",
      "Epoch 50/90\n",
      "47/47 - 0s - loss: 0.0414 - accuracy: 0.9953 - val_loss: 0.4063 - val_accuracy: 0.8580\n",
      "Epoch 51/90\n",
      "47/47 - 0s - loss: 0.0383 - accuracy: 0.9966 - val_loss: 0.4113 - val_accuracy: 0.8600\n",
      "Epoch 52/90\n",
      "47/47 - 0s - loss: 0.0353 - accuracy: 0.9973 - val_loss: 0.4115 - val_accuracy: 0.8600\n",
      "Epoch 53/90\n",
      "47/47 - 0s - loss: 0.0329 - accuracy: 0.9973 - val_loss: 0.4155 - val_accuracy: 0.8600\n",
      "Epoch 54/90\n",
      "47/47 - 0s - loss: 0.0306 - accuracy: 0.9973 - val_loss: 0.4145 - val_accuracy: 0.8660\n",
      "Epoch 55/90\n",
      "47/47 - 0s - loss: 0.0279 - accuracy: 0.9987 - val_loss: 0.4153 - val_accuracy: 0.8660\n",
      "Epoch 56/90\n",
      "47/47 - 1s - loss: 0.0260 - accuracy: 0.9987 - val_loss: 0.4180 - val_accuracy: 0.8660\n",
      "Epoch 57/90\n",
      "47/47 - 0s - loss: 0.0239 - accuracy: 0.9987 - val_loss: 0.4214 - val_accuracy: 0.8620\n",
      "Epoch 58/90\n",
      "47/47 - 1s - loss: 0.0218 - accuracy: 0.9987 - val_loss: 0.4227 - val_accuracy: 0.8620\n",
      "Epoch 59/90\n",
      "47/47 - 1s - loss: 0.0203 - accuracy: 0.9987 - val_loss: 0.4282 - val_accuracy: 0.8600\n",
      "Epoch 60/90\n",
      "47/47 - 1s - loss: 0.0186 - accuracy: 0.9987 - val_loss: 0.4302 - val_accuracy: 0.8600\n",
      "Epoch 61/90\n",
      "47/47 - 0s - loss: 0.0171 - accuracy: 0.9987 - val_loss: 0.4360 - val_accuracy: 0.8600\n",
      "Epoch 62/90\n",
      "47/47 - 0s - loss: 0.0153 - accuracy: 0.9987 - val_loss: 0.4341 - val_accuracy: 0.8620\n",
      "Epoch 63/90\n",
      "47/47 - 1s - loss: 0.0142 - accuracy: 0.9987 - val_loss: 0.4344 - val_accuracy: 0.8620\n",
      "Epoch 64/90\n",
      "47/47 - 1s - loss: 0.0131 - accuracy: 0.9987 - val_loss: 0.4413 - val_accuracy: 0.8640\n",
      "Epoch 65/90\n",
      "47/47 - 0s - loss: 0.0121 - accuracy: 0.9987 - val_loss: 0.4454 - val_accuracy: 0.8680\n",
      "Epoch 66/90\n",
      "47/47 - 0s - loss: 0.0109 - accuracy: 0.9987 - val_loss: 0.4478 - val_accuracy: 0.8660\n",
      "Epoch 67/90\n",
      "47/47 - 1s - loss: 0.0100 - accuracy: 0.9987 - val_loss: 0.4501 - val_accuracy: 0.8660\n",
      "Epoch 68/90\n",
      "47/47 - 1s - loss: 0.0091 - accuracy: 0.9993 - val_loss: 0.4567 - val_accuracy: 0.8640\n",
      "Epoch 69/90\n",
      "47/47 - 1s - loss: 0.0082 - accuracy: 0.9993 - val_loss: 0.4589 - val_accuracy: 0.8660\n",
      "Epoch 70/90\n",
      "47/47 - 0s - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.4585 - val_accuracy: 0.8660\n",
      "Epoch 71/90\n",
      "47/47 - 0s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 0.8680\n",
      "Epoch 72/90\n",
      "47/47 - 0s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.8680\n",
      "Epoch 73/90\n",
      "47/47 - 0s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.8680\n",
      "Epoch 74/90\n",
      "47/47 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.8620\n",
      "Epoch 75/90\n",
      "47/47 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.8660\n",
      "Epoch 76/90\n",
      "47/47 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.8680\n",
      "Epoch 77/90\n",
      "47/47 - 0s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.8680\n",
      "Epoch 78/90\n",
      "47/47 - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.8700\n",
      "Epoch 79/90\n",
      "47/47 - 1s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.8680\n",
      "Epoch 80/90\n",
      "47/47 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.8660\n",
      "Epoch 81/90\n",
      "47/47 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.8700\n",
      "Epoch 82/90\n",
      "47/47 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5186 - val_accuracy: 0.8640\n",
      "Epoch 83/90\n",
      "47/47 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5194 - val_accuracy: 0.8640\n",
      "Epoch 84/90\n",
      "47/47 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5325 - val_accuracy: 0.8700\n",
      "Epoch 85/90\n",
      "47/47 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.8660\n",
      "Epoch 86/90\n",
      "47/47 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5355 - val_accuracy: 0.8660\n",
      "Epoch 87/90\n",
      "47/47 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.8620\n",
      "Epoch 88/90\n",
      "47/47 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5475 - val_accuracy: 0.8620\n",
      "Epoch 89/90\n",
      "47/47 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.8660\n",
      "Epoch 90/90\n",
      "47/47 - 0s - loss: 8.9771e-04 - accuracy: 1.0000 - val_loss: 0.5632 - val_accuracy: 0.8660\n",
      "Epochs: 90, Batch size: 32, Validation accuracy: 0.8659999966621399\n",
      "Epoch 1/90\n",
      "24/24 - 0s - loss: 1.5864 - accuracy: 0.4681 - val_loss: 1.4539 - val_accuracy: 0.4840\n",
      "Epoch 2/90\n",
      "24/24 - 0s - loss: 1.4740 - accuracy: 0.4842 - val_loss: 1.4265 - val_accuracy: 0.4840\n",
      "Epoch 3/90\n",
      "24/24 - 0s - loss: 1.4390 - accuracy: 0.4842 - val_loss: 1.3994 - val_accuracy: 0.4840\n",
      "Epoch 4/90\n",
      "24/24 - 0s - loss: 1.3928 - accuracy: 0.4842 - val_loss: 1.3345 - val_accuracy: 0.4840\n",
      "Epoch 5/90\n",
      "24/24 - 0s - loss: 1.3349 - accuracy: 0.4956 - val_loss: 1.2915 - val_accuracy: 0.4840\n",
      "Epoch 6/90\n",
      "24/24 - 0s - loss: 1.2714 - accuracy: 0.5184 - val_loss: 1.2258 - val_accuracy: 0.5360\n",
      "Epoch 7/90\n",
      "24/24 - 0s - loss: 1.2003 - accuracy: 0.5607 - val_loss: 1.1652 - val_accuracy: 0.5520\n",
      "Epoch 8/90\n",
      "24/24 - 0s - loss: 1.1296 - accuracy: 0.6076 - val_loss: 1.1074 - val_accuracy: 0.5820\n",
      "Epoch 9/90\n",
      "24/24 - 0s - loss: 1.0586 - accuracy: 0.6512 - val_loss: 1.0379 - val_accuracy: 0.7060\n",
      "Epoch 10/90\n",
      "24/24 - 0s - loss: 0.9877 - accuracy: 0.6962 - val_loss: 0.9758 - val_accuracy: 0.7160\n",
      "Epoch 11/90\n",
      "24/24 - 0s - loss: 0.9206 - accuracy: 0.7197 - val_loss: 0.9268 - val_accuracy: 0.7440\n",
      "Epoch 12/90\n",
      "24/24 - 0s - loss: 0.8595 - accuracy: 0.7431 - val_loss: 0.8724 - val_accuracy: 0.7400\n",
      "Epoch 13/90\n",
      "24/24 - 0s - loss: 0.8007 - accuracy: 0.7646 - val_loss: 0.8443 - val_accuracy: 0.7320\n",
      "Epoch 14/90\n",
      "24/24 - 0s - loss: 0.7470 - accuracy: 0.7800 - val_loss: 0.7840 - val_accuracy: 0.7520\n",
      "Epoch 15/90\n",
      "24/24 - 0s - loss: 0.6983 - accuracy: 0.7948 - val_loss: 0.7564 - val_accuracy: 0.7420\n",
      "Epoch 16/90\n",
      "24/24 - 0s - loss: 0.6517 - accuracy: 0.8015 - val_loss: 0.7215 - val_accuracy: 0.7820\n",
      "Epoch 17/90\n",
      "24/24 - 0s - loss: 0.6121 - accuracy: 0.8169 - val_loss: 0.6871 - val_accuracy: 0.7780\n",
      "Epoch 18/90\n",
      "24/24 - 0s - loss: 0.5742 - accuracy: 0.8330 - val_loss: 0.6625 - val_accuracy: 0.7820\n",
      "Epoch 19/90\n",
      "24/24 - 0s - loss: 0.5396 - accuracy: 0.8444 - val_loss: 0.6277 - val_accuracy: 0.8080\n",
      "Epoch 20/90\n",
      "24/24 - 0s - loss: 0.5079 - accuracy: 0.8545 - val_loss: 0.6130 - val_accuracy: 0.8120\n",
      "Epoch 21/90\n",
      "24/24 - 0s - loss: 0.4791 - accuracy: 0.8679 - val_loss: 0.5911 - val_accuracy: 0.8240\n",
      "Epoch 22/90\n",
      "24/24 - 0s - loss: 0.4511 - accuracy: 0.8726 - val_loss: 0.5958 - val_accuracy: 0.8120\n",
      "Epoch 23/90\n",
      "24/24 - 0s - loss: 0.4266 - accuracy: 0.8920 - val_loss: 0.5683 - val_accuracy: 0.8180\n",
      "Epoch 24/90\n",
      "24/24 - 0s - loss: 0.4044 - accuracy: 0.8940 - val_loss: 0.5642 - val_accuracy: 0.8140\n",
      "Epoch 25/90\n",
      "24/24 - 0s - loss: 0.3819 - accuracy: 0.8974 - val_loss: 0.5356 - val_accuracy: 0.8200\n",
      "Epoch 26/90\n",
      "24/24 - 0s - loss: 0.3631 - accuracy: 0.9021 - val_loss: 0.5294 - val_accuracy: 0.8320\n",
      "Epoch 27/90\n",
      "24/24 - 0s - loss: 0.3430 - accuracy: 0.9101 - val_loss: 0.5246 - val_accuracy: 0.8340\n",
      "Epoch 28/90\n",
      "24/24 - 0s - loss: 0.3254 - accuracy: 0.9175 - val_loss: 0.5092 - val_accuracy: 0.8420\n",
      "Epoch 29/90\n",
      "24/24 - 0s - loss: 0.3083 - accuracy: 0.9256 - val_loss: 0.5086 - val_accuracy: 0.8360\n",
      "Epoch 30/90\n",
      "24/24 - 0s - loss: 0.2915 - accuracy: 0.9282 - val_loss: 0.5024 - val_accuracy: 0.8480\n",
      "Epoch 31/90\n",
      "24/24 - 0s - loss: 0.2767 - accuracy: 0.9329 - val_loss: 0.5071 - val_accuracy: 0.8180\n",
      "Epoch 32/90\n",
      "24/24 - 0s - loss: 0.2626 - accuracy: 0.9390 - val_loss: 0.4947 - val_accuracy: 0.8360\n",
      "Epoch 33/90\n",
      "24/24 - 0s - loss: 0.2492 - accuracy: 0.9430 - val_loss: 0.4766 - val_accuracy: 0.8500\n",
      "Epoch 34/90\n",
      "24/24 - 0s - loss: 0.2372 - accuracy: 0.9396 - val_loss: 0.4718 - val_accuracy: 0.8440\n",
      "Epoch 35/90\n",
      "24/24 - 0s - loss: 0.2240 - accuracy: 0.9497 - val_loss: 0.4571 - val_accuracy: 0.8500\n",
      "Epoch 36/90\n",
      "24/24 - 0s - loss: 0.2140 - accuracy: 0.9470 - val_loss: 0.4658 - val_accuracy: 0.8480\n",
      "Epoch 37/90\n",
      "24/24 - 0s - loss: 0.2016 - accuracy: 0.9564 - val_loss: 0.4595 - val_accuracy: 0.8480\n",
      "Epoch 38/90\n",
      "24/24 - 0s - loss: 0.1919 - accuracy: 0.9598 - val_loss: 0.4510 - val_accuracy: 0.8560\n",
      "Epoch 39/90\n",
      "24/24 - 0s - loss: 0.1815 - accuracy: 0.9631 - val_loss: 0.4542 - val_accuracy: 0.8560\n",
      "Epoch 40/90\n",
      "24/24 - 0s - loss: 0.1716 - accuracy: 0.9658 - val_loss: 0.4604 - val_accuracy: 0.8360\n",
      "Epoch 41/90\n",
      "24/24 - 0s - loss: 0.1631 - accuracy: 0.9698 - val_loss: 0.4505 - val_accuracy: 0.8520\n",
      "Epoch 42/90\n",
      "24/24 - 0s - loss: 0.1541 - accuracy: 0.9732 - val_loss: 0.4483 - val_accuracy: 0.8520\n",
      "Epoch 43/90\n",
      "24/24 - 0s - loss: 0.1454 - accuracy: 0.9718 - val_loss: 0.4430 - val_accuracy: 0.8460\n",
      "Epoch 44/90\n",
      "24/24 - 0s - loss: 0.1379 - accuracy: 0.9732 - val_loss: 0.4467 - val_accuracy: 0.8440\n",
      "Epoch 45/90\n",
      "24/24 - 0s - loss: 0.1303 - accuracy: 0.9752 - val_loss: 0.4435 - val_accuracy: 0.8440\n",
      "Epoch 46/90\n",
      "24/24 - 0s - loss: 0.1228 - accuracy: 0.9785 - val_loss: 0.4330 - val_accuracy: 0.8600\n",
      "Epoch 47/90\n",
      "24/24 - 0s - loss: 0.1163 - accuracy: 0.9772 - val_loss: 0.4357 - val_accuracy: 0.8560\n",
      "Epoch 48/90\n",
      "24/24 - 0s - loss: 0.1102 - accuracy: 0.9792 - val_loss: 0.4297 - val_accuracy: 0.8560\n",
      "Epoch 49/90\n",
      "24/24 - 0s - loss: 0.1037 - accuracy: 0.9805 - val_loss: 0.4368 - val_accuracy: 0.8560\n",
      "Epoch 50/90\n",
      "24/24 - 0s - loss: 0.0977 - accuracy: 0.9846 - val_loss: 0.4414 - val_accuracy: 0.8500\n",
      "Epoch 51/90\n",
      "24/24 - 0s - loss: 0.0924 - accuracy: 0.9846 - val_loss: 0.4314 - val_accuracy: 0.8640\n",
      "Epoch 52/90\n",
      "24/24 - 0s - loss: 0.0870 - accuracy: 0.9866 - val_loss: 0.4395 - val_accuracy: 0.8580\n",
      "Epoch 53/90\n",
      "24/24 - 0s - loss: 0.0818 - accuracy: 0.9899 - val_loss: 0.4333 - val_accuracy: 0.8580\n",
      "Epoch 54/90\n",
      "24/24 - 0s - loss: 0.0773 - accuracy: 0.9899 - val_loss: 0.4369 - val_accuracy: 0.8620\n",
      "Epoch 55/90\n",
      "24/24 - 0s - loss: 0.0724 - accuracy: 0.9940 - val_loss: 0.4284 - val_accuracy: 0.8660\n",
      "Epoch 56/90\n",
      "24/24 - 0s - loss: 0.0682 - accuracy: 0.9946 - val_loss: 0.4289 - val_accuracy: 0.8640\n",
      "Epoch 57/90\n",
      "24/24 - 0s - loss: 0.0643 - accuracy: 0.9933 - val_loss: 0.4338 - val_accuracy: 0.8620\n",
      "Epoch 58/90\n",
      "24/24 - 0s - loss: 0.0602 - accuracy: 0.9940 - val_loss: 0.4304 - val_accuracy: 0.8660\n",
      "Epoch 59/90\n",
      "24/24 - 0s - loss: 0.0565 - accuracy: 0.9953 - val_loss: 0.4332 - val_accuracy: 0.8720\n",
      "Epoch 60/90\n",
      "24/24 - 0s - loss: 0.0527 - accuracy: 0.9966 - val_loss: 0.4317 - val_accuracy: 0.8720\n",
      "Epoch 61/90\n",
      "24/24 - 0s - loss: 0.0497 - accuracy: 0.9960 - val_loss: 0.4340 - val_accuracy: 0.8660\n",
      "Epoch 62/90\n",
      "24/24 - 0s - loss: 0.0466 - accuracy: 0.9980 - val_loss: 0.4330 - val_accuracy: 0.8680\n",
      "Epoch 63/90\n",
      "24/24 - 0s - loss: 0.0434 - accuracy: 0.9980 - val_loss: 0.4342 - val_accuracy: 0.8720\n",
      "Epoch 64/90\n",
      "24/24 - 0s - loss: 0.0409 - accuracy: 0.9980 - val_loss: 0.4309 - val_accuracy: 0.8640\n",
      "Epoch 65/90\n",
      "24/24 - 0s - loss: 0.0380 - accuracy: 0.9987 - val_loss: 0.4383 - val_accuracy: 0.8660\n",
      "Epoch 66/90\n",
      "24/24 - 0s - loss: 0.0354 - accuracy: 0.9987 - val_loss: 0.4342 - val_accuracy: 0.8660\n",
      "Epoch 67/90\n",
      "24/24 - 0s - loss: 0.0333 - accuracy: 0.9987 - val_loss: 0.4314 - val_accuracy: 0.8680\n",
      "Epoch 68/90\n",
      "24/24 - 0s - loss: 0.0312 - accuracy: 0.9987 - val_loss: 0.4377 - val_accuracy: 0.8680\n",
      "Epoch 69/90\n",
      "24/24 - 0s - loss: 0.0287 - accuracy: 0.9987 - val_loss: 0.4422 - val_accuracy: 0.8700\n",
      "Epoch 70/90\n",
      "24/24 - 0s - loss: 0.0268 - accuracy: 0.9987 - val_loss: 0.4374 - val_accuracy: 0.8720\n",
      "Epoch 71/90\n",
      "24/24 - 0s - loss: 0.0249 - accuracy: 0.9987 - val_loss: 0.4451 - val_accuracy: 0.8700\n",
      "Epoch 72/90\n",
      "24/24 - 0s - loss: 0.0231 - accuracy: 0.9987 - val_loss: 0.4426 - val_accuracy: 0.8640\n",
      "Epoch 73/90\n",
      "24/24 - 0s - loss: 0.0216 - accuracy: 0.9987 - val_loss: 0.4506 - val_accuracy: 0.8700\n",
      "Epoch 74/90\n",
      "24/24 - 0s - loss: 0.0202 - accuracy: 0.9987 - val_loss: 0.4512 - val_accuracy: 0.8640\n",
      "Epoch 75/90\n",
      "24/24 - 0s - loss: 0.0187 - accuracy: 0.9987 - val_loss: 0.4535 - val_accuracy: 0.8720\n",
      "Epoch 76/90\n",
      "24/24 - 0s - loss: 0.0173 - accuracy: 0.9987 - val_loss: 0.4583 - val_accuracy: 0.8640\n",
      "Epoch 77/90\n",
      "24/24 - 0s - loss: 0.0160 - accuracy: 0.9993 - val_loss: 0.4565 - val_accuracy: 0.8720\n",
      "Epoch 78/90\n",
      "24/24 - 0s - loss: 0.0147 - accuracy: 0.9993 - val_loss: 0.4613 - val_accuracy: 0.8740\n",
      "Epoch 79/90\n",
      "24/24 - 0s - loss: 0.0139 - accuracy: 0.9993 - val_loss: 0.4586 - val_accuracy: 0.8740\n",
      "Epoch 80/90\n",
      "24/24 - 1s - loss: 0.0127 - accuracy: 0.9993 - val_loss: 0.4599 - val_accuracy: 0.8720\n",
      "Epoch 81/90\n",
      "24/24 - 0s - loss: 0.0117 - accuracy: 0.9993 - val_loss: 0.4629 - val_accuracy: 0.8700\n",
      "Epoch 82/90\n",
      "24/24 - 0s - loss: 0.0108 - accuracy: 0.9993 - val_loss: 0.4660 - val_accuracy: 0.8780\n",
      "Epoch 83/90\n",
      "24/24 - 0s - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4728 - val_accuracy: 0.8680\n",
      "Epoch 84/90\n",
      "24/24 - 0s - loss: 0.0091 - accuracy: 0.9993 - val_loss: 0.4789 - val_accuracy: 0.8700\n",
      "Epoch 85/90\n",
      "24/24 - 0s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.8680\n",
      "Epoch 86/90\n",
      "24/24 - 0s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.8680\n",
      "Epoch 87/90\n",
      "24/24 - 0s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.8720\n",
      "Epoch 88/90\n",
      "24/24 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4811 - val_accuracy: 0.8700\n",
      "Epoch 89/90\n",
      "24/24 - 0s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.8680\n",
      "Epoch 90/90\n",
      "24/24 - 0s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.8740\n",
      "Epochs: 90, Batch size: 64, Validation accuracy: 0.8740000128746033\n"
     ]
    }
   ],
   "source": [
    "# Different configurations to try\n",
    "epochs_list = [30, 60, 90]\n",
    "batch_sizes = [16, 32, 64]\n",
    "#embedding_dim = 8\n",
    "# Dictionary to store the history of each configuration\n",
    "history_dict = {}\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    for batch_size in batch_sizes:\n",
    "        # Get a fresh instance of the model for each run\n",
    "        model = getModel()\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='rmsprop',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(x_train, y_train_one_hot,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            validation_data=(x_val, y_val_one_hot),\n",
    "                            verbose=2)  # Set verbose to 2 for less output\n",
    "\n",
    "        # Save the history of this configuration\n",
    "        history_dict[f\"epochs_{epochs}_batch_{batch_size}\"] = history.history\n",
    "\n",
    "        # Optionally, you can print out the final validation accuracy for each configuration\n",
    "        final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "        print(f\"Epochs: {epochs}, Batch size: {batch_size}, Validation accuracy: {final_val_accuracy}\")\n",
    "\n",
    "# Now you can analyze the history_dict to see which configuration performed best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7be3a190-677d-4588-a3e3-c74e8b8f707b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs_30_batch_16': {'loss': [1.509526252746582,\n",
       "   1.3635553121566772,\n",
       "   1.1646208763122559,\n",
       "   0.9837902188301086,\n",
       "   0.8485177755355835,\n",
       "   0.742249071598053,\n",
       "   0.6610434651374817,\n",
       "   0.5922733545303345,\n",
       "   0.536267876625061,\n",
       "   0.48755964636802673,\n",
       "   0.44664090871810913,\n",
       "   0.4109458923339844,\n",
       "   0.3785935342311859,\n",
       "   0.3484634757041931,\n",
       "   0.3227599859237671,\n",
       "   0.29809239506721497,\n",
       "   0.2772292196750641,\n",
       "   0.2570899724960327,\n",
       "   0.23897084593772888,\n",
       "   0.22147691249847412,\n",
       "   0.20561937987804413,\n",
       "   0.1911049485206604,\n",
       "   0.17673826217651367,\n",
       "   0.16465657949447632,\n",
       "   0.152627632021904,\n",
       "   0.14159518480300903,\n",
       "   0.13084761798381805,\n",
       "   0.1198643296957016,\n",
       "   0.1115197241306305,\n",
       "   0.10371623933315277],\n",
       "  'accuracy': [0.46948355436325073,\n",
       "   0.49295774102211,\n",
       "   0.5902079343795776,\n",
       "   0.6975184679031372,\n",
       "   0.737089216709137,\n",
       "   0.7712944149971008,\n",
       "   0.7934272289276123,\n",
       "   0.8215962648391724,\n",
       "   0.8363514542579651,\n",
       "   0.8571428656578064,\n",
       "   0.8692153096199036,\n",
       "   0.884641170501709,\n",
       "   0.8900067210197449,\n",
       "   0.898725688457489,\n",
       "   0.9134808778762817,\n",
       "   0.9228705763816833,\n",
       "   0.9302481412887573,\n",
       "   0.9329309463500977,\n",
       "   0.9376257658004761,\n",
       "   0.9436619877815247,\n",
       "   0.9436619877815247,\n",
       "   0.9496982097625732,\n",
       "   0.9550637006759644,\n",
       "   0.9570757746696472,\n",
       "   0.9604292511940002,\n",
       "   0.9651240706443787,\n",
       "   0.964453399181366,\n",
       "   0.9711602926254272,\n",
       "   0.975184440612793,\n",
       "   0.9765258431434631],\n",
       "  'val_loss': [1.3896564245224,\n",
       "   1.237679123878479,\n",
       "   1.0387212038040161,\n",
       "   0.8879159688949585,\n",
       "   0.7873713374137878,\n",
       "   0.709676206111908,\n",
       "   0.6557462811470032,\n",
       "   0.6050276756286621,\n",
       "   0.584847629070282,\n",
       "   0.5465857982635498,\n",
       "   0.5375989675521851,\n",
       "   0.5111457705497742,\n",
       "   0.5001335740089417,\n",
       "   0.4772830009460449,\n",
       "   0.471665620803833,\n",
       "   0.45795896649360657,\n",
       "   0.46125903725624084,\n",
       "   0.45677268505096436,\n",
       "   0.45988115668296814,\n",
       "   0.4405643343925476,\n",
       "   0.44080689549446106,\n",
       "   0.445335328578949,\n",
       "   0.4411904215812683,\n",
       "   0.44207385182380676,\n",
       "   0.4453178346157074,\n",
       "   0.4355376064777374,\n",
       "   0.4421464800834656,\n",
       "   0.434134840965271,\n",
       "   0.4384567141532898,\n",
       "   0.44414812326431274],\n",
       "  'val_accuracy': [0.48399999737739563,\n",
       "   0.5360000133514404,\n",
       "   0.6499999761581421,\n",
       "   0.7300000190734863,\n",
       "   0.7680000066757202,\n",
       "   0.7960000038146973,\n",
       "   0.8059999942779541,\n",
       "   0.828000009059906,\n",
       "   0.8299999833106995,\n",
       "   0.8379999995231628,\n",
       "   0.8320000171661377,\n",
       "   0.8360000252723694,\n",
       "   0.828000009059906,\n",
       "   0.8320000171661377,\n",
       "   0.8399999737739563,\n",
       "   0.8379999995231628,\n",
       "   0.8360000252723694,\n",
       "   0.8399999737739563,\n",
       "   0.8420000076293945,\n",
       "   0.8479999899864197,\n",
       "   0.8560000061988831,\n",
       "   0.843999981880188,\n",
       "   0.843999981880188,\n",
       "   0.843999981880188,\n",
       "   0.8460000157356262,\n",
       "   0.8600000143051147,\n",
       "   0.8519999980926514,\n",
       "   0.8600000143051147,\n",
       "   0.8579999804496765,\n",
       "   0.8519999980926514]},\n",
       " 'epochs_30_batch_32': {'loss': [1.5380170345306396,\n",
       "   1.4512368440628052,\n",
       "   1.3709558248519897,\n",
       "   1.2568689584732056,\n",
       "   1.1398160457611084,\n",
       "   1.0219861268997192,\n",
       "   0.9150165319442749,\n",
       "   0.8236855864524841,\n",
       "   0.746864914894104,\n",
       "   0.6787523627281189,\n",
       "   0.6198220252990723,\n",
       "   0.5693807601928711,\n",
       "   0.522795557975769,\n",
       "   0.48347896337509155,\n",
       "   0.44614529609680176,\n",
       "   0.41364410519599915,\n",
       "   0.38596099615097046,\n",
       "   0.3598412275314331,\n",
       "   0.3348045349121094,\n",
       "   0.3124527633190155,\n",
       "   0.29327186942100525,\n",
       "   0.27400919795036316,\n",
       "   0.25694262981414795,\n",
       "   0.23960842192173004,\n",
       "   0.22473444044589996,\n",
       "   0.21082083880901337,\n",
       "   0.19761961698532104,\n",
       "   0.18372683227062225,\n",
       "   0.17315109074115753,\n",
       "   0.1616443693637848],\n",
       "  'accuracy': [0.46747151017189026,\n",
       "   0.48423877358436584,\n",
       "   0.4969818890094757,\n",
       "   0.5378940105438232,\n",
       "   0.5835009813308716,\n",
       "   0.6344735026359558,\n",
       "   0.7015426158905029,\n",
       "   0.7451375126838684,\n",
       "   0.7672702670097351,\n",
       "   0.797451376914978,\n",
       "   0.8182427883148193,\n",
       "   0.838363528251648,\n",
       "   0.8537893891334534,\n",
       "   0.873910129070282,\n",
       "   0.8779342770576477,\n",
       "   0.8873239159584045,\n",
       "   0.9000670909881592,\n",
       "   0.9047619104385376,\n",
       "   0.909456729888916,\n",
       "   0.9195170998573303,\n",
       "   0.9242119193077087,\n",
       "   0.9309188723564148,\n",
       "   0.9369550347328186,\n",
       "   0.9423205852508545,\n",
       "   0.9403085112571716,\n",
       "   0.9523809552192688,\n",
       "   0.9543930292129517,\n",
       "   0.9577465057373047,\n",
       "   0.9617705941200256,\n",
       "   0.9631119966506958],\n",
       "  'val_loss': [1.4325305223464966,\n",
       "   1.375195026397705,\n",
       "   1.2874352931976318,\n",
       "   1.188266396522522,\n",
       "   1.0643463134765625,\n",
       "   0.9611724019050598,\n",
       "   0.8821263909339905,\n",
       "   0.8184967637062073,\n",
       "   0.7601690888404846,\n",
       "   0.7111186981201172,\n",
       "   0.6658563613891602,\n",
       "   0.6321868896484375,\n",
       "   0.600537121295929,\n",
       "   0.5772643089294434,\n",
       "   0.5453433990478516,\n",
       "   0.540025532245636,\n",
       "   0.5170924067497253,\n",
       "   0.502863883972168,\n",
       "   0.49376747012138367,\n",
       "   0.48157238960266113,\n",
       "   0.4741123914718628,\n",
       "   0.4655665457248688,\n",
       "   0.45734259486198425,\n",
       "   0.45581352710723877,\n",
       "   0.4484093189239502,\n",
       "   0.4387071430683136,\n",
       "   0.42791301012039185,\n",
       "   0.4321349263191223,\n",
       "   0.4278619587421417,\n",
       "   0.4274522066116333],\n",
       "  'val_accuracy': [0.48399999737739563,\n",
       "   0.48399999737739563,\n",
       "   0.49399998784065247,\n",
       "   0.5759999752044678,\n",
       "   0.6119999885559082,\n",
       "   0.7059999704360962,\n",
       "   0.7400000095367432,\n",
       "   0.7400000095367432,\n",
       "   0.7879999876022339,\n",
       "   0.7799999713897705,\n",
       "   0.7960000038146973,\n",
       "   0.8019999861717224,\n",
       "   0.8119999766349792,\n",
       "   0.8199999928474426,\n",
       "   0.8339999914169312,\n",
       "   0.8320000171661377,\n",
       "   0.843999981880188,\n",
       "   0.8420000076293945,\n",
       "   0.8360000252723694,\n",
       "   0.8420000076293945,\n",
       "   0.8460000157356262,\n",
       "   0.8420000076293945,\n",
       "   0.843999981880188,\n",
       "   0.8479999899864197,\n",
       "   0.8360000252723694,\n",
       "   0.8519999980926514,\n",
       "   0.8600000143051147,\n",
       "   0.8539999723434448,\n",
       "   0.8600000143051147,\n",
       "   0.8500000238418579]},\n",
       " 'epochs_30_batch_64': {'loss': [1.5834286212921143,\n",
       "   1.4727591276168823,\n",
       "   1.4347951412200928,\n",
       "   1.3835110664367676,\n",
       "   1.319989800453186,\n",
       "   1.247352123260498,\n",
       "   1.1718206405639648,\n",
       "   1.0971771478652954,\n",
       "   1.0230952501296997,\n",
       "   0.9540584683418274,\n",
       "   0.8858916163444519,\n",
       "   0.8280594944953918,\n",
       "   0.7710190415382385,\n",
       "   0.7196425795555115,\n",
       "   0.6746680736541748,\n",
       "   0.6321209669113159,\n",
       "   0.5911182165145874,\n",
       "   0.5552694797515869,\n",
       "   0.5203392505645752,\n",
       "   0.49020645022392273,\n",
       "   0.4606035351753235,\n",
       "   0.43518000841140747,\n",
       "   0.40827980637550354,\n",
       "   0.38494381308555603,\n",
       "   0.3626995086669922,\n",
       "   0.34359946846961975,\n",
       "   0.3240841329097748,\n",
       "   0.3082227110862732,\n",
       "   0.2902573049068451,\n",
       "   0.27585291862487793],\n",
       "  'accuracy': [0.4701542556285858,\n",
       "   0.48423877358436584,\n",
       "   0.48423877358436584,\n",
       "   0.4855801463127136,\n",
       "   0.5003353357315063,\n",
       "   0.5291750431060791,\n",
       "   0.573440670967102,\n",
       "   0.625083863735199,\n",
       "   0.668008029460907,\n",
       "   0.7042253613471985,\n",
       "   0.7310529947280884,\n",
       "   0.7451375126838684,\n",
       "   0.7632461190223694,\n",
       "   0.786720335483551,\n",
       "   0.8088530898094177,\n",
       "   0.8169013857841492,\n",
       "   0.8343393802642822,\n",
       "   0.8484238982200623,\n",
       "   0.8537893891334534,\n",
       "   0.8604962825775146,\n",
       "   0.8759222030639648,\n",
       "   0.8786049485206604,\n",
       "   0.8906773924827576,\n",
       "   0.898725688457489,\n",
       "   0.9067739844322205,\n",
       "   0.9087860584259033,\n",
       "   0.9215291738510132,\n",
       "   0.9215291738510132,\n",
       "   0.923541247844696,\n",
       "   0.9309188723564148],\n",
       "  'val_loss': [1.4412784576416016,\n",
       "   1.4200325012207031,\n",
       "   1.3746017217636108,\n",
       "   1.3242262601852417,\n",
       "   1.27113676071167,\n",
       "   1.1967039108276367,\n",
       "   1.147972822189331,\n",
       "   1.080904245376587,\n",
       "   0.997799813747406,\n",
       "   0.9522712230682373,\n",
       "   0.8972126245498657,\n",
       "   0.8549445271492004,\n",
       "   0.8112635612487793,\n",
       "   0.7813369035720825,\n",
       "   0.7284353375434875,\n",
       "   0.705508828163147,\n",
       "   0.6823036074638367,\n",
       "   0.6490497589111328,\n",
       "   0.6317905187606812,\n",
       "   0.6133823394775391,\n",
       "   0.582313597202301,\n",
       "   0.5753942131996155,\n",
       "   0.5578700304031372,\n",
       "   0.5517717003822327,\n",
       "   0.5232047438621521,\n",
       "   0.527244508266449,\n",
       "   0.5191502571105957,\n",
       "   0.5043967962265015,\n",
       "   0.4956536889076233,\n",
       "   0.49392977356910706],\n",
       "  'val_accuracy': [0.48399999737739563,\n",
       "   0.48399999737739563,\n",
       "   0.48399999737739563,\n",
       "   0.48399999737739563,\n",
       "   0.5019999742507935,\n",
       "   0.5440000295639038,\n",
       "   0.6600000262260437,\n",
       "   0.6840000152587891,\n",
       "   0.6959999799728394,\n",
       "   0.7020000219345093,\n",
       "   0.7059999704360962,\n",
       "   0.7260000109672546,\n",
       "   0.7519999742507935,\n",
       "   0.7620000243186951,\n",
       "   0.7639999985694885,\n",
       "   0.7680000066757202,\n",
       "   0.7799999713897705,\n",
       "   0.7919999957084656,\n",
       "   0.7919999957084656,\n",
       "   0.8019999861717224,\n",
       "   0.8180000185966492,\n",
       "   0.8080000281333923,\n",
       "   0.8320000171661377,\n",
       "   0.8199999928474426,\n",
       "   0.8420000076293945,\n",
       "   0.8240000009536743,\n",
       "   0.828000009059906,\n",
       "   0.8299999833106995,\n",
       "   0.8259999752044678,\n",
       "   0.8259999752044678]},\n",
       " 'epochs_60_batch_16': {'loss': [1.5094571113586426,\n",
       "   1.3786687850952148,\n",
       "   1.2019662857055664,\n",
       "   1.033591628074646,\n",
       "   0.8950765132904053,\n",
       "   0.786314070224762,\n",
       "   0.7017475962638855,\n",
       "   0.6285965442657471,\n",
       "   0.5692281723022461,\n",
       "   0.5166794061660767,\n",
       "   0.4699717164039612,\n",
       "   0.4347690939903259,\n",
       "   0.3985607624053955,\n",
       "   0.37006810307502747,\n",
       "   0.34142306447029114,\n",
       "   0.3172526955604553,\n",
       "   0.295389860868454,\n",
       "   0.2745641767978668,\n",
       "   0.2542894184589386,\n",
       "   0.2374185472726822,\n",
       "   0.22091686725616455,\n",
       "   0.20596235990524292,\n",
       "   0.19070200622081757,\n",
       "   0.17651230096817017,\n",
       "   0.1653977632522583,\n",
       "   0.15219742059707642,\n",
       "   0.1423836648464203,\n",
       "   0.13205833733081818,\n",
       "   0.1226859763264656,\n",
       "   0.11383399367332458,\n",
       "   0.10532117635011673,\n",
       "   0.09809768944978714,\n",
       "   0.09065122902393341,\n",
       "   0.0829877033829689,\n",
       "   0.07749845087528229,\n",
       "   0.07150436192750931,\n",
       "   0.06534916162490845,\n",
       "   0.06089524179697037,\n",
       "   0.05518374219536781,\n",
       "   0.05155709385871887,\n",
       "   0.04698130488395691,\n",
       "   0.04290829598903656,\n",
       "   0.040148042142391205,\n",
       "   0.03699024021625519,\n",
       "   0.03334018960595131,\n",
       "   0.030332379043102264,\n",
       "   0.028220005333423615,\n",
       "   0.02566714771091938,\n",
       "   0.02379225380718708,\n",
       "   0.021280420944094658,\n",
       "   0.019331784918904305,\n",
       "   0.017763029783964157,\n",
       "   0.01625634916126728,\n",
       "   0.014684963971376419,\n",
       "   0.013153612613677979,\n",
       "   0.012019477784633636,\n",
       "   0.010813262313604355,\n",
       "   0.009730802848935127,\n",
       "   0.008777902461588383,\n",
       "   0.00786884967237711],\n",
       "  'accuracy': [0.4748491048812866,\n",
       "   0.49496981501579285,\n",
       "   0.577464759349823,\n",
       "   0.6841046214103699,\n",
       "   0.7317236661911011,\n",
       "   0.7531858086585999,\n",
       "   0.772635817527771,\n",
       "   0.7954393029212952,\n",
       "   0.8242790102958679,\n",
       "   0.8363514542579651,\n",
       "   0.8564721941947937,\n",
       "   0.8752515316009521,\n",
       "   0.8839704990386963,\n",
       "   0.8913480639457703,\n",
       "   0.9121394753456116,\n",
       "   0.9141515493392944,\n",
       "   0.9208585023880005,\n",
       "   0.9262239933013916,\n",
       "   0.9336016178131104,\n",
       "   0.9403085112571716,\n",
       "   0.9423205852508545,\n",
       "   0.9483568072319031,\n",
       "   0.9530516266822815,\n",
       "   0.9590878486633301,\n",
       "   0.9604292511940002,\n",
       "   0.9651240706443787,\n",
       "   0.9671361446380615,\n",
       "   0.9698188900947571,\n",
       "   0.9731723666191101,\n",
       "   0.9731723666191101,\n",
       "   0.9745137691497803,\n",
       "   0.9778671860694885,\n",
       "   0.9805499911308289,\n",
       "   0.9805499911308289,\n",
       "   0.9839034080505371,\n",
       "   0.9832327365875244,\n",
       "   0.98591548204422,\n",
       "   0.9872568845748901,\n",
       "   0.9906103014945984,\n",
       "   0.9906103014945984,\n",
       "   0.9932931065559387,\n",
       "   0.9926223754882812,\n",
       "   0.9939637780189514,\n",
       "   0.9926223754882812,\n",
       "   0.9946344494819641,\n",
       "   0.9946344494819641,\n",
       "   0.9959758520126343,\n",
       "   0.9973172545433044,\n",
       "   0.9973172545433044,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9986585974693298,\n",
       "   0.9979879260063171,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873],\n",
       "  'val_loss': [1.4026185274124146,\n",
       "   1.2733664512634277,\n",
       "   1.087846040725708,\n",
       "   0.9473109245300293,\n",
       "   0.8508201837539673,\n",
       "   0.7688857316970825,\n",
       "   0.7079851627349854,\n",
       "   0.6629452109336853,\n",
       "   0.6265952587127686,\n",
       "   0.5960038304328918,\n",
       "   0.5820248126983643,\n",
       "   0.5495821237564087,\n",
       "   0.5450036525726318,\n",
       "   0.5245200991630554,\n",
       "   0.5195741057395935,\n",
       "   0.5009981393814087,\n",
       "   0.5027587413787842,\n",
       "   0.4971340298652649,\n",
       "   0.4966418445110321,\n",
       "   0.47947797179222107,\n",
       "   0.482094407081604,\n",
       "   0.47416332364082336,\n",
       "   0.4816519021987915,\n",
       "   0.4793641269207001,\n",
       "   0.47337284684181213,\n",
       "   0.47073325514793396,\n",
       "   0.46703165769577026,\n",
       "   0.4726799726486206,\n",
       "   0.46660855412483215,\n",
       "   0.4727734625339508,\n",
       "   0.47259587049484253,\n",
       "   0.4735853672027588,\n",
       "   0.4722123444080353,\n",
       "   0.4733232855796814,\n",
       "   0.4772188365459442,\n",
       "   0.485554575920105,\n",
       "   0.47738438844680786,\n",
       "   0.47554099559783936,\n",
       "   0.4829581081867218,\n",
       "   0.4864243268966675,\n",
       "   0.4915679693222046,\n",
       "   0.4959637224674225,\n",
       "   0.4967661201953888,\n",
       "   0.4983757436275482,\n",
       "   0.5009944438934326,\n",
       "   0.5032103061676025,\n",
       "   0.5120861530303955,\n",
       "   0.5168279409408569,\n",
       "   0.5194526314735413,\n",
       "   0.5227490067481995,\n",
       "   0.524549663066864,\n",
       "   0.5340704917907715,\n",
       "   0.5322265028953552,\n",
       "   0.542876124382019,\n",
       "   0.5489447116851807,\n",
       "   0.551044762134552,\n",
       "   0.5593336224555969,\n",
       "   0.5679284930229187,\n",
       "   0.5732454657554626,\n",
       "   0.5849282145500183],\n",
       "  'val_accuracy': [0.48399999737739563,\n",
       "   0.4959999918937683,\n",
       "   0.6919999718666077,\n",
       "   0.7059999704360962,\n",
       "   0.7620000243186951,\n",
       "   0.765999972820282,\n",
       "   0.7799999713897705,\n",
       "   0.8019999861717224,\n",
       "   0.7940000295639038,\n",
       "   0.8140000104904175,\n",
       "   0.8259999752044678,\n",
       "   0.8320000171661377,\n",
       "   0.8339999914169312,\n",
       "   0.8420000076293945,\n",
       "   0.8360000252723694,\n",
       "   0.843999981880188,\n",
       "   0.8360000252723694,\n",
       "   0.8259999752044678,\n",
       "   0.8320000171661377,\n",
       "   0.8399999737739563,\n",
       "   0.8360000252723694,\n",
       "   0.8320000171661377,\n",
       "   0.8320000171661377,\n",
       "   0.8320000171661377,\n",
       "   0.8360000252723694,\n",
       "   0.843999981880188,\n",
       "   0.843999981880188,\n",
       "   0.843999981880188,\n",
       "   0.8479999899864197,\n",
       "   0.8500000238418579,\n",
       "   0.843999981880188,\n",
       "   0.8500000238418579,\n",
       "   0.8519999980926514,\n",
       "   0.8539999723434448,\n",
       "   0.8500000238418579,\n",
       "   0.8460000157356262,\n",
       "   0.8560000061988831,\n",
       "   0.8519999980926514,\n",
       "   0.8539999723434448,\n",
       "   0.843999981880188,\n",
       "   0.8460000157356262,\n",
       "   0.8539999723434448,\n",
       "   0.8600000143051147,\n",
       "   0.8539999723434448,\n",
       "   0.8500000238418579,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8539999723434448,\n",
       "   0.8539999723434448,\n",
       "   0.8539999723434448,\n",
       "   0.8539999723434448,\n",
       "   0.8539999723434448,\n",
       "   0.8579999804496765,\n",
       "   0.8560000061988831,\n",
       "   0.8579999804496765,\n",
       "   0.8539999723434448,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831]},\n",
       " 'epochs_60_batch_32': {'loss': [1.5297359228134155,\n",
       "   1.4496948719024658,\n",
       "   1.3637301921844482,\n",
       "   1.2526767253875732,\n",
       "   1.1303956508636475,\n",
       "   1.0192233324050903,\n",
       "   0.9223145842552185,\n",
       "   0.8368382453918457,\n",
       "   0.7663524150848389,\n",
       "   0.7046361565589905,\n",
       "   0.6494121551513672,\n",
       "   0.6031938791275024,\n",
       "   0.5623385310173035,\n",
       "   0.5248242616653442,\n",
       "   0.4909946620464325,\n",
       "   0.46048450469970703,\n",
       "   0.4331240653991699,\n",
       "   0.4070774018764496,\n",
       "   0.3835991322994232,\n",
       "   0.36042118072509766,\n",
       "   0.34054431319236755,\n",
       "   0.32099011540412903,\n",
       "   0.303268164396286,\n",
       "   0.28496089577674866,\n",
       "   0.26906225085258484,\n",
       "   0.25253206491470337,\n",
       "   0.23831631243228912,\n",
       "   0.22381547093391418,\n",
       "   0.2104911506175995,\n",
       "   0.19819431006908417,\n",
       "   0.1857040673494339,\n",
       "   0.17385323345661163,\n",
       "   0.16360175609588623,\n",
       "   0.15333038568496704,\n",
       "   0.14239810407161713,\n",
       "   0.13368235528469086,\n",
       "   0.12509343028068542,\n",
       "   0.1165621429681778,\n",
       "   0.10938925296068192,\n",
       "   0.10136517882347107,\n",
       "   0.09413199126720428,\n",
       "   0.08812624961137772,\n",
       "   0.08197468519210815,\n",
       "   0.0758565366268158,\n",
       "   0.07142537087202072,\n",
       "   0.06553462892770767,\n",
       "   0.061117708683013916,\n",
       "   0.05621737986803055,\n",
       "   0.0525340661406517,\n",
       "   0.04845983535051346,\n",
       "   0.04465777799487114,\n",
       "   0.0413169302046299,\n",
       "   0.0382319837808609,\n",
       "   0.03472534939646721,\n",
       "   0.03221018612384796,\n",
       "   0.029827985912561417,\n",
       "   0.027482634410262108,\n",
       "   0.024984246119856834,\n",
       "   0.022913653403520584,\n",
       "   0.021026577800512314],\n",
       "  'accuracy': [0.4714956283569336,\n",
       "   0.48423877358436584,\n",
       "   0.4983232617378235,\n",
       "   0.5372233390808105,\n",
       "   0.5881958603858948,\n",
       "   0.65727698802948,\n",
       "   0.7062374353408813,\n",
       "   0.7344064116477966,\n",
       "   0.7625754475593567,\n",
       "   0.786720335483551,\n",
       "   0.8034875988960266,\n",
       "   0.8262910842895508,\n",
       "   0.8329979777336121,\n",
       "   0.8504359722137451,\n",
       "   0.8544601202011108,\n",
       "   0.8678739070892334,\n",
       "   0.8853118419647217,\n",
       "   0.8900067210197449,\n",
       "   0.8980550169944763,\n",
       "   0.902079164981842,\n",
       "   0.9061033129692078,\n",
       "   0.9168343544006348,\n",
       "   0.9181756973266602,\n",
       "   0.9248826503753662,\n",
       "   0.9315895438194275,\n",
       "   0.9396378397941589,\n",
       "   0.9436619877815247,\n",
       "   0.9436619877815247,\n",
       "   0.9496982097625732,\n",
       "   0.9564051032066345,\n",
       "   0.9577465057373047,\n",
       "   0.9590878486633301,\n",
       "   0.9637826681137085,\n",
       "   0.9664654731750488,\n",
       "   0.9725016951560974,\n",
       "   0.975184440612793,\n",
       "   0.978537917137146,\n",
       "   0.9805499911308289,\n",
       "   0.9805499911308289,\n",
       "   0.9839034080505371,\n",
       "   0.9845741391181946,\n",
       "   0.9852448105812073,\n",
       "   0.9879275560379028,\n",
       "   0.9899396300315857,\n",
       "   0.9885982275009155,\n",
       "   0.9926223754882812,\n",
       "   0.9912810325622559,\n",
       "   0.9939637780189514,\n",
       "   0.9932931065559387,\n",
       "   0.9939637780189514,\n",
       "   0.9946344494819641,\n",
       "   0.996646523475647,\n",
       "   0.996646523475647,\n",
       "   0.996646523475647,\n",
       "   0.9979879260063171,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298],\n",
       "  'val_loss': [1.4357699155807495,\n",
       "   1.3748842477798462,\n",
       "   1.2961384057998657,\n",
       "   1.1586406230926514,\n",
       "   1.0538854598999023,\n",
       "   0.9728118777275085,\n",
       "   0.8852512836456299,\n",
       "   0.8131642937660217,\n",
       "   0.7635672092437744,\n",
       "   0.7249712944030762,\n",
       "   0.696304440498352,\n",
       "   0.6569488644599915,\n",
       "   0.6266885995864868,\n",
       "   0.6135329008102417,\n",
       "   0.6041788458824158,\n",
       "   0.577346682548523,\n",
       "   0.5526357293128967,\n",
       "   0.5316777229309082,\n",
       "   0.5390452146530151,\n",
       "   0.5254948139190674,\n",
       "   0.5098271369934082,\n",
       "   0.4951668977737427,\n",
       "   0.49350693821907043,\n",
       "   0.4898624122142792,\n",
       "   0.48519518971443176,\n",
       "   0.4718514084815979,\n",
       "   0.46344754099845886,\n",
       "   0.4629645347595215,\n",
       "   0.4594729244709015,\n",
       "   0.4571754038333893,\n",
       "   0.44799911975860596,\n",
       "   0.4530438780784607,\n",
       "   0.4442134201526642,\n",
       "   0.4470371603965759,\n",
       "   0.44133585691452026,\n",
       "   0.45229578018188477,\n",
       "   0.44246232509613037,\n",
       "   0.4366511106491089,\n",
       "   0.4349334239959717,\n",
       "   0.4279339611530304,\n",
       "   0.4395488202571869,\n",
       "   0.4294286072254181,\n",
       "   0.4337112307548523,\n",
       "   0.43824315071105957,\n",
       "   0.430741548538208,\n",
       "   0.4373536705970764,\n",
       "   0.43697690963745117,\n",
       "   0.4332346022129059,\n",
       "   0.43981194496154785,\n",
       "   0.43560895323753357,\n",
       "   0.44061923027038574,\n",
       "   0.44897130131721497,\n",
       "   0.4428021013736725,\n",
       "   0.45050734281539917,\n",
       "   0.4551260769367218,\n",
       "   0.4601539969444275,\n",
       "   0.45263534784317017,\n",
       "   0.4560757279396057,\n",
       "   0.46333396434783936,\n",
       "   0.45776596665382385],\n",
       "  'val_accuracy': [0.48399999737739563,\n",
       "   0.48399999737739563,\n",
       "   0.49799999594688416,\n",
       "   0.5640000104904175,\n",
       "   0.6499999761581421,\n",
       "   0.7120000123977661,\n",
       "   0.7039999961853027,\n",
       "   0.7360000014305115,\n",
       "   0.7459999918937683,\n",
       "   0.7839999794960022,\n",
       "   0.7900000214576721,\n",
       "   0.7940000295639038,\n",
       "   0.8180000185966492,\n",
       "   0.8119999766349792,\n",
       "   0.800000011920929,\n",
       "   0.8259999752044678,\n",
       "   0.828000009059906,\n",
       "   0.8320000171661377,\n",
       "   0.8199999928474426,\n",
       "   0.8339999914169312,\n",
       "   0.8379999995231628,\n",
       "   0.8460000157356262,\n",
       "   0.8399999737739563,\n",
       "   0.8379999995231628,\n",
       "   0.8360000252723694,\n",
       "   0.8420000076293945,\n",
       "   0.8479999899864197,\n",
       "   0.8519999980926514,\n",
       "   0.8519999980926514,\n",
       "   0.8500000238418579,\n",
       "   0.8600000143051147,\n",
       "   0.8579999804496765,\n",
       "   0.8619999885559082,\n",
       "   0.843999981880188,\n",
       "   0.8579999804496765,\n",
       "   0.8379999995231628,\n",
       "   0.8539999723434448,\n",
       "   0.8640000224113464,\n",
       "   0.8519999980926514,\n",
       "   0.8579999804496765,\n",
       "   0.8640000224113464,\n",
       "   0.8619999885559082,\n",
       "   0.8579999804496765,\n",
       "   0.8560000061988831,\n",
       "   0.8579999804496765,\n",
       "   0.8619999885559082,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8619999885559082,\n",
       "   0.8600000143051147,\n",
       "   0.8539999723434448,\n",
       "   0.8560000061988831,\n",
       "   0.8579999804496765,\n",
       "   0.8679999709129333,\n",
       "   0.8519999980926514,\n",
       "   0.8519999980926514,\n",
       "   0.8579999804496765,\n",
       "   0.8659999966621399,\n",
       "   0.8500000238418579,\n",
       "   0.8740000128746033]},\n",
       " 'epochs_60_batch_64': {'loss': [1.567862629890442,\n",
       "   1.463407278060913,\n",
       "   1.4253648519515991,\n",
       "   1.3670985698699951,\n",
       "   1.2984790802001953,\n",
       "   1.2252148389816284,\n",
       "   1.1477948427200317,\n",
       "   1.0739023685455322,\n",
       "   1.0007528066635132,\n",
       "   0.9314504265785217,\n",
       "   0.867199182510376,\n",
       "   0.8093429803848267,\n",
       "   0.7545014023780823,\n",
       "   0.7098790407180786,\n",
       "   0.6660866141319275,\n",
       "   0.6247389912605286,\n",
       "   0.5910405516624451,\n",
       "   0.5548931956291199,\n",
       "   0.5243872404098511,\n",
       "   0.4970216453075409,\n",
       "   0.47182366251945496,\n",
       "   0.44578075408935547,\n",
       "   0.422096312046051,\n",
       "   0.40234634280204773,\n",
       "   0.3809860646724701,\n",
       "   0.36204782128334045,\n",
       "   0.34422674775123596,\n",
       "   0.3267340362071991,\n",
       "   0.31152427196502686,\n",
       "   0.2945673167705536,\n",
       "   0.2805761694908142,\n",
       "   0.26666268706321716,\n",
       "   0.25465789437294006,\n",
       "   0.24180534482002258,\n",
       "   0.2294701635837555,\n",
       "   0.21920627355575562,\n",
       "   0.2077513486146927,\n",
       "   0.1968880295753479,\n",
       "   0.18659833073616028,\n",
       "   0.17937356233596802,\n",
       "   0.16859860718250275,\n",
       "   0.16168193519115448,\n",
       "   0.15190644562244415,\n",
       "   0.14463859796524048,\n",
       "   0.13741011917591095,\n",
       "   0.1298966258764267,\n",
       "   0.12356597930192947,\n",
       "   0.11662314087152481,\n",
       "   0.11077938973903656,\n",
       "   0.10414642095565796,\n",
       "   0.09860970079898834,\n",
       "   0.09314945340156555,\n",
       "   0.08799072355031967,\n",
       "   0.08374888449907303,\n",
       "   0.07878565788269043,\n",
       "   0.07435063272714615,\n",
       "   0.07029105722904205,\n",
       "   0.06625500321388245,\n",
       "   0.062216151505708694,\n",
       "   0.059181127697229385],\n",
       "  'accuracy': [0.4600938856601715,\n",
       "   0.48423877358436584,\n",
       "   0.48423877358436584,\n",
       "   0.4869215190410614,\n",
       "   0.5090543031692505,\n",
       "   0.5399060845375061,\n",
       "   0.5855130553245544,\n",
       "   0.6425217986106873,\n",
       "   0.6867873668670654,\n",
       "   0.7129443287849426,\n",
       "   0.7323943376541138,\n",
       "   0.758551299571991,\n",
       "   0.7793427109718323,\n",
       "   0.7880616784095764,\n",
       "   0.8061703443527222,\n",
       "   0.818913459777832,\n",
       "   0.8316566348075867,\n",
       "   0.8464118242263794,\n",
       "   0.849094569683075,\n",
       "   0.8571428656578064,\n",
       "   0.8672032356262207,\n",
       "   0.8765928745269775,\n",
       "   0.8826290965080261,\n",
       "   0.8940308690071106,\n",
       "   0.898725688457489,\n",
       "   0.9047619104385376,\n",
       "   0.9081153869628906,\n",
       "   0.9154929518699646,\n",
       "   0.923541247844696,\n",
       "   0.9289067983627319,\n",
       "   0.9302481412887573,\n",
       "   0.9336016178131104,\n",
       "   0.9409791827201843,\n",
       "   0.9443326592445374,\n",
       "   0.9476861357688904,\n",
       "   0.9476861357688904,\n",
       "   0.9550637006759644,\n",
       "   0.9557344317436218,\n",
       "   0.953722357749939,\n",
       "   0.9564051032066345,\n",
       "   0.9604292511940002,\n",
       "   0.9637826681137085,\n",
       "   0.9671361446380615,\n",
       "   0.9684775471687317,\n",
       "   0.9718309640884399,\n",
       "   0.9778671860694885,\n",
       "   0.9738430380821228,\n",
       "   0.9778671860694885,\n",
       "   0.9778671860694885,\n",
       "   0.9832327365875244,\n",
       "   0.9832327365875244,\n",
       "   0.98591548204422,\n",
       "   0.9852448105812073,\n",
       "   0.9879275560379028,\n",
       "   0.9879275560379028,\n",
       "   0.9899396300315857,\n",
       "   0.9906103014945984,\n",
       "   0.9912810325622559,\n",
       "   0.9926223754882812,\n",
       "   0.9926223754882812],\n",
       "  'val_loss': [1.458471417427063,\n",
       "   1.4173678159713745,\n",
       "   1.3732789754867554,\n",
       "   1.3024755716323853,\n",
       "   1.241981863975525,\n",
       "   1.1729387044906616,\n",
       "   1.0987656116485596,\n",
       "   1.033008098602295,\n",
       "   0.9872032403945923,\n",
       "   0.9256130456924438,\n",
       "   0.8715489506721497,\n",
       "   0.8263775706291199,\n",
       "   0.787236213684082,\n",
       "   0.7515159845352173,\n",
       "   0.7239123582839966,\n",
       "   0.6835353374481201,\n",
       "   0.6635305285453796,\n",
       "   0.6375418901443481,\n",
       "   0.6284961700439453,\n",
       "   0.6008249521255493,\n",
       "   0.5867269039154053,\n",
       "   0.5766870975494385,\n",
       "   0.5751822590827942,\n",
       "   0.5533763766288757,\n",
       "   0.5350918769836426,\n",
       "   0.5219261646270752,\n",
       "   0.5093234181404114,\n",
       "   0.5245115160942078,\n",
       "   0.506491482257843,\n",
       "   0.49325016140937805,\n",
       "   0.4960334300994873,\n",
       "   0.48607829213142395,\n",
       "   0.4796070158481598,\n",
       "   0.4809427857398987,\n",
       "   0.46984344720840454,\n",
       "   0.46252891421318054,\n",
       "   0.4689315855503082,\n",
       "   0.4539644420146942,\n",
       "   0.46030694246292114,\n",
       "   0.4601578116416931,\n",
       "   0.44572019577026367,\n",
       "   0.4454149901866913,\n",
       "   0.4394354224205017,\n",
       "   0.4553379416465759,\n",
       "   0.4489809572696686,\n",
       "   0.43540817499160767,\n",
       "   0.4339684545993805,\n",
       "   0.433940052986145,\n",
       "   0.4323384761810303,\n",
       "   0.43035078048706055,\n",
       "   0.4299321174621582,\n",
       "   0.42912977933883667,\n",
       "   0.4266234040260315,\n",
       "   0.4285174608230591,\n",
       "   0.4381324350833893,\n",
       "   0.42685502767562866,\n",
       "   0.43015947937965393,\n",
       "   0.42956894636154175,\n",
       "   0.42883753776550293,\n",
       "   0.4317978322505951],\n",
       "  'val_accuracy': [0.48399999737739563,\n",
       "   0.48399999737739563,\n",
       "   0.48399999737739563,\n",
       "   0.5059999823570251,\n",
       "   0.5,\n",
       "   0.5580000281333923,\n",
       "   0.6620000004768372,\n",
       "   0.6539999842643738,\n",
       "   0.6740000247955322,\n",
       "   0.7099999785423279,\n",
       "   0.7379999756813049,\n",
       "   0.7419999837875366,\n",
       "   0.7620000243186951,\n",
       "   0.7960000038146973,\n",
       "   0.7900000214576721,\n",
       "   0.8100000023841858,\n",
       "   0.8159999847412109,\n",
       "   0.8259999752044678,\n",
       "   0.8379999995231628,\n",
       "   0.8320000171661377,\n",
       "   0.8299999833106995,\n",
       "   0.8360000252723694,\n",
       "   0.843999981880188,\n",
       "   0.8539999723434448,\n",
       "   0.8519999980926514,\n",
       "   0.8560000061988831,\n",
       "   0.8579999804496765,\n",
       "   0.8379999995231628,\n",
       "   0.8479999899864197,\n",
       "   0.8460000157356262,\n",
       "   0.8420000076293945,\n",
       "   0.8460000157356262,\n",
       "   0.8519999980926514,\n",
       "   0.8420000076293945,\n",
       "   0.843999981880188,\n",
       "   0.843999981880188,\n",
       "   0.843999981880188,\n",
       "   0.8519999980926514,\n",
       "   0.8420000076293945,\n",
       "   0.8379999995231628,\n",
       "   0.8479999899864197,\n",
       "   0.843999981880188,\n",
       "   0.8519999980926514,\n",
       "   0.8339999914169312,\n",
       "   0.8339999914169312,\n",
       "   0.8519999980926514,\n",
       "   0.8479999899864197,\n",
       "   0.8500000238418579,\n",
       "   0.8479999899864197,\n",
       "   0.8519999980926514,\n",
       "   0.8539999723434448,\n",
       "   0.8600000143051147,\n",
       "   0.8560000061988831,\n",
       "   0.8519999980926514,\n",
       "   0.843999981880188,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8539999723434448,\n",
       "   0.8579999804496765]},\n",
       " 'epochs_90_batch_16': {'loss': [1.5128486156463623,\n",
       "   1.3780568838119507,\n",
       "   1.189832329750061,\n",
       "   1.0068013668060303,\n",
       "   0.8643897175788879,\n",
       "   0.756514847278595,\n",
       "   0.6715860366821289,\n",
       "   0.6034512519836426,\n",
       "   0.5442119836807251,\n",
       "   0.49357834458351135,\n",
       "   0.44996967911720276,\n",
       "   0.41106173396110535,\n",
       "   0.3777433931827545,\n",
       "   0.34725555777549744,\n",
       "   0.32037708163261414,\n",
       "   0.2952321171760559,\n",
       "   0.2739829421043396,\n",
       "   0.2523999512195587,\n",
       "   0.23426415026187897,\n",
       "   0.21611478924751282,\n",
       "   0.20093552768230438,\n",
       "   0.18627479672431946,\n",
       "   0.17257367074489594,\n",
       "   0.16051974892616272,\n",
       "   0.1473759263753891,\n",
       "   0.1372569352388382,\n",
       "   0.12714408338069916,\n",
       "   0.11808550357818604,\n",
       "   0.10914305597543716,\n",
       "   0.1002340242266655,\n",
       "   0.09296988695859909,\n",
       "   0.08517705649137497,\n",
       "   0.07979327440261841,\n",
       "   0.07377851009368896,\n",
       "   0.06762239336967468,\n",
       "   0.06253297626972198,\n",
       "   0.05726541206240654,\n",
       "   0.05267907679080963,\n",
       "   0.048276983201503754,\n",
       "   0.044492848217487335,\n",
       "   0.04155823215842247,\n",
       "   0.03786776214838028,\n",
       "   0.03423846885561943,\n",
       "   0.03160882741212845,\n",
       "   0.029305914416909218,\n",
       "   0.02671036683022976,\n",
       "   0.024889305233955383,\n",
       "   0.02195795066654682,\n",
       "   0.0200304314494133,\n",
       "   0.01850196346640587,\n",
       "   0.01692315563559532,\n",
       "   0.01512797549366951,\n",
       "   0.013121623545885086,\n",
       "   0.012032249942421913,\n",
       "   0.010524326004087925,\n",
       "   0.00975826382637024,\n",
       "   0.008868612349033356,\n",
       "   0.007997232489287853,\n",
       "   0.007178463973104954,\n",
       "   0.006482836324721575,\n",
       "   0.005796842277050018,\n",
       "   0.005074538756161928,\n",
       "   0.0042660715989768505,\n",
       "   0.0040819537825882435,\n",
       "   0.0035399070475250483,\n",
       "   0.003202342428267002,\n",
       "   0.00287857698276639,\n",
       "   0.00257395813241601,\n",
       "   0.0021011221688240767,\n",
       "   0.002126164035871625,\n",
       "   0.0016888788668438792,\n",
       "   0.0015848426846787333,\n",
       "   0.001502417610026896,\n",
       "   0.001130764838308096,\n",
       "   0.0010196224320679903,\n",
       "   0.0009074648260138929,\n",
       "   0.0007858671597205102,\n",
       "   0.0006720362580381334,\n",
       "   0.0006199827184900641,\n",
       "   0.000545597868040204,\n",
       "   0.0005238860030658543,\n",
       "   0.0004161818651482463,\n",
       "   0.0003661058726720512,\n",
       "   0.00031801845761947334,\n",
       "   0.00026221381267532706,\n",
       "   0.00024375026987399906,\n",
       "   0.00020451414457056671,\n",
       "   0.00017565306916367263,\n",
       "   0.0001645802112761885,\n",
       "   0.00015340717800427228],\n",
       "  'accuracy': [0.4775318503379822,\n",
       "   0.48960429430007935,\n",
       "   0.5888665318489075,\n",
       "   0.6981891393661499,\n",
       "   0.7384305596351624,\n",
       "   0.7672702670097351,\n",
       "   0.7900737524032593,\n",
       "   0.8054996728897095,\n",
       "   0.8289738297462463,\n",
       "   0.8497652411460876,\n",
       "   0.8692153096199036,\n",
       "   0.877263605594635,\n",
       "   0.8947015404701233,\n",
       "   0.902079164981842,\n",
       "   0.9114688038825989,\n",
       "   0.9215291738510132,\n",
       "   0.9248826503753662,\n",
       "   0.9322602152824402,\n",
       "   0.9356136918067932,\n",
       "   0.9423205852508545,\n",
       "   0.9483568072319031,\n",
       "   0.9543930292129517,\n",
       "   0.9543930292129517,\n",
       "   0.9590878486633301,\n",
       "   0.9617705941200256,\n",
       "   0.9678068161010742,\n",
       "   0.9725016951560974,\n",
       "   0.9731723666191101,\n",
       "   0.9758551120758057,\n",
       "   0.978537917137146,\n",
       "   0.9805499911308289,\n",
       "   0.9818913340568542,\n",
       "   0.9839034080505371,\n",
       "   0.9865862131118774,\n",
       "   0.9885982275009155,\n",
       "   0.989268958568573,\n",
       "   0.9906103014945984,\n",
       "   0.9919517040252686,\n",
       "   0.9932931065559387,\n",
       "   0.9932931065559387,\n",
       "   0.9932931065559387,\n",
       "   0.9953051805496216,\n",
       "   0.9953051805496216,\n",
       "   0.9946344494819641,\n",
       "   0.9939637780189514,\n",
       "   0.9959758520126343,\n",
       "   0.9959758520126343,\n",
       "   0.996646523475647,\n",
       "   0.996646523475647,\n",
       "   0.996646523475647,\n",
       "   0.9973172545433044,\n",
       "   0.9973172545433044,\n",
       "   0.9979879260063171,\n",
       "   0.9986585974693298,\n",
       "   0.9979879260063171,\n",
       "   0.9986585974693298,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9986585974693298,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'val_loss': [1.4012011289596558,\n",
       "   1.2608624696731567,\n",
       "   1.080249309539795,\n",
       "   0.9248283505439758,\n",
       "   0.8234073519706726,\n",
       "   0.7346464395523071,\n",
       "   0.6706572771072388,\n",
       "   0.6356008052825928,\n",
       "   0.5863156914710999,\n",
       "   0.5539833307266235,\n",
       "   0.5355347394943237,\n",
       "   0.5138024687767029,\n",
       "   0.500082790851593,\n",
       "   0.4815252423286438,\n",
       "   0.4682064950466156,\n",
       "   0.4579014480113983,\n",
       "   0.44792816042900085,\n",
       "   0.44679349660873413,\n",
       "   0.438219279050827,\n",
       "   0.4362727403640747,\n",
       "   0.4348776638507843,\n",
       "   0.4324587285518646,\n",
       "   0.4269901514053345,\n",
       "   0.42948266863822937,\n",
       "   0.42042943835258484,\n",
       "   0.424452543258667,\n",
       "   0.42176103591918945,\n",
       "   0.41829779744148254,\n",
       "   0.4229587912559509,\n",
       "   0.4251340627670288,\n",
       "   0.42045730352401733,\n",
       "   0.42203837633132935,\n",
       "   0.4152679145336151,\n",
       "   0.42152929306030273,\n",
       "   0.4257064759731293,\n",
       "   0.4228399991989136,\n",
       "   0.4243035316467285,\n",
       "   0.42795440554618835,\n",
       "   0.42287594079971313,\n",
       "   0.4347040355205536,\n",
       "   0.42639750242233276,\n",
       "   0.4346840977668762,\n",
       "   0.4278612732887268,\n",
       "   0.4350314140319824,\n",
       "   0.43535980582237244,\n",
       "   0.45068588852882385,\n",
       "   0.4434037506580353,\n",
       "   0.44688186049461365,\n",
       "   0.451438844203949,\n",
       "   0.453231543302536,\n",
       "   0.46610227227211,\n",
       "   0.45700204372406006,\n",
       "   0.4711410105228424,\n",
       "   0.46126094460487366,\n",
       "   0.4743834137916565,\n",
       "   0.4772273004055023,\n",
       "   0.47409817576408386,\n",
       "   0.4896160364151001,\n",
       "   0.49395090341567993,\n",
       "   0.4910915493965149,\n",
       "   0.49968868494033813,\n",
       "   0.5103050470352173,\n",
       "   0.519760012626648,\n",
       "   0.5113091468811035,\n",
       "   0.5227680206298828,\n",
       "   0.5223174095153809,\n",
       "   0.5323629379272461,\n",
       "   0.5311935544013977,\n",
       "   0.5406587719917297,\n",
       "   0.5512346625328064,\n",
       "   0.5567978024482727,\n",
       "   0.5695636868476868,\n",
       "   0.5684664845466614,\n",
       "   0.5668887495994568,\n",
       "   0.5830801725387573,\n",
       "   0.5840333700180054,\n",
       "   0.5946011543273926,\n",
       "   0.6014904975891113,\n",
       "   0.6050359010696411,\n",
       "   0.6147031784057617,\n",
       "   0.6305233240127563,\n",
       "   0.6242934465408325,\n",
       "   0.6379936337471008,\n",
       "   0.6532344818115234,\n",
       "   0.6496173143386841,\n",
       "   0.6648274064064026,\n",
       "   0.6719706058502197,\n",
       "   0.6871377825737,\n",
       "   0.6782609820365906,\n",
       "   0.691997766494751],\n",
       "  'val_accuracy': [0.48399999737739563,\n",
       "   0.4959999918937683,\n",
       "   0.6259999871253967,\n",
       "   0.7160000205039978,\n",
       "   0.7580000162124634,\n",
       "   0.7680000066757202,\n",
       "   0.7799999713897705,\n",
       "   0.8080000281333923,\n",
       "   0.8100000023841858,\n",
       "   0.8220000267028809,\n",
       "   0.828000009059906,\n",
       "   0.8460000157356262,\n",
       "   0.8379999995231628,\n",
       "   0.8399999737739563,\n",
       "   0.8479999899864197,\n",
       "   0.8519999980926514,\n",
       "   0.8479999899864197,\n",
       "   0.8519999980926514,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8640000224113464,\n",
       "   0.8539999723434448,\n",
       "   0.8579999804496765,\n",
       "   0.8659999966621399,\n",
       "   0.8600000143051147,\n",
       "   0.8579999804496765,\n",
       "   0.8619999885559082,\n",
       "   0.8640000224113464,\n",
       "   0.8600000143051147,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8579999804496765,\n",
       "   0.8600000143051147,\n",
       "   0.8640000224113464,\n",
       "   0.8640000224113464,\n",
       "   0.8679999709129333,\n",
       "   0.8619999885559082,\n",
       "   0.8679999709129333,\n",
       "   0.8659999966621399,\n",
       "   0.8740000128746033,\n",
       "   0.8679999709129333,\n",
       "   0.8700000047683716,\n",
       "   0.8640000224113464,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8640000224113464,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8560000061988831,\n",
       "   0.8659999966621399,\n",
       "   0.8640000224113464,\n",
       "   0.8679999709129333,\n",
       "   0.8659999966621399,\n",
       "   0.8600000143051147,\n",
       "   0.8619999885559082,\n",
       "   0.8679999709129333,\n",
       "   0.8640000224113464,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8679999709129333,\n",
       "   0.8659999966621399,\n",
       "   0.8700000047683716,\n",
       "   0.8679999709129333,\n",
       "   0.871999979019165,\n",
       "   0.8679999709129333,\n",
       "   0.8679999709129333,\n",
       "   0.8700000047683716,\n",
       "   0.8679999709129333,\n",
       "   0.8700000047683716,\n",
       "   0.8679999709129333,\n",
       "   0.871999979019165,\n",
       "   0.8700000047683716,\n",
       "   0.871999979019165,\n",
       "   0.871999979019165,\n",
       "   0.8700000047683716,\n",
       "   0.8740000128746033,\n",
       "   0.8759999871253967,\n",
       "   0.8700000047683716,\n",
       "   0.8759999871253967,\n",
       "   0.871999979019165,\n",
       "   0.871999979019165,\n",
       "   0.8679999709129333,\n",
       "   0.8679999709129333,\n",
       "   0.8759999871253967,\n",
       "   0.8700000047683716]},\n",
       " 'epochs_90_batch_32': {'loss': [1.5404114723205566,\n",
       "   1.4390310049057007,\n",
       "   1.3418803215026855,\n",
       "   1.222591519355774,\n",
       "   1.0984699726104736,\n",
       "   0.9890921711921692,\n",
       "   0.8891593217849731,\n",
       "   0.8088298439979553,\n",
       "   0.7378073930740356,\n",
       "   0.6749857664108276,\n",
       "   0.6215720176696777,\n",
       "   0.5731396675109863,\n",
       "   0.5294885635375977,\n",
       "   0.4907025694847107,\n",
       "   0.4552057981491089,\n",
       "   0.426029235124588,\n",
       "   0.39549168944358826,\n",
       "   0.36984843015670776,\n",
       "   0.3447425365447998,\n",
       "   0.3232716917991638,\n",
       "   0.30227527022361755,\n",
       "   0.28250229358673096,\n",
       "   0.2656477987766266,\n",
       "   0.2487405240535736,\n",
       "   0.23321093618869781,\n",
       "   0.21731139719486237,\n",
       "   0.20471815764904022,\n",
       "   0.1916210949420929,\n",
       "   0.17946314811706543,\n",
       "   0.1685425490140915,\n",
       "   0.15790054202079773,\n",
       "   0.14749525487422943,\n",
       "   0.13814260065555573,\n",
       "   0.12940287590026855,\n",
       "   0.12107624113559723,\n",
       "   0.11356459558010101,\n",
       "   0.10569919645786285,\n",
       "   0.09863423556089401,\n",
       "   0.09182292968034744,\n",
       "   0.08622041344642639,\n",
       "   0.08023619651794434,\n",
       "   0.07467564195394516,\n",
       "   0.069825179874897,\n",
       "   0.06461572647094727,\n",
       "   0.059901103377342224,\n",
       "   0.056096531450748444,\n",
       "   0.052123818546533585,\n",
       "   0.04804176464676857,\n",
       "   0.044824011623859406,\n",
       "   0.04143324866890907,\n",
       "   0.038273438811302185,\n",
       "   0.03533511608839035,\n",
       "   0.032932065427303314,\n",
       "   0.03062145598232746,\n",
       "   0.027871130034327507,\n",
       "   0.02595745399594307,\n",
       "   0.023851534351706505,\n",
       "   0.02175602689385414,\n",
       "   0.020279590040445328,\n",
       "   0.018561849370598793,\n",
       "   0.01709313690662384,\n",
       "   0.015341398306190968,\n",
       "   0.014173345640301704,\n",
       "   0.01312972605228424,\n",
       "   0.012065090239048004,\n",
       "   0.010865620337426662,\n",
       "   0.00997646152973175,\n",
       "   0.0090827327221632,\n",
       "   0.00824067834764719,\n",
       "   0.007547641638666391,\n",
       "   0.006824822165071964,\n",
       "   0.006092907395213842,\n",
       "   0.005734076723456383,\n",
       "   0.0050233351066708565,\n",
       "   0.0045516612008214,\n",
       "   0.004156976938247681,\n",
       "   0.003814408788457513,\n",
       "   0.003313979133963585,\n",
       "   0.0030019485857337713,\n",
       "   0.002685507293790579,\n",
       "   0.0024220033083111048,\n",
       "   0.002263421891257167,\n",
       "   0.002018179278820753,\n",
       "   0.0017223898321390152,\n",
       "   0.0016480310587212443,\n",
       "   0.0014164956519380212,\n",
       "   0.0012654719175770879,\n",
       "   0.0011240595486015081,\n",
       "   0.0010703009320423007,\n",
       "   0.0008977081743068993],\n",
       "  'accuracy': [0.47283703088760376,\n",
       "   0.48423877358436584,\n",
       "   0.49966466426849365,\n",
       "   0.5513078570365906,\n",
       "   0.6532528400421143,\n",
       "   0.6988598108291626,\n",
       "   0.7310529947280884,\n",
       "   0.7505030035972595,\n",
       "   0.7679409980773926,\n",
       "   0.7826961874961853,\n",
       "   0.8034875988960266,\n",
       "   0.8236083388328552,\n",
       "   0.8343393802642822,\n",
       "   0.8591549396514893,\n",
       "   0.8672032356262207,\n",
       "   0.8765928745269775,\n",
       "   0.8826290965080261,\n",
       "   0.8906773924827576,\n",
       "   0.9014084339141846,\n",
       "   0.9087860584259033,\n",
       "   0.9188464283943176,\n",
       "   0.9221998453140259,\n",
       "   0.9289067983627319,\n",
       "   0.934272289276123,\n",
       "   0.9382964372634888,\n",
       "   0.9476861357688904,\n",
       "   0.9503688812255859,\n",
       "   0.9517102837562561,\n",
       "   0.9557344317436218,\n",
       "   0.964453399181366,\n",
       "   0.9651240706443787,\n",
       "   0.9704896211624146,\n",
       "   0.9758551120758057,\n",
       "   0.9765258431434631,\n",
       "   0.9771965146064758,\n",
       "   0.9798792600631714,\n",
       "   0.9825620651245117,\n",
       "   0.9832327365875244,\n",
       "   0.98591548204422,\n",
       "   0.9879275560379028,\n",
       "   0.98591548204422,\n",
       "   0.9885982275009155,\n",
       "   0.989268958568573,\n",
       "   0.9899396300315857,\n",
       "   0.9919517040252686,\n",
       "   0.9912810325622559,\n",
       "   0.9932931065559387,\n",
       "   0.9932931065559387,\n",
       "   0.9932931065559387,\n",
       "   0.9953051805496216,\n",
       "   0.996646523475647,\n",
       "   0.9973172545433044,\n",
       "   0.9973172545433044,\n",
       "   0.9973172545433044,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'val_loss': [1.425669550895691,\n",
       "   1.352759599685669,\n",
       "   1.25521719455719,\n",
       "   1.1433964967727661,\n",
       "   1.0320578813552856,\n",
       "   0.949008047580719,\n",
       "   0.8623228669166565,\n",
       "   0.7997434735298157,\n",
       "   0.7440103888511658,\n",
       "   0.7057847380638123,\n",
       "   0.6601167917251587,\n",
       "   0.6294479966163635,\n",
       "   0.5953595042228699,\n",
       "   0.5724445581436157,\n",
       "   0.5499207973480225,\n",
       "   0.539154589176178,\n",
       "   0.5219040513038635,\n",
       "   0.5119203925132751,\n",
       "   0.49406659603118896,\n",
       "   0.4937945306301117,\n",
       "   0.47983673214912415,\n",
       "   0.46658051013946533,\n",
       "   0.45718881487846375,\n",
       "   0.45815494656562805,\n",
       "   0.4488160014152527,\n",
       "   0.45326751470565796,\n",
       "   0.4453577995300293,\n",
       "   0.43784308433532715,\n",
       "   0.4341445863246918,\n",
       "   0.4282177686691284,\n",
       "   0.4246978759765625,\n",
       "   0.4280014932155609,\n",
       "   0.4179582893848419,\n",
       "   0.4148903787136078,\n",
       "   0.4156814515590668,\n",
       "   0.4096817970275879,\n",
       "   0.4151408076286316,\n",
       "   0.4061432480812073,\n",
       "   0.408025860786438,\n",
       "   0.41074109077453613,\n",
       "   0.4052496552467346,\n",
       "   0.40319764614105225,\n",
       "   0.40720120072364807,\n",
       "   0.410238116979599,\n",
       "   0.4106990396976471,\n",
       "   0.41109752655029297,\n",
       "   0.412769615650177,\n",
       "   0.4158783555030823,\n",
       "   0.40955641865730286,\n",
       "   0.4063097834587097,\n",
       "   0.41130703687667847,\n",
       "   0.41147682070732117,\n",
       "   0.41553470492362976,\n",
       "   0.4144527316093445,\n",
       "   0.415278822183609,\n",
       "   0.41801926493644714,\n",
       "   0.4214363098144531,\n",
       "   0.42270806431770325,\n",
       "   0.428179532289505,\n",
       "   0.4302288889884949,\n",
       "   0.43602028489112854,\n",
       "   0.43408942222595215,\n",
       "   0.43436169624328613,\n",
       "   0.4412769377231598,\n",
       "   0.4453797936439514,\n",
       "   0.4477793276309967,\n",
       "   0.45011427998542786,\n",
       "   0.4566790759563446,\n",
       "   0.4589272439479828,\n",
       "   0.4584592878818512,\n",
       "   0.462587833404541,\n",
       "   0.4679296910762787,\n",
       "   0.4716578722000122,\n",
       "   0.4767296314239502,\n",
       "   0.4798163175582886,\n",
       "   0.4832068681716919,\n",
       "   0.49087661504745483,\n",
       "   0.4959298372268677,\n",
       "   0.501052737236023,\n",
       "   0.5093693733215332,\n",
       "   0.509292721748352,\n",
       "   0.5185930132865906,\n",
       "   0.5194271206855774,\n",
       "   0.5325374007225037,\n",
       "   0.5297927856445312,\n",
       "   0.5355150699615479,\n",
       "   0.5431342124938965,\n",
       "   0.5475220084190369,\n",
       "   0.556553840637207,\n",
       "   0.5631876587867737],\n",
       "  'val_accuracy': [0.48399999737739563,\n",
       "   0.48399999737739563,\n",
       "   0.5339999794960022,\n",
       "   0.6759999990463257,\n",
       "   0.6759999990463257,\n",
       "   0.7260000109672546,\n",
       "   0.722000002861023,\n",
       "   0.7459999918937683,\n",
       "   0.7480000257492065,\n",
       "   0.7919999957084656,\n",
       "   0.7979999780654907,\n",
       "   0.8040000200271606,\n",
       "   0.8100000023841858,\n",
       "   0.8199999928474426,\n",
       "   0.8360000252723694,\n",
       "   0.8320000171661377,\n",
       "   0.828000009059906,\n",
       "   0.8379999995231628,\n",
       "   0.843999981880188,\n",
       "   0.8339999914169312,\n",
       "   0.8339999914169312,\n",
       "   0.8500000238418579,\n",
       "   0.8519999980926514,\n",
       "   0.8399999737739563,\n",
       "   0.8479999899864197,\n",
       "   0.8360000252723694,\n",
       "   0.8399999737739563,\n",
       "   0.8460000157356262,\n",
       "   0.8420000076293945,\n",
       "   0.8479999899864197,\n",
       "   0.8479999899864197,\n",
       "   0.843999981880188,\n",
       "   0.8479999899864197,\n",
       "   0.8560000061988831,\n",
       "   0.8519999980926514,\n",
       "   0.8539999723434448,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8640000224113464,\n",
       "   0.8519999980926514,\n",
       "   0.8659999966621399,\n",
       "   0.8640000224113464,\n",
       "   0.8619999885559082,\n",
       "   0.8539999723434448,\n",
       "   0.8560000061988831,\n",
       "   0.8579999804496765,\n",
       "   0.8579999804496765,\n",
       "   0.8560000061988831,\n",
       "   0.8579999804496765,\n",
       "   0.8579999804496765,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8619999885559082,\n",
       "   0.8619999885559082,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8619999885559082,\n",
       "   0.8619999885559082,\n",
       "   0.8640000224113464,\n",
       "   0.8679999709129333,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8640000224113464,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8679999709129333,\n",
       "   0.8679999709129333,\n",
       "   0.8679999709129333,\n",
       "   0.8619999885559082,\n",
       "   0.8659999966621399,\n",
       "   0.8679999709129333,\n",
       "   0.8679999709129333,\n",
       "   0.8700000047683716,\n",
       "   0.8679999709129333,\n",
       "   0.8659999966621399,\n",
       "   0.8700000047683716,\n",
       "   0.8640000224113464,\n",
       "   0.8640000224113464,\n",
       "   0.8700000047683716,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8619999885559082,\n",
       "   0.8619999885559082,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399]},\n",
       " 'epochs_90_batch_64': {'loss': [1.586380958557129,\n",
       "   1.4739776849746704,\n",
       "   1.438960075378418,\n",
       "   1.3928179740905762,\n",
       "   1.3349254131317139,\n",
       "   1.2713679075241089,\n",
       "   1.2003313302993774,\n",
       "   1.1295874118804932,\n",
       "   1.0585848093032837,\n",
       "   0.98771071434021,\n",
       "   0.920643150806427,\n",
       "   0.8594753742218018,\n",
       "   0.8006614446640015,\n",
       "   0.7469846606254578,\n",
       "   0.6983436346054077,\n",
       "   0.6517324447631836,\n",
       "   0.612133800983429,\n",
       "   0.5742294788360596,\n",
       "   0.5395628213882446,\n",
       "   0.5078843832015991,\n",
       "   0.4791141152381897,\n",
       "   0.45113736391067505,\n",
       "   0.42659783363342285,\n",
       "   0.40436625480651855,\n",
       "   0.38190150260925293,\n",
       "   0.36313170194625854,\n",
       "   0.3430245518684387,\n",
       "   0.3254099488258362,\n",
       "   0.30833253264427185,\n",
       "   0.2914523780345917,\n",
       "   0.2767317295074463,\n",
       "   0.2626226246356964,\n",
       "   0.24916404485702515,\n",
       "   0.23716935515403748,\n",
       "   0.22402946650981903,\n",
       "   0.21400563418865204,\n",
       "   0.20163244009017944,\n",
       "   0.19189898669719696,\n",
       "   0.18149282038211823,\n",
       "   0.17164908349514008,\n",
       "   0.16306202113628387,\n",
       "   0.15414521098136902,\n",
       "   0.1454303115606308,\n",
       "   0.13792026042938232,\n",
       "   0.13025407493114471,\n",
       "   0.12284725904464722,\n",
       "   0.11627363413572311,\n",
       "   0.11018272489309311,\n",
       "   0.10369547456502914,\n",
       "   0.0976894274353981,\n",
       "   0.09241005033254623,\n",
       "   0.0870075672864914,\n",
       "   0.08182070404291153,\n",
       "   0.07728688418865204,\n",
       "   0.07235129177570343,\n",
       "   0.06823216378688812,\n",
       "   0.0642702654004097,\n",
       "   0.060198813676834106,\n",
       "   0.05646531283855438,\n",
       "   0.052743226289749146,\n",
       "   0.04971092939376831,\n",
       "   0.04662281647324562,\n",
       "   0.043408624827861786,\n",
       "   0.04086587578058243,\n",
       "   0.03795788809657097,\n",
       "   0.03543262928724289,\n",
       "   0.03328561782836914,\n",
       "   0.031218234449625015,\n",
       "   0.02866017445921898,\n",
       "   0.026810843497514725,\n",
       "   0.024899452924728394,\n",
       "   0.02308613620698452,\n",
       "   0.021641923114657402,\n",
       "   0.02018878422677517,\n",
       "   0.018671492114663124,\n",
       "   0.01731231063604355,\n",
       "   0.01596023328602314,\n",
       "   0.014729098416864872,\n",
       "   0.013865325599908829,\n",
       "   0.012670577503740788,\n",
       "   0.011710918508470058,\n",
       "   0.010796912014484406,\n",
       "   0.009896782226860523,\n",
       "   0.009107929654419422,\n",
       "   0.008404669351875782,\n",
       "   0.007799970451742411,\n",
       "   0.007067682221531868,\n",
       "   0.006559865083545446,\n",
       "   0.0060165501199662685,\n",
       "   0.005497846286743879],\n",
       "  'accuracy': [0.46814218163490295,\n",
       "   0.48423877358436584,\n",
       "   0.48423877358436584,\n",
       "   0.48423877358436584,\n",
       "   0.49564051628112793,\n",
       "   0.5184440016746521,\n",
       "   0.5606974959373474,\n",
       "   0.6076458692550659,\n",
       "   0.6512407660484314,\n",
       "   0.696177065372467,\n",
       "   0.7196512222290039,\n",
       "   0.7431254386901855,\n",
       "   0.7645875215530396,\n",
       "   0.7800134420394897,\n",
       "   0.7947686314582825,\n",
       "   0.8014755249023438,\n",
       "   0.8169013857841492,\n",
       "   0.8329979777336121,\n",
       "   0.8443997502326965,\n",
       "   0.8544601202011108,\n",
       "   0.8678739070892334,\n",
       "   0.8725687265396118,\n",
       "   0.8920187950134277,\n",
       "   0.8940308690071106,\n",
       "   0.8973842859268188,\n",
       "   0.902079164981842,\n",
       "   0.9101274609565735,\n",
       "   0.9175050258636475,\n",
       "   0.9255533218383789,\n",
       "   0.9282360672950745,\n",
       "   0.9329309463500977,\n",
       "   0.9389671087265015,\n",
       "   0.9429912567138672,\n",
       "   0.9396378397941589,\n",
       "   0.9496982097625732,\n",
       "   0.9470154047012329,\n",
       "   0.9564051032066345,\n",
       "   0.9597585797309875,\n",
       "   0.9631119966506958,\n",
       "   0.9657947421073914,\n",
       "   0.9698188900947571,\n",
       "   0.9731723666191101,\n",
       "   0.9718309640884399,\n",
       "   0.9731723666191101,\n",
       "   0.975184440612793,\n",
       "   0.978537917137146,\n",
       "   0.9771965146064758,\n",
       "   0.9792085886001587,\n",
       "   0.9805499911308289,\n",
       "   0.9845741391181946,\n",
       "   0.9845741391181946,\n",
       "   0.9865862131118774,\n",
       "   0.9899396300315857,\n",
       "   0.9899396300315857,\n",
       "   0.9939637780189514,\n",
       "   0.9946344494819641,\n",
       "   0.9932931065559387,\n",
       "   0.9939637780189514,\n",
       "   0.9953051805496216,\n",
       "   0.996646523475647,\n",
       "   0.9959758520126343,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   1.0,\n",
       "   0.9993293285369873,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'val_loss': [1.45390784740448,\n",
       "   1.4265040159225464,\n",
       "   1.3993778228759766,\n",
       "   1.334539532661438,\n",
       "   1.291502833366394,\n",
       "   1.2257741689682007,\n",
       "   1.1651959419250488,\n",
       "   1.1074212789535522,\n",
       "   1.0379024744033813,\n",
       "   0.9758269786834717,\n",
       "   0.926756739616394,\n",
       "   0.8723657131195068,\n",
       "   0.8443306684494019,\n",
       "   0.7840090394020081,\n",
       "   0.7564265727996826,\n",
       "   0.7214970588684082,\n",
       "   0.6871196031570435,\n",
       "   0.6625145077705383,\n",
       "   0.6277428269386292,\n",
       "   0.613025426864624,\n",
       "   0.5911117196083069,\n",
       "   0.5957998037338257,\n",
       "   0.5682715177536011,\n",
       "   0.56419837474823,\n",
       "   0.5356398820877075,\n",
       "   0.5293965339660645,\n",
       "   0.5245956778526306,\n",
       "   0.509212076663971,\n",
       "   0.508560061454773,\n",
       "   0.5024005174636841,\n",
       "   0.5071386098861694,\n",
       "   0.49469250440597534,\n",
       "   0.47657138109207153,\n",
       "   0.47182759642601013,\n",
       "   0.45711180567741394,\n",
       "   0.4658229947090149,\n",
       "   0.4594581127166748,\n",
       "   0.45101726055145264,\n",
       "   0.45421963930130005,\n",
       "   0.46041953563690186,\n",
       "   0.4504694640636444,\n",
       "   0.4482705593109131,\n",
       "   0.4430423378944397,\n",
       "   0.4467315673828125,\n",
       "   0.44346973299980164,\n",
       "   0.43297091126441956,\n",
       "   0.43566447496414185,\n",
       "   0.42972490191459656,\n",
       "   0.43683576583862305,\n",
       "   0.44143393635749817,\n",
       "   0.43137282133102417,\n",
       "   0.43950343132019043,\n",
       "   0.433256596326828,\n",
       "   0.4369412064552307,\n",
       "   0.4284166395664215,\n",
       "   0.4289166033267975,\n",
       "   0.43379271030426025,\n",
       "   0.4304402470588684,\n",
       "   0.43315669894218445,\n",
       "   0.4317128360271454,\n",
       "   0.43397265672683716,\n",
       "   0.432972252368927,\n",
       "   0.43422913551330566,\n",
       "   0.4309144914150238,\n",
       "   0.438281774520874,\n",
       "   0.4342414438724518,\n",
       "   0.43143606185913086,\n",
       "   0.43771541118621826,\n",
       "   0.44216564297676086,\n",
       "   0.43741852045059204,\n",
       "   0.44509536027908325,\n",
       "   0.442597895860672,\n",
       "   0.4506398141384125,\n",
       "   0.45118996500968933,\n",
       "   0.45345842838287354,\n",
       "   0.45828449726104736,\n",
       "   0.4565427303314209,\n",
       "   0.4613338112831116,\n",
       "   0.4586157202720642,\n",
       "   0.4599215090274811,\n",
       "   0.46288374066352844,\n",
       "   0.46595245599746704,\n",
       "   0.472805917263031,\n",
       "   0.4788898825645447,\n",
       "   0.4770442843437195,\n",
       "   0.4820583462715149,\n",
       "   0.478550523519516,\n",
       "   0.4810938835144043,\n",
       "   0.4908874034881592,\n",
       "   0.4907938838005066],\n",
       "  'val_accuracy': [0.48399999737739563,\n",
       "   0.48399999737739563,\n",
       "   0.48399999737739563,\n",
       "   0.48399999737739563,\n",
       "   0.48399999737739563,\n",
       "   0.5360000133514404,\n",
       "   0.5519999861717224,\n",
       "   0.5820000171661377,\n",
       "   0.7059999704360962,\n",
       "   0.7160000205039978,\n",
       "   0.7440000176429749,\n",
       "   0.7400000095367432,\n",
       "   0.7319999933242798,\n",
       "   0.7519999742507935,\n",
       "   0.7419999837875366,\n",
       "   0.7820000052452087,\n",
       "   0.777999997138977,\n",
       "   0.7820000052452087,\n",
       "   0.8080000281333923,\n",
       "   0.8119999766349792,\n",
       "   0.8240000009536743,\n",
       "   0.8119999766349792,\n",
       "   0.8180000185966492,\n",
       "   0.8140000104904175,\n",
       "   0.8199999928474426,\n",
       "   0.8320000171661377,\n",
       "   0.8339999914169312,\n",
       "   0.8420000076293945,\n",
       "   0.8360000252723694,\n",
       "   0.8479999899864197,\n",
       "   0.8180000185966492,\n",
       "   0.8360000252723694,\n",
       "   0.8500000238418579,\n",
       "   0.843999981880188,\n",
       "   0.8500000238418579,\n",
       "   0.8479999899864197,\n",
       "   0.8479999899864197,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8360000252723694,\n",
       "   0.8519999980926514,\n",
       "   0.8519999980926514,\n",
       "   0.8460000157356262,\n",
       "   0.843999981880188,\n",
       "   0.843999981880188,\n",
       "   0.8600000143051147,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8500000238418579,\n",
       "   0.8640000224113464,\n",
       "   0.8579999804496765,\n",
       "   0.8579999804496765,\n",
       "   0.8619999885559082,\n",
       "   0.8659999966621399,\n",
       "   0.8640000224113464,\n",
       "   0.8619999885559082,\n",
       "   0.8659999966621399,\n",
       "   0.871999979019165,\n",
       "   0.871999979019165,\n",
       "   0.8659999966621399,\n",
       "   0.8679999709129333,\n",
       "   0.871999979019165,\n",
       "   0.8640000224113464,\n",
       "   0.8659999966621399,\n",
       "   0.8659999966621399,\n",
       "   0.8679999709129333,\n",
       "   0.8679999709129333,\n",
       "   0.8700000047683716,\n",
       "   0.871999979019165,\n",
       "   0.8700000047683716,\n",
       "   0.8640000224113464,\n",
       "   0.8700000047683716,\n",
       "   0.8640000224113464,\n",
       "   0.871999979019165,\n",
       "   0.8640000224113464,\n",
       "   0.871999979019165,\n",
       "   0.8740000128746033,\n",
       "   0.8740000128746033,\n",
       "   0.871999979019165,\n",
       "   0.8700000047683716,\n",
       "   0.878000020980835,\n",
       "   0.8679999709129333,\n",
       "   0.8700000047683716,\n",
       "   0.8679999709129333,\n",
       "   0.8679999709129333,\n",
       "   0.871999979019165,\n",
       "   0.8700000047683716,\n",
       "   0.8679999709129333,\n",
       "   0.8740000128746033]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cee368-916f-44d6-8a6e-984d1842f3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3_7",
   "language": "python",
   "name": "python_3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
