{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f863a6-430a-447c-8bbd-80c8babadf0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37316f8-2de7-40b4-bfec-7b2937788db4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpsc_case_number</th>\n",
       "      <th>narrative</th>\n",
       "      <th>primary_mechanism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100145411</td>\n",
       "      <td>67 yof pt fell on the floor playing pickle bal...</td>\n",
       "      <td>Falls, trips, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100417928</td>\n",
       "      <td>63yof playing pickleball in the hot sun and pa...</td>\n",
       "      <td>Heat stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100417973</td>\n",
       "      <td>66yom strained lower leg playing pickle ball</td>\n",
       "      <td>Other mechanism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100417997</td>\n",
       "      <td>60yof pt playing pickle ball and fell sustaine...</td>\n",
       "      <td>Falls, trips, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100454409</td>\n",
       "      <td>70 yom pt injured knee while playing pickle ba...</td>\n",
       "      <td>Other mechanism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>200101825</td>\n",
       "      <td>68 yof tripped and fell while playing tennis. ...</td>\n",
       "      <td>Falls, trips, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>200102934</td>\n",
       "      <td>76yof was hit in the eye with a tennis ball dx...</td>\n",
       "      <td>Hit with various obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>200110467</td>\n",
       "      <td>61yof was playing tennis when she developed pa...</td>\n",
       "      <td>Undetermined/unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>200124689</td>\n",
       "      <td>70yof fell while playing tennis dx: strained u...</td>\n",
       "      <td>Falls, trips, etc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>200301553</td>\n",
       "      <td>76yom.playing tennis slipped.fell down.dx.lac....</td>\n",
       "      <td>Falls, trips, etc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1991 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cpsc_case_number                                          narrative  \\\n",
       "0            100145411  67 yof pt fell on the floor playing pickle bal...   \n",
       "1            100417928  63yof playing pickleball in the hot sun and pa...   \n",
       "2            100417973       66yom strained lower leg playing pickle ball   \n",
       "3            100417997  60yof pt playing pickle ball and fell sustaine...   \n",
       "4            100454409  70 yom pt injured knee while playing pickle ba...   \n",
       "...                ...                                                ...   \n",
       "1986         200101825  68 yof tripped and fell while playing tennis. ...   \n",
       "1987         200102934  76yof was hit in the eye with a tennis ball dx...   \n",
       "1988         200110467  61yof was playing tennis when she developed pa...   \n",
       "1989         200124689  70yof fell while playing tennis dx: strained u...   \n",
       "1990         200301553  76yom.playing tennis slipped.fell down.dx.lac....   \n",
       "\n",
       "         primary_mechanism  \n",
       "0       Falls, trips, etc.  \n",
       "1              Heat stroke  \n",
       "2          Other mechanism  \n",
       "3       Falls, trips, etc.  \n",
       "4          Other mechanism  \n",
       "...                    ...  \n",
       "1986    Falls, trips, etc.  \n",
       "1987  Hit with various obj  \n",
       "1988  Undetermined/unknown  \n",
       "1989    Falls, trips, etc.  \n",
       "1990    Falls, trips, etc.  \n",
       "\n",
       "[1991 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'data_to_model/keras_data/model_df_full_narrative.csv'\n",
    "train_df = pd.read_csv(train_path)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe842aa9-0933-4e49-aeef-83849831c8bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Falls, trips, etc.', 'Heat stroke', 'Other mechanism',\n",
       "       'Falls, trips, etc.', 'Other mechanism', 'Falls, trips, etc.',\n",
       "       'Falls, trips, etc.', 'Other mechanism', 'Other mechanism',\n",
       "       'Falls, trips, etc.'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_np = np.array(train_df['narrative'])\n",
    "train_labels_np = np.array(train_df['primary_mechanism'])\n",
    "train_labels_np[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9c24b9-8bd5-49c8-a559-a28409bc5c42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#l_list = []\n",
    "#for txt in text_np:\n",
    "#    l_list.append( len(txt) )\n",
    "    \n",
    "#l_list[0:10]\n",
    "\n",
    "#max(l_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f6eef2f-32b1-4810-a477-40fa9fc91a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxlen = 207\n",
    "training_samples = 1491\n",
    "validation_samples = 500\n",
    "max_words = 100000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(text_np)\n",
    "sequences = tokenizer.texts_to_sequences(text_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df633e05-a798-4e41-bf87-d622c22f251c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1857 unique tokens.\n",
      "Shape of data tensor: (1991, 207)\n",
      "Shape of label tensor: (1991,)\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', train_labels_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e127fa0-3dca-4a02-8605-0f6dff47d340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "train_labels_np = train_labels_np[indices]\n",
    "x_train = data[:training_samples]\n",
    "y_train = train_labels_np[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = train_labels_np[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df544f1-1e1b-47c4-ba7d-736362f614c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_integer_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_integer_encoded = label_encoder.fit_transform(y_val)\n",
    "\n",
    "#y_train_integer_encoded\n",
    "#y_train_integer_encoded\n",
    "y_train_one_hot = to_categorical(y_train_integer_encoded, num_classes=7)\n",
    "y_val_one_hot = to_categorical(y_val_integer_encoded, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13659797-747c-4446-8422-2ce9de69ae48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 207, 8)            800000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1656)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 11599     \n",
      "=================================================================\n",
      "Total params: 811,599\n",
      "Trainable params: 811,599\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 8, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "303dc81f-656b-483c-ac7d-8ee93567778d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.3353 - accuracy: 0.4769 - val_loss: 0.3260 - val_accuracy: 0.4700\n",
      "Epoch 2/80\n",
      "47/47 [==============================] - 1s 15ms/step - loss: 0.3146 - accuracy: 0.4889 - val_loss: 0.3099 - val_accuracy: 0.4700\n",
      "Epoch 3/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.2927 - accuracy: 0.5070 - val_loss: 0.2875 - val_accuracy: 0.5200\n",
      "Epoch 4/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.2668 - accuracy: 0.5654 - val_loss: 0.2635 - val_accuracy: 0.5800\n",
      "Epoch 5/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.2416 - accuracy: 0.6318 - val_loss: 0.2467 - val_accuracy: 0.5820\n",
      "Epoch 6/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.2204 - accuracy: 0.6841 - val_loss: 0.2276 - val_accuracy: 0.6740\n",
      "Epoch 7/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.2022 - accuracy: 0.7304 - val_loss: 0.2110 - val_accuracy: 0.7240\n",
      "Epoch 8/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.1858 - accuracy: 0.7599 - val_loss: 0.1982 - val_accuracy: 0.7300\n",
      "Epoch 9/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.1722 - accuracy: 0.7673 - val_loss: 0.1879 - val_accuracy: 0.7360\n",
      "Epoch 10/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.1596 - accuracy: 0.7800 - val_loss: 0.1779 - val_accuracy: 0.7500\n",
      "Epoch 11/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.1483 - accuracy: 0.7934 - val_loss: 0.1678 - val_accuracy: 0.7680\n",
      "Epoch 12/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.1381 - accuracy: 0.8095 - val_loss: 0.1604 - val_accuracy: 0.7780\n",
      "Epoch 13/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.1292 - accuracy: 0.8310 - val_loss: 0.1558 - val_accuracy: 0.7840\n",
      "Epoch 14/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.1207 - accuracy: 0.8498 - val_loss: 0.1491 - val_accuracy: 0.7900\n",
      "Epoch 15/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.1128 - accuracy: 0.8605 - val_loss: 0.1446 - val_accuracy: 0.7940\n",
      "Epoch 16/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.1056 - accuracy: 0.8685 - val_loss: 0.1418 - val_accuracy: 0.8060\n",
      "Epoch 17/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0991 - accuracy: 0.8840 - val_loss: 0.1368 - val_accuracy: 0.8060\n",
      "Epoch 18/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0930 - accuracy: 0.8900 - val_loss: 0.1329 - val_accuracy: 0.8260\n",
      "Epoch 19/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0875 - accuracy: 0.8967 - val_loss: 0.1308 - val_accuracy: 0.8120\n",
      "Epoch 20/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0823 - accuracy: 0.9041 - val_loss: 0.1282 - val_accuracy: 0.8200\n",
      "Epoch 21/80\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0775 - accuracy: 0.9121 - val_loss: 0.1248 - val_accuracy: 0.8340\n",
      "Epoch 22/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0729 - accuracy: 0.9128 - val_loss: 0.1244 - val_accuracy: 0.8300\n",
      "Epoch 23/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0687 - accuracy: 0.9195 - val_loss: 0.1226 - val_accuracy: 0.8400\n",
      "Epoch 24/80\n",
      "47/47 [==============================] - 1s 15ms/step - loss: 0.0646 - accuracy: 0.9296 - val_loss: 0.1199 - val_accuracy: 0.8440\n",
      "Epoch 25/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0610 - accuracy: 0.9370 - val_loss: 0.1208 - val_accuracy: 0.8420\n",
      "Epoch 26/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0575 - accuracy: 0.9403 - val_loss: 0.1176 - val_accuracy: 0.8460\n",
      "Epoch 27/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0541 - accuracy: 0.9457 - val_loss: 0.1145 - val_accuracy: 0.8500\n",
      "Epoch 28/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0509 - accuracy: 0.9564 - val_loss: 0.1143 - val_accuracy: 0.8500\n",
      "Epoch 29/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0479 - accuracy: 0.9571 - val_loss: 0.1137 - val_accuracy: 0.8480\n",
      "Epoch 30/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0450 - accuracy: 0.9611 - val_loss: 0.1143 - val_accuracy: 0.8480\n",
      "Epoch 31/80\n",
      "47/47 [==============================] - 1s 15ms/step - loss: 0.0423 - accuracy: 0.9618 - val_loss: 0.1135 - val_accuracy: 0.8480\n",
      "Epoch 32/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0398 - accuracy: 0.9658 - val_loss: 0.1129 - val_accuracy: 0.8460\n",
      "Epoch 33/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0373 - accuracy: 0.9691 - val_loss: 0.1115 - val_accuracy: 0.8500\n",
      "Epoch 34/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0350 - accuracy: 0.9698 - val_loss: 0.1108 - val_accuracy: 0.8540\n",
      "Epoch 35/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0327 - accuracy: 0.9718 - val_loss: 0.1119 - val_accuracy: 0.8540\n",
      "Epoch 36/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0308 - accuracy: 0.9745 - val_loss: 0.1103 - val_accuracy: 0.8500\n",
      "Epoch 37/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0287 - accuracy: 0.9779 - val_loss: 0.1081 - val_accuracy: 0.8580\n",
      "Epoch 38/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0269 - accuracy: 0.9785 - val_loss: 0.1105 - val_accuracy: 0.8560\n",
      "Epoch 39/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0252 - accuracy: 0.9792 - val_loss: 0.1097 - val_accuracy: 0.8560\n",
      "Epoch 40/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0236 - accuracy: 0.9805 - val_loss: 0.1108 - val_accuracy: 0.8540\n",
      "Epoch 41/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0220 - accuracy: 0.9826 - val_loss: 0.1089 - val_accuracy: 0.8560\n",
      "Epoch 42/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0206 - accuracy: 0.9819 - val_loss: 0.1086 - val_accuracy: 0.8560\n",
      "Epoch 43/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0192 - accuracy: 0.9839 - val_loss: 0.1087 - val_accuracy: 0.8580\n",
      "Epoch 44/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0179 - accuracy: 0.9852 - val_loss: 0.1131 - val_accuracy: 0.8560\n",
      "Epoch 45/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0167 - accuracy: 0.9852 - val_loss: 0.1142 - val_accuracy: 0.8600\n",
      "Epoch 46/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0157 - accuracy: 0.9859 - val_loss: 0.1106 - val_accuracy: 0.8560\n",
      "Epoch 47/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0145 - accuracy: 0.9906 - val_loss: 0.1103 - val_accuracy: 0.8600\n",
      "Epoch 48/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0134 - accuracy: 0.9913 - val_loss: 0.1125 - val_accuracy: 0.8620\n",
      "Epoch 49/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0126 - accuracy: 0.9926 - val_loss: 0.1112 - val_accuracy: 0.8640\n",
      "Epoch 50/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0116 - accuracy: 0.9933 - val_loss: 0.1108 - val_accuracy: 0.8620\n",
      "Epoch 51/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0109 - accuracy: 0.9940 - val_loss: 0.1133 - val_accuracy: 0.8620\n",
      "Epoch 52/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0099 - accuracy: 0.9946 - val_loss: 0.1120 - val_accuracy: 0.8640\n",
      "Epoch 53/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0093 - accuracy: 0.9953 - val_loss: 0.1120 - val_accuracy: 0.8640\n",
      "Epoch 54/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0087 - accuracy: 0.9966 - val_loss: 0.1140 - val_accuracy: 0.8620\n",
      "Epoch 55/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0079 - accuracy: 0.9966 - val_loss: 0.1167 - val_accuracy: 0.8640\n",
      "Epoch 56/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0073 - accuracy: 0.9966 - val_loss: 0.1134 - val_accuracy: 0.8600\n",
      "Epoch 57/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0068 - accuracy: 0.9966 - val_loss: 0.1134 - val_accuracy: 0.8640\n",
      "Epoch 58/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0062 - accuracy: 0.9966 - val_loss: 0.1158 - val_accuracy: 0.8600\n",
      "Epoch 59/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0058 - accuracy: 0.9973 - val_loss: 0.1173 - val_accuracy: 0.8600\n",
      "Epoch 60/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.1184 - val_accuracy: 0.8640\n",
      "Epoch 61/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0048 - accuracy: 0.9980 - val_loss: 0.1182 - val_accuracy: 0.8600\n",
      "Epoch 62/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.1188 - val_accuracy: 0.8600\n",
      "Epoch 63/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.1181 - val_accuracy: 0.8600\n",
      "Epoch 64/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.1194 - val_accuracy: 0.8600\n",
      "Epoch 65/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.1229 - val_accuracy: 0.8560\n",
      "Epoch 66/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.1221 - val_accuracy: 0.8600\n",
      "Epoch 67/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.1230 - val_accuracy: 0.8620\n",
      "Epoch 68/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.1259 - val_accuracy: 0.8580\n",
      "Epoch 69/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.1266 - val_accuracy: 0.8620\n",
      "Epoch 70/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.1270 - val_accuracy: 0.8580\n",
      "Epoch 71/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.8580\n",
      "Epoch 72/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.8640\n",
      "Epoch 73/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 0.8620\n",
      "Epoch 74/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.8640\n",
      "Epoch 75/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.8640\n",
      "Epoch 76/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 0.8600\n",
      "Epoch 77/80\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.8580\n",
      "Epoch 78/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 8.8936e-04 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.8620\n",
      "Epoch 79/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 7.8270e-04 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.8560\n",
      "Epoch 80/80\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 7.1966e-04 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.8620\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train_one_hot,\n",
    "epochs=80,\n",
    "batch_size=32,\n",
    "validation_data=(x_val, y_val_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91d32b28-57cf-4497-9708-4531cc7885e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Model Objects/keras_outv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07bf2ef-cc32-4cbb-a4de-a4f1d1af825a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8b59762-1b60-43af-b3ea-51d91fc7507a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    my_dim = 8\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, my_dim, input_length=maxlen))\n",
    "    model.add(Flatten())\n",
    "#    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "653ed884-ce2a-4711-a343-d96a00fb2521",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "94/94 - 1s - loss: 1.4822 - accuracy: 0.4889 - val_loss: 1.4312 - val_accuracy: 0.4700\n",
      "Epoch 2/30\n",
      "94/94 - 1s - loss: 1.3428 - accuracy: 0.4997 - val_loss: 1.3066 - val_accuracy: 0.4960\n",
      "Epoch 3/30\n",
      "94/94 - 1s - loss: 1.1522 - accuracy: 0.6043 - val_loss: 1.1045 - val_accuracy: 0.6320\n",
      "Epoch 4/30\n",
      "94/94 - 1s - loss: 0.9778 - accuracy: 0.7082 - val_loss: 0.9689 - val_accuracy: 0.6880\n",
      "Epoch 5/30\n",
      "94/94 - 1s - loss: 0.8420 - accuracy: 0.7512 - val_loss: 0.8633 - val_accuracy: 0.7300\n",
      "Epoch 6/30\n",
      "94/94 - 1s - loss: 0.7414 - accuracy: 0.7706 - val_loss: 0.7916 - val_accuracy: 0.7480\n",
      "Epoch 7/30\n",
      "94/94 - 1s - loss: 0.6606 - accuracy: 0.7954 - val_loss: 0.7408 - val_accuracy: 0.7580\n",
      "Epoch 8/30\n",
      "94/94 - 1s - loss: 0.5966 - accuracy: 0.8102 - val_loss: 0.6896 - val_accuracy: 0.7660\n",
      "Epoch 9/30\n",
      "94/94 - 1s - loss: 0.5415 - accuracy: 0.8243 - val_loss: 0.6456 - val_accuracy: 0.7980\n",
      "Epoch 10/30\n",
      "94/94 - 1s - loss: 0.4942 - accuracy: 0.8464 - val_loss: 0.6122 - val_accuracy: 0.8020\n",
      "Epoch 11/30\n",
      "94/94 - 1s - loss: 0.4542 - accuracy: 0.8665 - val_loss: 0.5869 - val_accuracy: 0.8140\n",
      "Epoch 12/30\n",
      "94/94 - 1s - loss: 0.4182 - accuracy: 0.8759 - val_loss: 0.5571 - val_accuracy: 0.8200\n",
      "Epoch 13/30\n",
      "94/94 - 1s - loss: 0.3869 - accuracy: 0.8867 - val_loss: 0.5556 - val_accuracy: 0.8260\n",
      "Epoch 14/30\n",
      "94/94 - 1s - loss: 0.3599 - accuracy: 0.8947 - val_loss: 0.5345 - val_accuracy: 0.8260\n",
      "Epoch 15/30\n",
      "94/94 - 1s - loss: 0.3340 - accuracy: 0.9068 - val_loss: 0.5302 - val_accuracy: 0.8300\n",
      "Epoch 16/30\n",
      "94/94 - 1s - loss: 0.3106 - accuracy: 0.9115 - val_loss: 0.5147 - val_accuracy: 0.8320\n",
      "Epoch 17/30\n",
      "94/94 - 1s - loss: 0.2891 - accuracy: 0.9249 - val_loss: 0.5113 - val_accuracy: 0.8340\n",
      "Epoch 18/30\n",
      "94/94 - 1s - loss: 0.2683 - accuracy: 0.9289 - val_loss: 0.5094 - val_accuracy: 0.8340\n",
      "Epoch 19/30\n",
      "94/94 - 1s - loss: 0.2511 - accuracy: 0.9323 - val_loss: 0.4897 - val_accuracy: 0.8400\n",
      "Epoch 20/30\n",
      "94/94 - 1s - loss: 0.2330 - accuracy: 0.9403 - val_loss: 0.4980 - val_accuracy: 0.8360\n",
      "Epoch 21/30\n",
      "94/94 - 1s - loss: 0.2173 - accuracy: 0.9450 - val_loss: 0.4780 - val_accuracy: 0.8500\n",
      "Epoch 22/30\n",
      "94/94 - 1s - loss: 0.2013 - accuracy: 0.9484 - val_loss: 0.4825 - val_accuracy: 0.8460\n",
      "Epoch 23/30\n",
      "94/94 - 1s - loss: 0.1875 - accuracy: 0.9551 - val_loss: 0.4780 - val_accuracy: 0.8480\n",
      "Epoch 24/30\n",
      "94/94 - 1s - loss: 0.1736 - accuracy: 0.9611 - val_loss: 0.4791 - val_accuracy: 0.8460\n",
      "Epoch 25/30\n",
      "94/94 - 1s - loss: 0.1615 - accuracy: 0.9651 - val_loss: 0.4714 - val_accuracy: 0.8560\n",
      "Epoch 26/30\n",
      "94/94 - 1s - loss: 0.1488 - accuracy: 0.9685 - val_loss: 0.4807 - val_accuracy: 0.8440\n",
      "Epoch 27/30\n",
      "94/94 - 1s - loss: 0.1387 - accuracy: 0.9678 - val_loss: 0.4739 - val_accuracy: 0.8580\n",
      "Epoch 28/30\n",
      "94/94 - 1s - loss: 0.1283 - accuracy: 0.9718 - val_loss: 0.4652 - val_accuracy: 0.8500\n",
      "Epoch 29/30\n",
      "94/94 - 1s - loss: 0.1189 - accuracy: 0.9712 - val_loss: 0.4802 - val_accuracy: 0.8520\n",
      "Epoch 30/30\n",
      "94/94 - 1s - loss: 0.1103 - accuracy: 0.9732 - val_loss: 0.4787 - val_accuracy: 0.8540\n",
      "Epochs: 30, Batch size: 16, Validation accuracy: 0.8539999723434448\n",
      "Epoch 1/30\n",
      "47/47 - 0s - loss: 1.5256 - accuracy: 0.4782 - val_loss: 1.4709 - val_accuracy: 0.4700\n",
      "Epoch 2/30\n",
      "47/47 - 0s - loss: 1.4193 - accuracy: 0.4889 - val_loss: 1.3959 - val_accuracy: 0.4700\n",
      "Epoch 3/30\n",
      "47/47 - 0s - loss: 1.3193 - accuracy: 0.5077 - val_loss: 1.2890 - val_accuracy: 0.5160\n",
      "Epoch 4/30\n",
      "47/47 - 0s - loss: 1.1930 - accuracy: 0.5708 - val_loss: 1.1849 - val_accuracy: 0.5920\n",
      "Epoch 5/30\n",
      "47/47 - 0s - loss: 1.0669 - accuracy: 0.6512 - val_loss: 1.0644 - val_accuracy: 0.6780\n",
      "Epoch 6/30\n",
      "47/47 - 0s - loss: 0.9540 - accuracy: 0.7069 - val_loss: 0.9818 - val_accuracy: 0.6800\n",
      "Epoch 7/30\n",
      "47/47 - 0s - loss: 0.8593 - accuracy: 0.7357 - val_loss: 0.9024 - val_accuracy: 0.7060\n",
      "Epoch 8/30\n",
      "47/47 - 0s - loss: 0.7808 - accuracy: 0.7565 - val_loss: 0.8320 - val_accuracy: 0.7220\n",
      "Epoch 9/30\n",
      "47/47 - 0s - loss: 0.7120 - accuracy: 0.7827 - val_loss: 0.7846 - val_accuracy: 0.7340\n",
      "Epoch 10/30\n",
      "47/47 - 0s - loss: 0.6543 - accuracy: 0.7954 - val_loss: 0.7331 - val_accuracy: 0.7580\n",
      "Epoch 11/30\n",
      "47/47 - 0s - loss: 0.6011 - accuracy: 0.8156 - val_loss: 0.6954 - val_accuracy: 0.7900\n",
      "Epoch 12/30\n",
      "47/47 - 0s - loss: 0.5568 - accuracy: 0.8303 - val_loss: 0.6679 - val_accuracy: 0.7780\n",
      "Epoch 13/30\n",
      "47/47 - 0s - loss: 0.5160 - accuracy: 0.8444 - val_loss: 0.6373 - val_accuracy: 0.7860\n",
      "Epoch 14/30\n",
      "47/47 - 0s - loss: 0.4782 - accuracy: 0.8531 - val_loss: 0.6104 - val_accuracy: 0.8060\n",
      "Epoch 15/30\n",
      "47/47 - 0s - loss: 0.4463 - accuracy: 0.8665 - val_loss: 0.5984 - val_accuracy: 0.8100\n",
      "Epoch 16/30\n",
      "47/47 - 0s - loss: 0.4172 - accuracy: 0.8779 - val_loss: 0.5679 - val_accuracy: 0.8280\n",
      "Epoch 17/30\n",
      "47/47 - 0s - loss: 0.3901 - accuracy: 0.8860 - val_loss: 0.5537 - val_accuracy: 0.8300\n",
      "Epoch 18/30\n",
      "47/47 - 0s - loss: 0.3671 - accuracy: 0.8981 - val_loss: 0.5394 - val_accuracy: 0.8300\n",
      "Epoch 19/30\n",
      "47/47 - 0s - loss: 0.3436 - accuracy: 0.9068 - val_loss: 0.5231 - val_accuracy: 0.8400\n",
      "Epoch 20/30\n",
      "47/47 - 0s - loss: 0.3231 - accuracy: 0.9142 - val_loss: 0.5149 - val_accuracy: 0.8340\n",
      "Epoch 21/30\n",
      "47/47 - 0s - loss: 0.3035 - accuracy: 0.9202 - val_loss: 0.5025 - val_accuracy: 0.8440\n",
      "Epoch 22/30\n",
      "47/47 - 0s - loss: 0.2869 - accuracy: 0.9269 - val_loss: 0.4925 - val_accuracy: 0.8360\n",
      "Epoch 23/30\n",
      "47/47 - 0s - loss: 0.2683 - accuracy: 0.9323 - val_loss: 0.4903 - val_accuracy: 0.8320\n",
      "Epoch 24/30\n",
      "47/47 - 0s - loss: 0.2537 - accuracy: 0.9363 - val_loss: 0.4828 - val_accuracy: 0.8340\n",
      "Epoch 25/30\n",
      "47/47 - 0s - loss: 0.2366 - accuracy: 0.9416 - val_loss: 0.4778 - val_accuracy: 0.8340\n",
      "Epoch 26/30\n",
      "47/47 - 0s - loss: 0.2239 - accuracy: 0.9457 - val_loss: 0.4666 - val_accuracy: 0.8340\n",
      "Epoch 27/30\n",
      "47/47 - 0s - loss: 0.2101 - accuracy: 0.9477 - val_loss: 0.4732 - val_accuracy: 0.8420\n",
      "Epoch 28/30\n",
      "47/47 - 0s - loss: 0.1985 - accuracy: 0.9544 - val_loss: 0.4609 - val_accuracy: 0.8420\n",
      "Epoch 29/30\n",
      "47/47 - 0s - loss: 0.1852 - accuracy: 0.9571 - val_loss: 0.4525 - val_accuracy: 0.8380\n",
      "Epoch 30/30\n",
      "47/47 - 0s - loss: 0.1749 - accuracy: 0.9557 - val_loss: 0.4545 - val_accuracy: 0.8380\n",
      "Epochs: 30, Batch size: 32, Validation accuracy: 0.8379999995231628\n",
      "Epoch 1/30\n",
      "24/24 - 0s - loss: 1.5676 - accuracy: 0.4628 - val_loss: 1.4898 - val_accuracy: 0.4700\n",
      "Epoch 2/30\n",
      "24/24 - 0s - loss: 1.4546 - accuracy: 0.4889 - val_loss: 1.4588 - val_accuracy: 0.4700\n",
      "Epoch 3/30\n",
      "24/24 - 0s - loss: 1.4238 - accuracy: 0.4889 - val_loss: 1.4286 - val_accuracy: 0.4700\n",
      "Epoch 4/30\n",
      "24/24 - 0s - loss: 1.3757 - accuracy: 0.4889 - val_loss: 1.4028 - val_accuracy: 0.4700\n",
      "Epoch 5/30\n",
      "24/24 - 0s - loss: 1.3180 - accuracy: 0.4956 - val_loss: 1.3296 - val_accuracy: 0.4960\n",
      "Epoch 6/30\n",
      "24/24 - 0s - loss: 1.2515 - accuracy: 0.5225 - val_loss: 1.2716 - val_accuracy: 0.5100\n",
      "Epoch 7/30\n",
      "24/24 - 0s - loss: 1.1791 - accuracy: 0.5721 - val_loss: 1.2205 - val_accuracy: 0.5300\n",
      "Epoch 8/30\n",
      "24/24 - 0s - loss: 1.1099 - accuracy: 0.6244 - val_loss: 1.1581 - val_accuracy: 0.5980\n",
      "Epoch 9/30\n",
      "24/24 - 0s - loss: 1.0394 - accuracy: 0.6667 - val_loss: 1.0932 - val_accuracy: 0.6660\n",
      "Epoch 10/30\n",
      "24/24 - 0s - loss: 0.9712 - accuracy: 0.7109 - val_loss: 1.0353 - val_accuracy: 0.6780\n",
      "Epoch 11/30\n",
      "24/24 - 0s - loss: 0.9062 - accuracy: 0.7304 - val_loss: 0.9909 - val_accuracy: 0.6840\n",
      "Epoch 12/30\n",
      "24/24 - 0s - loss: 0.8482 - accuracy: 0.7418 - val_loss: 0.9372 - val_accuracy: 0.7080\n",
      "Epoch 13/30\n",
      "24/24 - 0s - loss: 0.7933 - accuracy: 0.7619 - val_loss: 0.8901 - val_accuracy: 0.7160\n",
      "Epoch 14/30\n",
      "24/24 - 0s - loss: 0.7436 - accuracy: 0.7713 - val_loss: 0.8512 - val_accuracy: 0.7280\n",
      "Epoch 15/30\n",
      "24/24 - 0s - loss: 0.6980 - accuracy: 0.7867 - val_loss: 0.8227 - val_accuracy: 0.7280\n",
      "Epoch 16/30\n",
      "24/24 - 0s - loss: 0.6551 - accuracy: 0.7914 - val_loss: 0.7885 - val_accuracy: 0.7400\n",
      "Epoch 17/30\n",
      "24/24 - 0s - loss: 0.6188 - accuracy: 0.8062 - val_loss: 0.7636 - val_accuracy: 0.7380\n",
      "Epoch 18/30\n",
      "24/24 - 0s - loss: 0.5831 - accuracy: 0.8156 - val_loss: 0.7401 - val_accuracy: 0.7480\n",
      "Epoch 19/30\n",
      "24/24 - 0s - loss: 0.5491 - accuracy: 0.8290 - val_loss: 0.7111 - val_accuracy: 0.7700\n",
      "Epoch 20/30\n",
      "24/24 - 0s - loss: 0.5204 - accuracy: 0.8437 - val_loss: 0.6925 - val_accuracy: 0.7800\n",
      "Epoch 21/30\n",
      "24/24 - 0s - loss: 0.4934 - accuracy: 0.8457 - val_loss: 0.6817 - val_accuracy: 0.7700\n",
      "Epoch 22/30\n",
      "24/24 - 0s - loss: 0.4654 - accuracy: 0.8578 - val_loss: 0.6480 - val_accuracy: 0.8020\n",
      "Epoch 23/30\n",
      "24/24 - 0s - loss: 0.4432 - accuracy: 0.8699 - val_loss: 0.6392 - val_accuracy: 0.7960\n",
      "Epoch 24/30\n",
      "24/24 - 0s - loss: 0.4195 - accuracy: 0.8820 - val_loss: 0.6298 - val_accuracy: 0.8000\n",
      "Epoch 25/30\n",
      "24/24 - 0s - loss: 0.3966 - accuracy: 0.8873 - val_loss: 0.6192 - val_accuracy: 0.8080\n",
      "Epoch 26/30\n",
      "24/24 - 0s - loss: 0.3770 - accuracy: 0.8974 - val_loss: 0.6176 - val_accuracy: 0.8100\n",
      "Epoch 27/30\n",
      "24/24 - 0s - loss: 0.3592 - accuracy: 0.9034 - val_loss: 0.5969 - val_accuracy: 0.8060\n",
      "Epoch 28/30\n",
      "24/24 - 0s - loss: 0.3407 - accuracy: 0.9135 - val_loss: 0.5865 - val_accuracy: 0.8180\n",
      "Epoch 29/30\n",
      "24/24 - 0s - loss: 0.3232 - accuracy: 0.9188 - val_loss: 0.5810 - val_accuracy: 0.8160\n",
      "Epoch 30/30\n",
      "24/24 - 0s - loss: 0.3072 - accuracy: 0.9249 - val_loss: 0.5625 - val_accuracy: 0.8220\n",
      "Epochs: 30, Batch size: 64, Validation accuracy: 0.8220000267028809\n",
      "Epoch 1/60\n",
      "94/94 - 1s - loss: 1.5006 - accuracy: 0.4762 - val_loss: 1.4472 - val_accuracy: 0.4700\n",
      "Epoch 2/60\n",
      "94/94 - 1s - loss: 1.3494 - accuracy: 0.5030 - val_loss: 1.2928 - val_accuracy: 0.4980\n",
      "Epoch 3/60\n",
      "94/94 - 1s - loss: 1.1510 - accuracy: 0.5889 - val_loss: 1.0930 - val_accuracy: 0.6160\n",
      "Epoch 4/60\n",
      "94/94 - 1s - loss: 0.9584 - accuracy: 0.7015 - val_loss: 0.9338 - val_accuracy: 0.7100\n",
      "Epoch 5/60\n",
      "94/94 - 1s - loss: 0.8126 - accuracy: 0.7579 - val_loss: 0.8171 - val_accuracy: 0.7440\n",
      "Epoch 6/60\n",
      "94/94 - 1s - loss: 0.7053 - accuracy: 0.7894 - val_loss: 0.7396 - val_accuracy: 0.7900\n",
      "Epoch 7/60\n",
      "94/94 - 1s - loss: 0.6255 - accuracy: 0.8102 - val_loss: 0.6833 - val_accuracy: 0.7960\n",
      "Epoch 8/60\n",
      "94/94 - 1s - loss: 0.5622 - accuracy: 0.8310 - val_loss: 0.6362 - val_accuracy: 0.8140\n",
      "Epoch 9/60\n",
      "94/94 - 1s - loss: 0.5089 - accuracy: 0.8484 - val_loss: 0.6069 - val_accuracy: 0.8200\n",
      "Epoch 10/60\n",
      "94/94 - 1s - loss: 0.4627 - accuracy: 0.8652 - val_loss: 0.5752 - val_accuracy: 0.8300\n",
      "Epoch 11/60\n",
      "94/94 - 1s - loss: 0.4212 - accuracy: 0.8833 - val_loss: 0.5488 - val_accuracy: 0.8320\n",
      "Epoch 12/60\n",
      "94/94 - 1s - loss: 0.3855 - accuracy: 0.8947 - val_loss: 0.5422 - val_accuracy: 0.8320\n",
      "Epoch 13/60\n",
      "94/94 - 1s - loss: 0.3555 - accuracy: 0.9041 - val_loss: 0.5097 - val_accuracy: 0.8340\n",
      "Epoch 14/60\n",
      "94/94 - 1s - loss: 0.3282 - accuracy: 0.9188 - val_loss: 0.5019 - val_accuracy: 0.8340\n",
      "Epoch 15/60\n",
      "94/94 - 1s - loss: 0.3034 - accuracy: 0.9229 - val_loss: 0.4883 - val_accuracy: 0.8360\n",
      "Epoch 16/60\n",
      "94/94 - 1s - loss: 0.2796 - accuracy: 0.9323 - val_loss: 0.4745 - val_accuracy: 0.8480\n",
      "Epoch 17/60\n",
      "94/94 - 1s - loss: 0.2590 - accuracy: 0.9370 - val_loss: 0.4580 - val_accuracy: 0.8540\n",
      "Epoch 18/60\n",
      "94/94 - 1s - loss: 0.2390 - accuracy: 0.9450 - val_loss: 0.4579 - val_accuracy: 0.8500\n",
      "Epoch 19/60\n",
      "94/94 - 1s - loss: 0.2202 - accuracy: 0.9463 - val_loss: 0.4690 - val_accuracy: 0.8480\n",
      "Epoch 20/60\n",
      "94/94 - 1s - loss: 0.2048 - accuracy: 0.9484 - val_loss: 0.4502 - val_accuracy: 0.8500\n",
      "Epoch 21/60\n",
      "94/94 - 1s - loss: 0.1888 - accuracy: 0.9557 - val_loss: 0.4477 - val_accuracy: 0.8560\n",
      "Epoch 22/60\n",
      "94/94 - 1s - loss: 0.1752 - accuracy: 0.9577 - val_loss: 0.4416 - val_accuracy: 0.8540\n",
      "Epoch 23/60\n",
      "94/94 - 1s - loss: 0.1602 - accuracy: 0.9638 - val_loss: 0.4362 - val_accuracy: 0.8560\n",
      "Epoch 24/60\n",
      "94/94 - 1s - loss: 0.1489 - accuracy: 0.9658 - val_loss: 0.4361 - val_accuracy: 0.8480\n",
      "Epoch 25/60\n",
      "94/94 - 1s - loss: 0.1358 - accuracy: 0.9725 - val_loss: 0.4493 - val_accuracy: 0.8620\n",
      "Epoch 26/60\n",
      "94/94 - 1s - loss: 0.1249 - accuracy: 0.9752 - val_loss: 0.4444 - val_accuracy: 0.8560\n",
      "Epoch 27/60\n",
      "94/94 - 1s - loss: 0.1163 - accuracy: 0.9745 - val_loss: 0.4352 - val_accuracy: 0.8600\n",
      "Epoch 28/60\n",
      "94/94 - 1s - loss: 0.1072 - accuracy: 0.9799 - val_loss: 0.4344 - val_accuracy: 0.8600\n",
      "Epoch 29/60\n",
      "94/94 - 1s - loss: 0.0988 - accuracy: 0.9826 - val_loss: 0.4313 - val_accuracy: 0.8600\n",
      "Epoch 30/60\n",
      "94/94 - 1s - loss: 0.0901 - accuracy: 0.9826 - val_loss: 0.4381 - val_accuracy: 0.8600\n",
      "Epoch 31/60\n",
      "94/94 - 1s - loss: 0.0828 - accuracy: 0.9852 - val_loss: 0.4245 - val_accuracy: 0.8620\n",
      "Epoch 32/60\n",
      "94/94 - 1s - loss: 0.0758 - accuracy: 0.9866 - val_loss: 0.4439 - val_accuracy: 0.8620\n",
      "Epoch 33/60\n",
      "94/94 - 1s - loss: 0.0702 - accuracy: 0.9866 - val_loss: 0.4231 - val_accuracy: 0.8600\n",
      "Epoch 34/60\n",
      "94/94 - 1s - loss: 0.0643 - accuracy: 0.9873 - val_loss: 0.4466 - val_accuracy: 0.8580\n",
      "Epoch 35/60\n",
      "94/94 - 1s - loss: 0.0586 - accuracy: 0.9886 - val_loss: 0.4572 - val_accuracy: 0.8580\n",
      "Epoch 36/60\n",
      "94/94 - 1s - loss: 0.0542 - accuracy: 0.9886 - val_loss: 0.4508 - val_accuracy: 0.8620\n",
      "Epoch 37/60\n",
      "94/94 - 1s - loss: 0.0495 - accuracy: 0.9906 - val_loss: 0.4475 - val_accuracy: 0.8640\n",
      "Epoch 38/60\n",
      "94/94 - 1s - loss: 0.0457 - accuracy: 0.9926 - val_loss: 0.4476 - val_accuracy: 0.8640\n",
      "Epoch 39/60\n",
      "94/94 - 1s - loss: 0.0415 - accuracy: 0.9953 - val_loss: 0.4594 - val_accuracy: 0.8640\n",
      "Epoch 40/60\n",
      "94/94 - 1s - loss: 0.0381 - accuracy: 0.9933 - val_loss: 0.4426 - val_accuracy: 0.8680\n",
      "Epoch 41/60\n",
      "94/94 - 1s - loss: 0.0343 - accuracy: 0.9960 - val_loss: 0.4635 - val_accuracy: 0.8640\n",
      "Epoch 42/60\n",
      "94/94 - 1s - loss: 0.0321 - accuracy: 0.9946 - val_loss: 0.4569 - val_accuracy: 0.8680\n",
      "Epoch 43/60\n",
      "94/94 - 1s - loss: 0.0290 - accuracy: 0.9960 - val_loss: 0.4458 - val_accuracy: 0.8680\n",
      "Epoch 44/60\n",
      "94/94 - 1s - loss: 0.0257 - accuracy: 0.9973 - val_loss: 0.4875 - val_accuracy: 0.8640\n",
      "Epoch 45/60\n",
      "94/94 - 1s - loss: 0.0243 - accuracy: 0.9966 - val_loss: 0.4661 - val_accuracy: 0.8660\n",
      "Epoch 46/60\n",
      "94/94 - 1s - loss: 0.0218 - accuracy: 0.9966 - val_loss: 0.4627 - val_accuracy: 0.8700\n",
      "Epoch 47/60\n",
      "94/94 - 1s - loss: 0.0200 - accuracy: 0.9973 - val_loss: 0.4848 - val_accuracy: 0.8640\n",
      "Epoch 48/60\n",
      "94/94 - 1s - loss: 0.0180 - accuracy: 0.9973 - val_loss: 0.5000 - val_accuracy: 0.8680\n",
      "Epoch 49/60\n",
      "94/94 - 1s - loss: 0.0165 - accuracy: 0.9973 - val_loss: 0.4841 - val_accuracy: 0.8680\n",
      "Epoch 50/60\n",
      "94/94 - 1s - loss: 0.0145 - accuracy: 0.9980 - val_loss: 0.4848 - val_accuracy: 0.8700\n",
      "Epoch 51/60\n",
      "94/94 - 1s - loss: 0.0135 - accuracy: 0.9980 - val_loss: 0.4952 - val_accuracy: 0.8700\n",
      "Epoch 52/60\n",
      "94/94 - 1s - loss: 0.0120 - accuracy: 0.9987 - val_loss: 0.5083 - val_accuracy: 0.8700\n",
      "Epoch 53/60\n",
      "94/94 - 1s - loss: 0.0107 - accuracy: 0.9987 - val_loss: 0.5078 - val_accuracy: 0.8680\n",
      "Epoch 54/60\n",
      "94/94 - 1s - loss: 0.0097 - accuracy: 0.9987 - val_loss: 0.5234 - val_accuracy: 0.8680\n",
      "Epoch 55/60\n",
      "94/94 - 1s - loss: 0.0086 - accuracy: 0.9993 - val_loss: 0.5100 - val_accuracy: 0.8640\n",
      "Epoch 56/60\n",
      "94/94 - 1s - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.5418 - val_accuracy: 0.8680\n",
      "Epoch 57/60\n",
      "94/94 - 1s - loss: 0.0071 - accuracy: 0.9993 - val_loss: 0.5136 - val_accuracy: 0.8680\n",
      "Epoch 58/60\n",
      "94/94 - 1s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5188 - val_accuracy: 0.8660\n",
      "Epoch 59/60\n",
      "94/94 - 1s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.8720\n",
      "Epoch 60/60\n",
      "94/94 - 1s - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.5297 - val_accuracy: 0.8740\n",
      "Epochs: 60, Batch size: 16, Validation accuracy: 0.8740000128746033\n",
      "Epoch 1/60\n",
      "47/47 - 0s - loss: 1.5091 - accuracy: 0.4816 - val_loss: 1.4800 - val_accuracy: 0.4700\n",
      "Epoch 2/60\n",
      "47/47 - 0s - loss: 1.4157 - accuracy: 0.4889 - val_loss: 1.4125 - val_accuracy: 0.4700\n",
      "Epoch 3/60\n",
      "47/47 - 0s - loss: 1.3134 - accuracy: 0.5097 - val_loss: 1.2910 - val_accuracy: 0.5180\n",
      "Epoch 4/60\n",
      "47/47 - 0s - loss: 1.1825 - accuracy: 0.5748 - val_loss: 1.1793 - val_accuracy: 0.6000\n",
      "Epoch 5/60\n",
      "47/47 - 0s - loss: 1.0581 - accuracy: 0.6626 - val_loss: 1.0642 - val_accuracy: 0.6720\n",
      "Epoch 6/60\n",
      "47/47 - 0s - loss: 0.9441 - accuracy: 0.7223 - val_loss: 0.9700 - val_accuracy: 0.7020\n",
      "Epoch 7/60\n",
      "47/47 - 0s - loss: 0.8509 - accuracy: 0.7471 - val_loss: 0.8897 - val_accuracy: 0.7260\n",
      "Epoch 8/60\n",
      "47/47 - 0s - loss: 0.7710 - accuracy: 0.7686 - val_loss: 0.8272 - val_accuracy: 0.7420\n",
      "Epoch 9/60\n",
      "47/47 - 0s - loss: 0.7017 - accuracy: 0.7867 - val_loss: 0.7715 - val_accuracy: 0.7520\n",
      "Epoch 10/60\n",
      "47/47 - 0s - loss: 0.6432 - accuracy: 0.8089 - val_loss: 0.7277 - val_accuracy: 0.7560\n",
      "Epoch 11/60\n",
      "47/47 - 0s - loss: 0.5892 - accuracy: 0.8182 - val_loss: 0.6751 - val_accuracy: 0.7980\n",
      "Epoch 12/60\n",
      "47/47 - 0s - loss: 0.5437 - accuracy: 0.8397 - val_loss: 0.6535 - val_accuracy: 0.7860\n",
      "Epoch 13/60\n",
      "47/47 - 0s - loss: 0.5023 - accuracy: 0.8491 - val_loss: 0.6203 - val_accuracy: 0.8060\n",
      "Epoch 14/60\n",
      "47/47 - 0s - loss: 0.4660 - accuracy: 0.8571 - val_loss: 0.5936 - val_accuracy: 0.8060\n",
      "Epoch 15/60\n",
      "47/47 - 0s - loss: 0.4322 - accuracy: 0.8732 - val_loss: 0.5648 - val_accuracy: 0.8180\n",
      "Epoch 16/60\n",
      "47/47 - 0s - loss: 0.4029 - accuracy: 0.8820 - val_loss: 0.5560 - val_accuracy: 0.8120\n",
      "Epoch 17/60\n",
      "47/47 - 0s - loss: 0.3770 - accuracy: 0.8900 - val_loss: 0.5324 - val_accuracy: 0.8220\n",
      "Epoch 18/60\n",
      "47/47 - 0s - loss: 0.3502 - accuracy: 0.9014 - val_loss: 0.5289 - val_accuracy: 0.8180\n",
      "Epoch 19/60\n",
      "47/47 - 0s - loss: 0.3280 - accuracy: 0.9034 - val_loss: 0.5146 - val_accuracy: 0.8260\n",
      "Epoch 20/60\n",
      "47/47 - 0s - loss: 0.3078 - accuracy: 0.9155 - val_loss: 0.4904 - val_accuracy: 0.8280\n",
      "Epoch 21/60\n",
      "47/47 - 0s - loss: 0.2878 - accuracy: 0.9209 - val_loss: 0.4855 - val_accuracy: 0.8240\n",
      "Epoch 22/60\n",
      "47/47 - 0s - loss: 0.2707 - accuracy: 0.9249 - val_loss: 0.4791 - val_accuracy: 0.8300\n",
      "Epoch 23/60\n",
      "47/47 - 0s - loss: 0.2525 - accuracy: 0.9316 - val_loss: 0.4640 - val_accuracy: 0.8360\n",
      "Epoch 24/60\n",
      "47/47 - 0s - loss: 0.2366 - accuracy: 0.9383 - val_loss: 0.4600 - val_accuracy: 0.8420\n",
      "Epoch 25/60\n",
      "47/47 - 0s - loss: 0.2221 - accuracy: 0.9450 - val_loss: 0.4545 - val_accuracy: 0.8380\n",
      "Epoch 26/60\n",
      "47/47 - 0s - loss: 0.2075 - accuracy: 0.9504 - val_loss: 0.4491 - val_accuracy: 0.8440\n",
      "Epoch 27/60\n",
      "47/47 - 0s - loss: 0.1938 - accuracy: 0.9531 - val_loss: 0.4331 - val_accuracy: 0.8460\n",
      "Epoch 28/60\n",
      "47/47 - 0s - loss: 0.1818 - accuracy: 0.9571 - val_loss: 0.4412 - val_accuracy: 0.8380\n",
      "Epoch 29/60\n",
      "47/47 - 0s - loss: 0.1708 - accuracy: 0.9604 - val_loss: 0.4345 - val_accuracy: 0.8480\n",
      "Epoch 30/60\n",
      "47/47 - 0s - loss: 0.1590 - accuracy: 0.9658 - val_loss: 0.4240 - val_accuracy: 0.8440\n",
      "Epoch 31/60\n",
      "47/47 - 0s - loss: 0.1496 - accuracy: 0.9685 - val_loss: 0.4191 - val_accuracy: 0.8520\n",
      "Epoch 32/60\n",
      "47/47 - 0s - loss: 0.1393 - accuracy: 0.9732 - val_loss: 0.4257 - val_accuracy: 0.8600\n",
      "Epoch 33/60\n",
      "47/47 - 0s - loss: 0.1299 - accuracy: 0.9752 - val_loss: 0.4304 - val_accuracy: 0.8580\n",
      "Epoch 34/60\n",
      "47/47 - 0s - loss: 0.1222 - accuracy: 0.9765 - val_loss: 0.4182 - val_accuracy: 0.8540\n",
      "Epoch 35/60\n",
      "47/47 - 0s - loss: 0.1137 - accuracy: 0.9785 - val_loss: 0.4218 - val_accuracy: 0.8540\n",
      "Epoch 36/60\n",
      "47/47 - 0s - loss: 0.1069 - accuracy: 0.9799 - val_loss: 0.4175 - val_accuracy: 0.8560\n",
      "Epoch 37/60\n",
      "47/47 - 0s - loss: 0.0987 - accuracy: 0.9799 - val_loss: 0.4249 - val_accuracy: 0.8580\n",
      "Epoch 38/60\n",
      "47/47 - 0s - loss: 0.0932 - accuracy: 0.9832 - val_loss: 0.4155 - val_accuracy: 0.8560\n",
      "Epoch 39/60\n",
      "47/47 - 0s - loss: 0.0866 - accuracy: 0.9852 - val_loss: 0.4186 - val_accuracy: 0.8640\n",
      "Epoch 40/60\n",
      "47/47 - 0s - loss: 0.0803 - accuracy: 0.9846 - val_loss: 0.4193 - val_accuracy: 0.8660\n",
      "Epoch 41/60\n",
      "47/47 - 0s - loss: 0.0751 - accuracy: 0.9866 - val_loss: 0.4191 - val_accuracy: 0.8620\n",
      "Epoch 42/60\n",
      "47/47 - 0s - loss: 0.0702 - accuracy: 0.9879 - val_loss: 0.4202 - val_accuracy: 0.8620\n",
      "Epoch 43/60\n",
      "47/47 - 0s - loss: 0.0643 - accuracy: 0.9893 - val_loss: 0.4255 - val_accuracy: 0.8660\n",
      "Epoch 44/60\n",
      "47/47 - 0s - loss: 0.0605 - accuracy: 0.9906 - val_loss: 0.4189 - val_accuracy: 0.8620\n",
      "Epoch 45/60\n",
      "47/47 - 0s - loss: 0.0561 - accuracy: 0.9920 - val_loss: 0.4222 - val_accuracy: 0.8600\n",
      "Epoch 46/60\n",
      "47/47 - 0s - loss: 0.0519 - accuracy: 0.9926 - val_loss: 0.4322 - val_accuracy: 0.8600\n",
      "Epoch 47/60\n",
      "47/47 - 0s - loss: 0.0481 - accuracy: 0.9920 - val_loss: 0.4139 - val_accuracy: 0.8620\n",
      "Epoch 48/60\n",
      "47/47 - 0s - loss: 0.0443 - accuracy: 0.9926 - val_loss: 0.4248 - val_accuracy: 0.8640\n",
      "Epoch 49/60\n",
      "47/47 - 0s - loss: 0.0411 - accuracy: 0.9940 - val_loss: 0.4145 - val_accuracy: 0.8620\n",
      "Epoch 50/60\n",
      "47/47 - 0s - loss: 0.0381 - accuracy: 0.9953 - val_loss: 0.4259 - val_accuracy: 0.8620\n",
      "Epoch 51/60\n",
      "47/47 - 0s - loss: 0.0351 - accuracy: 0.9953 - val_loss: 0.4280 - val_accuracy: 0.8600\n",
      "Epoch 52/60\n",
      "47/47 - 0s - loss: 0.0323 - accuracy: 0.9960 - val_loss: 0.4408 - val_accuracy: 0.8600\n",
      "Epoch 53/60\n",
      "47/47 - 0s - loss: 0.0294 - accuracy: 0.9966 - val_loss: 0.4609 - val_accuracy: 0.8640\n",
      "Epoch 54/60\n",
      "47/47 - 0s - loss: 0.0274 - accuracy: 0.9980 - val_loss: 0.4570 - val_accuracy: 0.8600\n",
      "Epoch 55/60\n",
      "47/47 - 0s - loss: 0.0255 - accuracy: 0.9980 - val_loss: 0.4562 - val_accuracy: 0.8640\n",
      "Epoch 56/60\n",
      "47/47 - 0s - loss: 0.0230 - accuracy: 0.9980 - val_loss: 0.4606 - val_accuracy: 0.8580\n",
      "Epoch 57/60\n",
      "47/47 - 0s - loss: 0.0212 - accuracy: 0.9980 - val_loss: 0.4399 - val_accuracy: 0.8580\n",
      "Epoch 58/60\n",
      "47/47 - 0s - loss: 0.0194 - accuracy: 0.9987 - val_loss: 0.4672 - val_accuracy: 0.8620\n",
      "Epoch 59/60\n",
      "47/47 - 0s - loss: 0.0177 - accuracy: 0.9993 - val_loss: 0.4529 - val_accuracy: 0.8600\n",
      "Epoch 60/60\n",
      "47/47 - 0s - loss: 0.0164 - accuracy: 0.9980 - val_loss: 0.4580 - val_accuracy: 0.8620\n",
      "Epochs: 60, Batch size: 32, Validation accuracy: 0.8619999885559082\n",
      "Epoch 1/60\n",
      "24/24 - 0s - loss: 1.5669 - accuracy: 0.4742 - val_loss: 1.4957 - val_accuracy: 0.4700\n",
      "Epoch 2/60\n",
      "24/24 - 0s - loss: 1.4571 - accuracy: 0.4889 - val_loss: 1.4639 - val_accuracy: 0.4700\n",
      "Epoch 3/60\n",
      "24/24 - 0s - loss: 1.4268 - accuracy: 0.4889 - val_loss: 1.4204 - val_accuracy: 0.4700\n",
      "Epoch 4/60\n",
      "24/24 - 0s - loss: 1.3769 - accuracy: 0.4896 - val_loss: 1.3837 - val_accuracy: 0.4700\n",
      "Epoch 5/60\n",
      "24/24 - 0s - loss: 1.3173 - accuracy: 0.5003 - val_loss: 1.3543 - val_accuracy: 0.4700\n",
      "Epoch 6/60\n",
      "24/24 - 0s - loss: 1.2539 - accuracy: 0.5205 - val_loss: 1.2658 - val_accuracy: 0.5520\n",
      "Epoch 7/60\n",
      "24/24 - 0s - loss: 1.1830 - accuracy: 0.5681 - val_loss: 1.2046 - val_accuracy: 0.6040\n",
      "Epoch 8/60\n",
      "24/24 - 0s - loss: 1.1122 - accuracy: 0.6157 - val_loss: 1.1418 - val_accuracy: 0.6060\n",
      "Epoch 9/60\n",
      "24/24 - 0s - loss: 1.0412 - accuracy: 0.6734 - val_loss: 1.0890 - val_accuracy: 0.5960\n",
      "Epoch 10/60\n",
      "24/24 - 0s - loss: 0.9746 - accuracy: 0.6942 - val_loss: 1.0216 - val_accuracy: 0.6820\n",
      "Epoch 11/60\n",
      "24/24 - 0s - loss: 0.9086 - accuracy: 0.7223 - val_loss: 0.9613 - val_accuracy: 0.7020\n",
      "Epoch 12/60\n",
      "24/24 - 0s - loss: 0.8497 - accuracy: 0.7404 - val_loss: 0.9157 - val_accuracy: 0.7020\n",
      "Epoch 13/60\n",
      "24/24 - 0s - loss: 0.7955 - accuracy: 0.7525 - val_loss: 0.8640 - val_accuracy: 0.7380\n",
      "Epoch 14/60\n",
      "24/24 - 0s - loss: 0.7449 - accuracy: 0.7773 - val_loss: 0.8382 - val_accuracy: 0.7220\n",
      "Epoch 15/60\n",
      "24/24 - 0s - loss: 0.6997 - accuracy: 0.7780 - val_loss: 0.7934 - val_accuracy: 0.7460\n",
      "Epoch 16/60\n",
      "24/24 - 0s - loss: 0.6574 - accuracy: 0.7928 - val_loss: 0.7810 - val_accuracy: 0.7380\n",
      "Epoch 17/60\n",
      "24/24 - 0s - loss: 0.6199 - accuracy: 0.7995 - val_loss: 0.7292 - val_accuracy: 0.7700\n",
      "Epoch 18/60\n",
      "24/24 - 0s - loss: 0.5844 - accuracy: 0.8122 - val_loss: 0.7114 - val_accuracy: 0.7720\n",
      "Epoch 19/60\n",
      "24/24 - 0s - loss: 0.5513 - accuracy: 0.8236 - val_loss: 0.6805 - val_accuracy: 0.7840\n",
      "Epoch 20/60\n",
      "24/24 - 0s - loss: 0.5222 - accuracy: 0.8290 - val_loss: 0.6606 - val_accuracy: 0.7940\n",
      "Epoch 21/60\n",
      "24/24 - 0s - loss: 0.4939 - accuracy: 0.8451 - val_loss: 0.6516 - val_accuracy: 0.7960\n",
      "Epoch 22/60\n",
      "24/24 - 0s - loss: 0.4678 - accuracy: 0.8618 - val_loss: 0.6260 - val_accuracy: 0.7980\n",
      "Epoch 23/60\n",
      "24/24 - 0s - loss: 0.4439 - accuracy: 0.8665 - val_loss: 0.6184 - val_accuracy: 0.7980\n",
      "Epoch 24/60\n",
      "24/24 - 0s - loss: 0.4210 - accuracy: 0.8806 - val_loss: 0.6008 - val_accuracy: 0.8120\n",
      "Epoch 25/60\n",
      "24/24 - 0s - loss: 0.3982 - accuracy: 0.8920 - val_loss: 0.5910 - val_accuracy: 0.8080\n",
      "Epoch 26/60\n",
      "24/24 - 0s - loss: 0.3793 - accuracy: 0.9007 - val_loss: 0.5785 - val_accuracy: 0.8100\n",
      "Epoch 27/60\n",
      "24/24 - 0s - loss: 0.3581 - accuracy: 0.9095 - val_loss: 0.5758 - val_accuracy: 0.8080\n",
      "Epoch 28/60\n",
      "24/24 - 0s - loss: 0.3414 - accuracy: 0.9135 - val_loss: 0.5668 - val_accuracy: 0.8180\n",
      "Epoch 29/60\n",
      "24/24 - 0s - loss: 0.3250 - accuracy: 0.9175 - val_loss: 0.5460 - val_accuracy: 0.8240\n",
      "Epoch 30/60\n",
      "24/24 - 0s - loss: 0.3077 - accuracy: 0.9256 - val_loss: 0.5532 - val_accuracy: 0.8160\n",
      "Epoch 31/60\n",
      "24/24 - 0s - loss: 0.2928 - accuracy: 0.9282 - val_loss: 0.5343 - val_accuracy: 0.8300\n",
      "Epoch 32/60\n",
      "24/24 - 0s - loss: 0.2782 - accuracy: 0.9383 - val_loss: 0.5285 - val_accuracy: 0.8240\n",
      "Epoch 33/60\n",
      "24/24 - 0s - loss: 0.2645 - accuracy: 0.9396 - val_loss: 0.5193 - val_accuracy: 0.8300\n",
      "Epoch 34/60\n",
      "24/24 - 0s - loss: 0.2510 - accuracy: 0.9410 - val_loss: 0.5079 - val_accuracy: 0.8320\n",
      "Epoch 35/60\n",
      "24/24 - 0s - loss: 0.2390 - accuracy: 0.9450 - val_loss: 0.5177 - val_accuracy: 0.8340\n",
      "Epoch 36/60\n",
      "24/24 - 0s - loss: 0.2269 - accuracy: 0.9524 - val_loss: 0.5025 - val_accuracy: 0.8260\n",
      "Epoch 37/60\n",
      "24/24 - 0s - loss: 0.2151 - accuracy: 0.9531 - val_loss: 0.5092 - val_accuracy: 0.8340\n",
      "Epoch 38/60\n",
      "24/24 - 0s - loss: 0.2038 - accuracy: 0.9564 - val_loss: 0.4962 - val_accuracy: 0.8320\n",
      "Epoch 39/60\n",
      "24/24 - 0s - loss: 0.1942 - accuracy: 0.9598 - val_loss: 0.4945 - val_accuracy: 0.8340\n",
      "Epoch 40/60\n",
      "24/24 - 0s - loss: 0.1839 - accuracy: 0.9624 - val_loss: 0.4871 - val_accuracy: 0.8280\n",
      "Epoch 41/60\n",
      "24/24 - 0s - loss: 0.1732 - accuracy: 0.9624 - val_loss: 0.4876 - val_accuracy: 0.8340\n",
      "Epoch 42/60\n",
      "24/24 - 0s - loss: 0.1643 - accuracy: 0.9705 - val_loss: 0.4804 - val_accuracy: 0.8400\n",
      "Epoch 43/60\n",
      "24/24 - 0s - loss: 0.1560 - accuracy: 0.9718 - val_loss: 0.4743 - val_accuracy: 0.8380\n",
      "Epoch 44/60\n",
      "24/24 - 0s - loss: 0.1477 - accuracy: 0.9725 - val_loss: 0.4694 - val_accuracy: 0.8340\n",
      "Epoch 45/60\n",
      "24/24 - 0s - loss: 0.1396 - accuracy: 0.9765 - val_loss: 0.4747 - val_accuracy: 0.8440\n",
      "Epoch 46/60\n",
      "24/24 - 0s - loss: 0.1322 - accuracy: 0.9772 - val_loss: 0.4657 - val_accuracy: 0.8300\n",
      "Epoch 47/60\n",
      "24/24 - 0s - loss: 0.1250 - accuracy: 0.9785 - val_loss: 0.4681 - val_accuracy: 0.8340\n",
      "Epoch 48/60\n",
      "24/24 - 0s - loss: 0.1182 - accuracy: 0.9805 - val_loss: 0.4644 - val_accuracy: 0.8360\n",
      "Epoch 49/60\n",
      "24/24 - 0s - loss: 0.1118 - accuracy: 0.9826 - val_loss: 0.4577 - val_accuracy: 0.8340\n",
      "Epoch 50/60\n",
      "24/24 - 0s - loss: 0.1057 - accuracy: 0.9832 - val_loss: 0.4611 - val_accuracy: 0.8320\n",
      "Epoch 51/60\n",
      "24/24 - 0s - loss: 0.0998 - accuracy: 0.9839 - val_loss: 0.4543 - val_accuracy: 0.8320\n",
      "Epoch 52/60\n",
      "24/24 - 0s - loss: 0.0942 - accuracy: 0.9846 - val_loss: 0.4563 - val_accuracy: 0.8360\n",
      "Epoch 53/60\n",
      "24/24 - 0s - loss: 0.0891 - accuracy: 0.9859 - val_loss: 0.4529 - val_accuracy: 0.8320\n",
      "Epoch 54/60\n",
      "24/24 - 0s - loss: 0.0835 - accuracy: 0.9879 - val_loss: 0.4598 - val_accuracy: 0.8360\n",
      "Epoch 55/60\n",
      "24/24 - 0s - loss: 0.0791 - accuracy: 0.9886 - val_loss: 0.4594 - val_accuracy: 0.8340\n",
      "Epoch 56/60\n",
      "24/24 - 0s - loss: 0.0748 - accuracy: 0.9879 - val_loss: 0.4604 - val_accuracy: 0.8400\n",
      "Epoch 57/60\n",
      "24/24 - 0s - loss: 0.0703 - accuracy: 0.9913 - val_loss: 0.4679 - val_accuracy: 0.8420\n",
      "Epoch 58/60\n",
      "24/24 - 0s - loss: 0.0664 - accuracy: 0.9906 - val_loss: 0.4603 - val_accuracy: 0.8380\n",
      "Epoch 59/60\n",
      "24/24 - 0s - loss: 0.0624 - accuracy: 0.9920 - val_loss: 0.4567 - val_accuracy: 0.8380\n",
      "Epoch 60/60\n",
      "24/24 - 0s - loss: 0.0586 - accuracy: 0.9913 - val_loss: 0.4490 - val_accuracy: 0.8400\n",
      "Epochs: 60, Batch size: 64, Validation accuracy: 0.8399999737739563\n",
      "Epoch 1/90\n",
      "94/94 - 1s - loss: 1.5039 - accuracy: 0.4829 - val_loss: 1.4532 - val_accuracy: 0.4700\n",
      "Epoch 2/90\n",
      "94/94 - 1s - loss: 1.3520 - accuracy: 0.4997 - val_loss: 1.2888 - val_accuracy: 0.4960\n",
      "Epoch 3/90\n",
      "94/94 - 1s - loss: 1.1590 - accuracy: 0.5869 - val_loss: 1.1203 - val_accuracy: 0.6520\n",
      "Epoch 4/90\n",
      "94/94 - 1s - loss: 0.9836 - accuracy: 0.7036 - val_loss: 0.9758 - val_accuracy: 0.6700\n",
      "Epoch 5/90\n",
      "94/94 - 1s - loss: 0.8508 - accuracy: 0.7391 - val_loss: 0.8731 - val_accuracy: 0.7240\n",
      "Epoch 6/90\n",
      "94/94 - 1s - loss: 0.7525 - accuracy: 0.7639 - val_loss: 0.7898 - val_accuracy: 0.7460\n",
      "Epoch 7/90\n",
      "94/94 - 1s - loss: 0.6723 - accuracy: 0.7860 - val_loss: 0.7349 - val_accuracy: 0.7600\n",
      "Epoch 8/90\n",
      "94/94 - 1s - loss: 0.6072 - accuracy: 0.8035 - val_loss: 0.6919 - val_accuracy: 0.7640\n",
      "Epoch 9/90\n",
      "94/94 - 1s - loss: 0.5514 - accuracy: 0.8283 - val_loss: 0.6553 - val_accuracy: 0.7940\n",
      "Epoch 10/90\n",
      "94/94 - 1s - loss: 0.5041 - accuracy: 0.8498 - val_loss: 0.6176 - val_accuracy: 0.8060\n",
      "Epoch 11/90\n",
      "94/94 - 1s - loss: 0.4605 - accuracy: 0.8638 - val_loss: 0.5867 - val_accuracy: 0.8180\n",
      "Epoch 12/90\n",
      "94/94 - 1s - loss: 0.4236 - accuracy: 0.8766 - val_loss: 0.5743 - val_accuracy: 0.8140\n",
      "Epoch 13/90\n",
      "94/94 - 1s - loss: 0.3903 - accuracy: 0.8907 - val_loss: 0.5487 - val_accuracy: 0.8240\n",
      "Epoch 14/90\n",
      "94/94 - 1s - loss: 0.3592 - accuracy: 0.8994 - val_loss: 0.5282 - val_accuracy: 0.8320\n",
      "Epoch 15/90\n",
      "94/94 - 1s - loss: 0.3321 - accuracy: 0.9108 - val_loss: 0.5138 - val_accuracy: 0.8360\n",
      "Epoch 16/90\n",
      "94/94 - 1s - loss: 0.3065 - accuracy: 0.9188 - val_loss: 0.5048 - val_accuracy: 0.8380\n",
      "Epoch 17/90\n",
      "94/94 - 1s - loss: 0.2832 - accuracy: 0.9262 - val_loss: 0.4993 - val_accuracy: 0.8300\n",
      "Epoch 18/90\n",
      "94/94 - 1s - loss: 0.2625 - accuracy: 0.9309 - val_loss: 0.4913 - val_accuracy: 0.8400\n",
      "Epoch 19/90\n",
      "94/94 - 1s - loss: 0.2430 - accuracy: 0.9410 - val_loss: 0.4786 - val_accuracy: 0.8420\n",
      "Epoch 20/90\n",
      "94/94 - 1s - loss: 0.2254 - accuracy: 0.9423 - val_loss: 0.4782 - val_accuracy: 0.8380\n",
      "Epoch 21/90\n",
      "94/94 - 1s - loss: 0.2086 - accuracy: 0.9510 - val_loss: 0.4731 - val_accuracy: 0.8380\n",
      "Epoch 22/90\n",
      "94/94 - 1s - loss: 0.1934 - accuracy: 0.9504 - val_loss: 0.4721 - val_accuracy: 0.8360\n",
      "Epoch 23/90\n",
      "94/94 - 1s - loss: 0.1798 - accuracy: 0.9577 - val_loss: 0.4625 - val_accuracy: 0.8360\n",
      "Epoch 24/90\n",
      "94/94 - 1s - loss: 0.1653 - accuracy: 0.9631 - val_loss: 0.4599 - val_accuracy: 0.8400\n",
      "Epoch 25/90\n",
      "94/94 - 1s - loss: 0.1532 - accuracy: 0.9671 - val_loss: 0.4634 - val_accuracy: 0.8400\n",
      "Epoch 26/90\n",
      "94/94 - 1s - loss: 0.1421 - accuracy: 0.9671 - val_loss: 0.4534 - val_accuracy: 0.8440\n",
      "Epoch 27/90\n",
      "94/94 - 1s - loss: 0.1310 - accuracy: 0.9712 - val_loss: 0.4660 - val_accuracy: 0.8380\n",
      "Epoch 28/90\n",
      "94/94 - 1s - loss: 0.1234 - accuracy: 0.9718 - val_loss: 0.4612 - val_accuracy: 0.8420\n",
      "Epoch 29/90\n",
      "94/94 - 1s - loss: 0.1133 - accuracy: 0.9745 - val_loss: 0.4486 - val_accuracy: 0.8380\n",
      "Epoch 30/90\n",
      "94/94 - 1s - loss: 0.1057 - accuracy: 0.9752 - val_loss: 0.4607 - val_accuracy: 0.8440\n",
      "Epoch 31/90\n",
      "94/94 - 1s - loss: 0.0974 - accuracy: 0.9792 - val_loss: 0.4510 - val_accuracy: 0.8420\n",
      "Epoch 32/90\n",
      "94/94 - 1s - loss: 0.0905 - accuracy: 0.9792 - val_loss: 0.4485 - val_accuracy: 0.8500\n",
      "Epoch 33/90\n",
      "94/94 - 1s - loss: 0.0842 - accuracy: 0.9812 - val_loss: 0.4609 - val_accuracy: 0.8460\n",
      "Epoch 34/90\n",
      "94/94 - 1s - loss: 0.0785 - accuracy: 0.9819 - val_loss: 0.4564 - val_accuracy: 0.8460\n",
      "Epoch 35/90\n",
      "94/94 - 1s - loss: 0.0721 - accuracy: 0.9846 - val_loss: 0.4675 - val_accuracy: 0.8500\n",
      "Epoch 36/90\n",
      "94/94 - 1s - loss: 0.0675 - accuracy: 0.9839 - val_loss: 0.4683 - val_accuracy: 0.8480\n",
      "Epoch 37/90\n",
      "94/94 - 1s - loss: 0.0629 - accuracy: 0.9852 - val_loss: 0.4615 - val_accuracy: 0.8540\n",
      "Epoch 38/90\n",
      "94/94 - 1s - loss: 0.0578 - accuracy: 0.9879 - val_loss: 0.4620 - val_accuracy: 0.8500\n",
      "Epoch 39/90\n",
      "94/94 - 1s - loss: 0.0535 - accuracy: 0.9886 - val_loss: 0.4677 - val_accuracy: 0.8480\n",
      "Epoch 40/90\n",
      "94/94 - 1s - loss: 0.0497 - accuracy: 0.9906 - val_loss: 0.4645 - val_accuracy: 0.8480\n",
      "Epoch 41/90\n",
      "94/94 - 1s - loss: 0.0460 - accuracy: 0.9906 - val_loss: 0.4766 - val_accuracy: 0.8520\n",
      "Epoch 42/90\n",
      "94/94 - 1s - loss: 0.0429 - accuracy: 0.9913 - val_loss: 0.4585 - val_accuracy: 0.8480\n",
      "Epoch 43/90\n",
      "94/94 - 1s - loss: 0.0392 - accuracy: 0.9933 - val_loss: 0.4755 - val_accuracy: 0.8520\n",
      "Epoch 44/90\n",
      "94/94 - 1s - loss: 0.0367 - accuracy: 0.9920 - val_loss: 0.4893 - val_accuracy: 0.8540\n",
      "Epoch 45/90\n",
      "94/94 - 1s - loss: 0.0337 - accuracy: 0.9933 - val_loss: 0.4874 - val_accuracy: 0.8460\n",
      "Epoch 46/90\n",
      "94/94 - 1s - loss: 0.0312 - accuracy: 0.9946 - val_loss: 0.4813 - val_accuracy: 0.8520\n",
      "Epoch 47/90\n",
      "94/94 - 1s - loss: 0.0282 - accuracy: 0.9953 - val_loss: 0.5012 - val_accuracy: 0.8500\n",
      "Epoch 48/90\n",
      "94/94 - 1s - loss: 0.0260 - accuracy: 0.9973 - val_loss: 0.4974 - val_accuracy: 0.8460\n",
      "Epoch 49/90\n",
      "94/94 - 1s - loss: 0.0239 - accuracy: 0.9973 - val_loss: 0.4932 - val_accuracy: 0.8540\n",
      "Epoch 50/90\n",
      "94/94 - 1s - loss: 0.0220 - accuracy: 0.9966 - val_loss: 0.5060 - val_accuracy: 0.8460\n",
      "Epoch 51/90\n",
      "94/94 - 1s - loss: 0.0204 - accuracy: 0.9980 - val_loss: 0.5021 - val_accuracy: 0.8520\n",
      "Epoch 52/90\n",
      "94/94 - 1s - loss: 0.0184 - accuracy: 0.9980 - val_loss: 0.5165 - val_accuracy: 0.8500\n",
      "Epoch 53/90\n",
      "94/94 - 1s - loss: 0.0170 - accuracy: 0.9980 - val_loss: 0.5239 - val_accuracy: 0.8480\n",
      "Epoch 54/90\n",
      "94/94 - 1s - loss: 0.0155 - accuracy: 0.9980 - val_loss: 0.5339 - val_accuracy: 0.8460\n",
      "Epoch 55/90\n",
      "94/94 - 1s - loss: 0.0142 - accuracy: 0.9980 - val_loss: 0.5156 - val_accuracy: 0.8600\n",
      "Epoch 56/90\n",
      "94/94 - 1s - loss: 0.0125 - accuracy: 0.9987 - val_loss: 0.5240 - val_accuracy: 0.8520\n",
      "Epoch 57/90\n",
      "94/94 - 1s - loss: 0.0111 - accuracy: 0.9993 - val_loss: 0.5376 - val_accuracy: 0.8480\n",
      "Epoch 58/90\n",
      "94/94 - 1s - loss: 0.0100 - accuracy: 0.9993 - val_loss: 0.5398 - val_accuracy: 0.8520\n",
      "Epoch 59/90\n",
      "94/94 - 1s - loss: 0.0096 - accuracy: 0.9987 - val_loss: 0.5464 - val_accuracy: 0.8500\n",
      "Epoch 60/90\n",
      "94/94 - 1s - loss: 0.0084 - accuracy: 0.9993 - val_loss: 0.5628 - val_accuracy: 0.8460\n",
      "Epoch 61/90\n",
      "94/94 - 1s - loss: 0.0078 - accuracy: 0.9993 - val_loss: 0.5577 - val_accuracy: 0.8480\n",
      "Epoch 62/90\n",
      "94/94 - 1s - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.5637 - val_accuracy: 0.8420\n",
      "Epoch 63/90\n",
      "94/94 - 1s - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.6107 - val_accuracy: 0.8400\n",
      "Epoch 64/90\n",
      "94/94 - 1s - loss: 0.0056 - accuracy: 0.9993 - val_loss: 0.5655 - val_accuracy: 0.8480\n",
      "Epoch 65/90\n",
      "94/94 - 1s - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.5711 - val_accuracy: 0.8420\n",
      "Epoch 66/90\n",
      "94/94 - 1s - loss: 0.0045 - accuracy: 0.9993 - val_loss: 0.5925 - val_accuracy: 0.8420\n",
      "Epoch 67/90\n",
      "94/94 - 1s - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.6001 - val_accuracy: 0.8480\n",
      "Epoch 68/90\n",
      "94/94 - 1s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.8520\n",
      "Epoch 69/90\n",
      "94/94 - 1s - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.5992 - val_accuracy: 0.8480\n",
      "Epoch 70/90\n",
      "94/94 - 1s - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.6326 - val_accuracy: 0.8440\n",
      "Epoch 71/90\n",
      "94/94 - 1s - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.6467 - val_accuracy: 0.8440\n",
      "Epoch 72/90\n",
      "94/94 - 1s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.8440\n",
      "Epoch 73/90\n",
      "94/94 - 1s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6590 - val_accuracy: 0.8420\n",
      "Epoch 74/90\n",
      "94/94 - 1s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6796 - val_accuracy: 0.8420\n",
      "Epoch 75/90\n",
      "94/94 - 1s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.8460\n",
      "Epoch 76/90\n",
      "94/94 - 1s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6753 - val_accuracy: 0.8440\n",
      "Epoch 77/90\n",
      "94/94 - 1s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6787 - val_accuracy: 0.8460\n",
      "Epoch 78/90\n",
      "94/94 - 1s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8460\n",
      "Epoch 79/90\n",
      "94/94 - 1s - loss: 8.9207e-04 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8420\n",
      "Epoch 80/90\n",
      "94/94 - 1s - loss: 8.2356e-04 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.8440\n",
      "Epoch 81/90\n",
      "94/94 - 1s - loss: 7.5956e-04 - accuracy: 1.0000 - val_loss: 0.7223 - val_accuracy: 0.8460\n",
      "Epoch 82/90\n",
      "94/94 - 1s - loss: 6.2903e-04 - accuracy: 1.0000 - val_loss: 0.7354 - val_accuracy: 0.8460\n",
      "Epoch 83/90\n",
      "94/94 - 1s - loss: 5.8264e-04 - accuracy: 1.0000 - val_loss: 0.7353 - val_accuracy: 0.8460\n",
      "Epoch 84/90\n",
      "94/94 - 1s - loss: 5.0477e-04 - accuracy: 1.0000 - val_loss: 0.7379 - val_accuracy: 0.8420\n",
      "Epoch 85/90\n",
      "94/94 - 1s - loss: 4.3879e-04 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.8440\n",
      "Epoch 86/90\n",
      "94/94 - 1s - loss: 4.0105e-04 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.8460\n",
      "Epoch 87/90\n",
      "94/94 - 1s - loss: 3.4803e-04 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.8460\n",
      "Epoch 88/90\n",
      "94/94 - 1s - loss: 3.0505e-04 - accuracy: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.8440\n",
      "Epoch 89/90\n",
      "94/94 - 1s - loss: 2.3838e-04 - accuracy: 1.0000 - val_loss: 0.7720 - val_accuracy: 0.8480\n",
      "Epoch 90/90\n",
      "94/94 - 1s - loss: 2.4391e-04 - accuracy: 1.0000 - val_loss: 0.8086 - val_accuracy: 0.8440\n",
      "Epochs: 90, Batch size: 16, Validation accuracy: 0.843999981880188\n",
      "Epoch 1/90\n",
      "47/47 - 0s - loss: 1.5232 - accuracy: 0.4802 - val_loss: 1.4764 - val_accuracy: 0.4700\n",
      "Epoch 2/90\n",
      "47/47 - 0s - loss: 1.4244 - accuracy: 0.4889 - val_loss: 1.4132 - val_accuracy: 0.4700\n",
      "Epoch 3/90\n",
      "47/47 - 0s - loss: 1.3289 - accuracy: 0.4997 - val_loss: 1.3056 - val_accuracy: 0.5120\n",
      "Epoch 4/90\n",
      "47/47 - 0s - loss: 1.2090 - accuracy: 0.5607 - val_loss: 1.1996 - val_accuracy: 0.5480\n",
      "Epoch 5/90\n",
      "47/47 - 0s - loss: 1.0886 - accuracy: 0.6278 - val_loss: 1.0957 - val_accuracy: 0.6420\n",
      "Epoch 6/90\n",
      "47/47 - 0s - loss: 0.9740 - accuracy: 0.7015 - val_loss: 0.9969 - val_accuracy: 0.7020\n",
      "Epoch 7/90\n",
      "47/47 - 0s - loss: 0.8740 - accuracy: 0.7451 - val_loss: 0.9230 - val_accuracy: 0.7220\n",
      "Epoch 8/90\n",
      "47/47 - 0s - loss: 0.7904 - accuracy: 0.7626 - val_loss: 0.8624 - val_accuracy: 0.7320\n",
      "Epoch 9/90\n",
      "47/47 - 0s - loss: 0.7193 - accuracy: 0.7867 - val_loss: 0.7973 - val_accuracy: 0.7460\n",
      "Epoch 10/90\n",
      "47/47 - 0s - loss: 0.6574 - accuracy: 0.7995 - val_loss: 0.7517 - val_accuracy: 0.7620\n",
      "Epoch 11/90\n",
      "47/47 - 0s - loss: 0.6036 - accuracy: 0.8169 - val_loss: 0.7225 - val_accuracy: 0.7580\n",
      "Epoch 12/90\n",
      "47/47 - 0s - loss: 0.5568 - accuracy: 0.8317 - val_loss: 0.6829 - val_accuracy: 0.7740\n",
      "Epoch 13/90\n",
      "47/47 - 0s - loss: 0.5161 - accuracy: 0.8478 - val_loss: 0.6555 - val_accuracy: 0.7880\n",
      "Epoch 14/90\n",
      "47/47 - 0s - loss: 0.4779 - accuracy: 0.8585 - val_loss: 0.6353 - val_accuracy: 0.7960\n",
      "Epoch 15/90\n",
      "47/47 - 0s - loss: 0.4454 - accuracy: 0.8719 - val_loss: 0.6102 - val_accuracy: 0.8040\n",
      "Epoch 16/90\n",
      "47/47 - 0s - loss: 0.4158 - accuracy: 0.8793 - val_loss: 0.5935 - val_accuracy: 0.8080\n",
      "Epoch 17/90\n",
      "47/47 - 0s - loss: 0.3875 - accuracy: 0.8873 - val_loss: 0.5794 - val_accuracy: 0.8100\n",
      "Epoch 18/90\n",
      "47/47 - 0s - loss: 0.3633 - accuracy: 0.8927 - val_loss: 0.5627 - val_accuracy: 0.8260\n",
      "Epoch 19/90\n",
      "47/47 - 0s - loss: 0.3386 - accuracy: 0.9048 - val_loss: 0.5567 - val_accuracy: 0.8180\n",
      "Epoch 20/90\n",
      "47/47 - 0s - loss: 0.3190 - accuracy: 0.9148 - val_loss: 0.5436 - val_accuracy: 0.8260\n",
      "Epoch 21/90\n",
      "47/47 - 0s - loss: 0.2990 - accuracy: 0.9229 - val_loss: 0.5285 - val_accuracy: 0.8260\n",
      "Epoch 22/90\n",
      "47/47 - 0s - loss: 0.2809 - accuracy: 0.9309 - val_loss: 0.5250 - val_accuracy: 0.8260\n",
      "Epoch 23/90\n",
      "47/47 - 0s - loss: 0.2625 - accuracy: 0.9356 - val_loss: 0.5105 - val_accuracy: 0.8300\n",
      "Epoch 24/90\n",
      "47/47 - 0s - loss: 0.2471 - accuracy: 0.9383 - val_loss: 0.5041 - val_accuracy: 0.8340\n",
      "Epoch 25/90\n",
      "47/47 - 0s - loss: 0.2311 - accuracy: 0.9437 - val_loss: 0.5002 - val_accuracy: 0.8300\n",
      "Epoch 26/90\n",
      "47/47 - 0s - loss: 0.2165 - accuracy: 0.9504 - val_loss: 0.4989 - val_accuracy: 0.8360\n",
      "Epoch 27/90\n",
      "47/47 - 0s - loss: 0.2034 - accuracy: 0.9510 - val_loss: 0.4839 - val_accuracy: 0.8380\n",
      "Epoch 28/90\n",
      "47/47 - 0s - loss: 0.1903 - accuracy: 0.9537 - val_loss: 0.4815 - val_accuracy: 0.8340\n",
      "Epoch 29/90\n",
      "47/47 - 0s - loss: 0.1786 - accuracy: 0.9624 - val_loss: 0.4848 - val_accuracy: 0.8380\n",
      "Epoch 30/90\n",
      "47/47 - 0s - loss: 0.1668 - accuracy: 0.9665 - val_loss: 0.4771 - val_accuracy: 0.8400\n",
      "Epoch 31/90\n",
      "47/47 - 0s - loss: 0.1570 - accuracy: 0.9658 - val_loss: 0.4696 - val_accuracy: 0.8440\n",
      "Epoch 32/90\n",
      "47/47 - 0s - loss: 0.1466 - accuracy: 0.9712 - val_loss: 0.4749 - val_accuracy: 0.8360\n",
      "Epoch 33/90\n",
      "47/47 - 0s - loss: 0.1370 - accuracy: 0.9738 - val_loss: 0.4729 - val_accuracy: 0.8460\n",
      "Epoch 34/90\n",
      "47/47 - 0s - loss: 0.1281 - accuracy: 0.9779 - val_loss: 0.4799 - val_accuracy: 0.8420\n",
      "Epoch 35/90\n",
      "47/47 - 0s - loss: 0.1200 - accuracy: 0.9792 - val_loss: 0.4705 - val_accuracy: 0.8420\n",
      "Epoch 36/90\n",
      "47/47 - 0s - loss: 0.1119 - accuracy: 0.9826 - val_loss: 0.4705 - val_accuracy: 0.8460\n",
      "Epoch 37/90\n",
      "47/47 - 0s - loss: 0.1037 - accuracy: 0.9846 - val_loss: 0.4661 - val_accuracy: 0.8500\n",
      "Epoch 38/90\n",
      "47/47 - 0s - loss: 0.0974 - accuracy: 0.9846 - val_loss: 0.4716 - val_accuracy: 0.8500\n",
      "Epoch 39/90\n",
      "47/47 - 0s - loss: 0.0904 - accuracy: 0.9873 - val_loss: 0.4651 - val_accuracy: 0.8500\n",
      "Epoch 40/90\n",
      "47/47 - 0s - loss: 0.0846 - accuracy: 0.9873 - val_loss: 0.4679 - val_accuracy: 0.8480\n",
      "Epoch 41/90\n",
      "47/47 - 0s - loss: 0.0790 - accuracy: 0.9913 - val_loss: 0.4633 - val_accuracy: 0.8560\n",
      "Epoch 42/90\n",
      "47/47 - 0s - loss: 0.0729 - accuracy: 0.9913 - val_loss: 0.4602 - val_accuracy: 0.8480\n",
      "Epoch 43/90\n",
      "47/47 - 0s - loss: 0.0682 - accuracy: 0.9920 - val_loss: 0.4618 - val_accuracy: 0.8520\n",
      "Epoch 44/90\n",
      "47/47 - 0s - loss: 0.0632 - accuracy: 0.9920 - val_loss: 0.4686 - val_accuracy: 0.8560\n",
      "Epoch 45/90\n",
      "47/47 - 0s - loss: 0.0587 - accuracy: 0.9926 - val_loss: 0.4747 - val_accuracy: 0.8560\n",
      "Epoch 46/90\n",
      "47/47 - 0s - loss: 0.0544 - accuracy: 0.9926 - val_loss: 0.4724 - val_accuracy: 0.8560\n",
      "Epoch 47/90\n",
      "47/47 - 0s - loss: 0.0504 - accuracy: 0.9940 - val_loss: 0.4715 - val_accuracy: 0.8580\n",
      "Epoch 48/90\n",
      "47/47 - 0s - loss: 0.0472 - accuracy: 0.9933 - val_loss: 0.4759 - val_accuracy: 0.8560\n",
      "Epoch 49/90\n",
      "47/47 - 0s - loss: 0.0435 - accuracy: 0.9940 - val_loss: 0.4775 - val_accuracy: 0.8580\n",
      "Epoch 50/90\n",
      "47/47 - 0s - loss: 0.0401 - accuracy: 0.9940 - val_loss: 0.4790 - val_accuracy: 0.8600\n",
      "Epoch 51/90\n",
      "47/47 - 0s - loss: 0.0371 - accuracy: 0.9946 - val_loss: 0.4832 - val_accuracy: 0.8600\n",
      "Epoch 52/90\n",
      "47/47 - 0s - loss: 0.0340 - accuracy: 0.9946 - val_loss: 0.4802 - val_accuracy: 0.8620\n",
      "Epoch 53/90\n",
      "47/47 - 0s - loss: 0.0315 - accuracy: 0.9966 - val_loss: 0.4870 - val_accuracy: 0.8540\n",
      "Epoch 54/90\n",
      "47/47 - 0s - loss: 0.0288 - accuracy: 0.9973 - val_loss: 0.4868 - val_accuracy: 0.8580\n",
      "Epoch 55/90\n",
      "47/47 - 0s - loss: 0.0267 - accuracy: 0.9973 - val_loss: 0.4819 - val_accuracy: 0.8620\n",
      "Epoch 56/90\n",
      "47/47 - 0s - loss: 0.0241 - accuracy: 0.9987 - val_loss: 0.4953 - val_accuracy: 0.8560\n",
      "Epoch 57/90\n",
      "47/47 - 0s - loss: 0.0225 - accuracy: 0.9980 - val_loss: 0.5026 - val_accuracy: 0.8600\n",
      "Epoch 58/90\n",
      "47/47 - 0s - loss: 0.0205 - accuracy: 0.9987 - val_loss: 0.4997 - val_accuracy: 0.8600\n",
      "Epoch 59/90\n",
      "47/47 - 0s - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.8560\n",
      "Epoch 60/90\n",
      "47/47 - 0s - loss: 0.0174 - accuracy: 0.9993 - val_loss: 0.5053 - val_accuracy: 0.8600\n",
      "Epoch 61/90\n",
      "47/47 - 0s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.8580\n",
      "Epoch 62/90\n",
      "47/47 - 0s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.8500\n",
      "Epoch 63/90\n",
      "47/47 - 0s - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.8640\n",
      "Epoch 64/90\n",
      "47/47 - 0s - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.5196 - val_accuracy: 0.8620\n",
      "Epoch 65/90\n",
      "47/47 - 0s - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.8600\n",
      "Epoch 66/90\n",
      "47/47 - 0s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5306 - val_accuracy: 0.8580\n",
      "Epoch 67/90\n",
      "47/47 - 0s - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.8600\n",
      "Epoch 68/90\n",
      "47/47 - 0s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5548 - val_accuracy: 0.8520\n",
      "Epoch 69/90\n",
      "47/47 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5457 - val_accuracy: 0.8580\n",
      "Epoch 70/90\n",
      "47/47 - 0s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.5648 - val_accuracy: 0.8520\n",
      "Epoch 71/90\n",
      "47/47 - 0s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5581 - val_accuracy: 0.8540\n",
      "Epoch 72/90\n",
      "47/47 - 0s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.5676 - val_accuracy: 0.8640\n",
      "Epoch 73/90\n",
      "47/47 - 0s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5814 - val_accuracy: 0.8540\n",
      "Epoch 74/90\n",
      "47/47 - 0s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5750 - val_accuracy: 0.8540\n",
      "Epoch 75/90\n",
      "47/47 - 0s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5804 - val_accuracy: 0.8560\n",
      "Epoch 76/90\n",
      "47/47 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5924 - val_accuracy: 0.8540\n",
      "Epoch 77/90\n",
      "47/47 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5948 - val_accuracy: 0.8540\n",
      "Epoch 78/90\n",
      "47/47 - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6016 - val_accuracy: 0.8580\n",
      "Epoch 79/90\n",
      "47/47 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5969 - val_accuracy: 0.8580\n",
      "Epoch 80/90\n",
      "47/47 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.8560\n",
      "Epoch 81/90\n",
      "47/47 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 0.8540\n",
      "Epoch 82/90\n",
      "47/47 - 0s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6233 - val_accuracy: 0.8540\n",
      "Epoch 83/90\n",
      "47/47 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6368 - val_accuracy: 0.8540\n",
      "Epoch 84/90\n",
      "47/47 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 0.8580\n",
      "Epoch 85/90\n",
      "47/47 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6270 - val_accuracy: 0.8620\n",
      "Epoch 86/90\n",
      "47/47 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6550 - val_accuracy: 0.8580\n",
      "Epoch 87/90\n",
      "47/47 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6470 - val_accuracy: 0.8580\n",
      "Epoch 88/90\n",
      "47/47 - 0s - loss: 9.7807e-04 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 0.8580\n",
      "Epoch 89/90\n",
      "47/47 - 0s - loss: 8.8150e-04 - accuracy: 1.0000 - val_loss: 0.6808 - val_accuracy: 0.8580\n",
      "Epoch 90/90\n",
      "47/47 - 0s - loss: 7.8099e-04 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8580\n",
      "Epochs: 90, Batch size: 32, Validation accuracy: 0.8579999804496765\n",
      "Epoch 1/90\n",
      "24/24 - 0s - loss: 1.5688 - accuracy: 0.4574 - val_loss: 1.4926 - val_accuracy: 0.4700\n",
      "Epoch 2/90\n",
      "24/24 - 0s - loss: 1.4538 - accuracy: 0.4889 - val_loss: 1.4517 - val_accuracy: 0.4700\n",
      "Epoch 3/90\n",
      "24/24 - 0s - loss: 1.4071 - accuracy: 0.4889 - val_loss: 1.4095 - val_accuracy: 0.4700\n",
      "Epoch 4/90\n",
      "24/24 - 0s - loss: 1.3449 - accuracy: 0.4956 - val_loss: 1.3536 - val_accuracy: 0.4720\n",
      "Epoch 5/90\n",
      "24/24 - 0s - loss: 1.2743 - accuracy: 0.5285 - val_loss: 1.2858 - val_accuracy: 0.5380\n",
      "Epoch 6/90\n",
      "24/24 - 0s - loss: 1.1964 - accuracy: 0.5714 - val_loss: 1.2316 - val_accuracy: 0.5400\n",
      "Epoch 7/90\n",
      "24/24 - 0s - loss: 1.1187 - accuracy: 0.5929 - val_loss: 1.1543 - val_accuracy: 0.5820\n",
      "Epoch 8/90\n",
      "24/24 - 0s - loss: 1.0449 - accuracy: 0.6365 - val_loss: 1.0846 - val_accuracy: 0.6080\n",
      "Epoch 9/90\n",
      "24/24 - 0s - loss: 0.9737 - accuracy: 0.6673 - val_loss: 1.0240 - val_accuracy: 0.6720\n",
      "Epoch 10/90\n",
      "24/24 - 0s - loss: 0.9079 - accuracy: 0.7257 - val_loss: 0.9831 - val_accuracy: 0.6500\n",
      "Epoch 11/90\n",
      "24/24 - 0s - loss: 0.8506 - accuracy: 0.7418 - val_loss: 0.9265 - val_accuracy: 0.7020\n",
      "Epoch 12/90\n",
      "24/24 - 0s - loss: 0.7937 - accuracy: 0.7666 - val_loss: 0.8995 - val_accuracy: 0.7080\n",
      "Epoch 13/90\n",
      "24/24 - 0s - loss: 0.7473 - accuracy: 0.7673 - val_loss: 0.8498 - val_accuracy: 0.7320\n",
      "Epoch 14/90\n",
      "24/24 - 0s - loss: 0.7020 - accuracy: 0.7907 - val_loss: 0.8091 - val_accuracy: 0.7480\n",
      "Epoch 15/90\n",
      "24/24 - 0s - loss: 0.6600 - accuracy: 0.8028 - val_loss: 0.7801 - val_accuracy: 0.7520\n",
      "Epoch 16/90\n",
      "24/24 - 0s - loss: 0.6224 - accuracy: 0.8135 - val_loss: 0.7422 - val_accuracy: 0.7740\n",
      "Epoch 17/90\n",
      "24/24 - 0s - loss: 0.5889 - accuracy: 0.8182 - val_loss: 0.7196 - val_accuracy: 0.7900\n",
      "Epoch 18/90\n",
      "24/24 - 0s - loss: 0.5555 - accuracy: 0.8323 - val_loss: 0.6968 - val_accuracy: 0.7900\n",
      "Epoch 19/90\n",
      "24/24 - 0s - loss: 0.5261 - accuracy: 0.8431 - val_loss: 0.6823 - val_accuracy: 0.7820\n",
      "Epoch 20/90\n",
      "24/24 - 0s - loss: 0.4983 - accuracy: 0.8524 - val_loss: 0.6635 - val_accuracy: 0.7900\n",
      "Epoch 21/90\n",
      "24/24 - 0s - loss: 0.4733 - accuracy: 0.8652 - val_loss: 0.6449 - val_accuracy: 0.7920\n",
      "Epoch 22/90\n",
      "24/24 - 0s - loss: 0.4477 - accuracy: 0.8739 - val_loss: 0.6282 - val_accuracy: 0.8020\n",
      "Epoch 23/90\n",
      "24/24 - 0s - loss: 0.4244 - accuracy: 0.8840 - val_loss: 0.6071 - val_accuracy: 0.8060\n",
      "Epoch 24/90\n",
      "24/24 - 0s - loss: 0.4034 - accuracy: 0.8934 - val_loss: 0.6050 - val_accuracy: 0.8080\n",
      "Epoch 25/90\n",
      "24/24 - 0s - loss: 0.3846 - accuracy: 0.9001 - val_loss: 0.5840 - val_accuracy: 0.8080\n",
      "Epoch 26/90\n",
      "24/24 - 0s - loss: 0.3652 - accuracy: 0.9014 - val_loss: 0.5714 - val_accuracy: 0.8180\n",
      "Epoch 27/90\n",
      "24/24 - 0s - loss: 0.3470 - accuracy: 0.9081 - val_loss: 0.5669 - val_accuracy: 0.8180\n",
      "Epoch 28/90\n",
      "24/24 - 0s - loss: 0.3286 - accuracy: 0.9088 - val_loss: 0.5612 - val_accuracy: 0.8100\n",
      "Epoch 29/90\n",
      "24/24 - 0s - loss: 0.3139 - accuracy: 0.9142 - val_loss: 0.5467 - val_accuracy: 0.8200\n",
      "Epoch 30/90\n",
      "24/24 - 0s - loss: 0.2967 - accuracy: 0.9195 - val_loss: 0.5369 - val_accuracy: 0.8220\n",
      "Epoch 31/90\n",
      "24/24 - 0s - loss: 0.2836 - accuracy: 0.9282 - val_loss: 0.5333 - val_accuracy: 0.8280\n",
      "Epoch 32/90\n",
      "24/24 - 0s - loss: 0.2692 - accuracy: 0.9323 - val_loss: 0.5282 - val_accuracy: 0.8220\n",
      "Epoch 33/90\n",
      "24/24 - 0s - loss: 0.2553 - accuracy: 0.9396 - val_loss: 0.5199 - val_accuracy: 0.8240\n",
      "Epoch 34/90\n",
      "24/24 - 0s - loss: 0.2428 - accuracy: 0.9437 - val_loss: 0.5156 - val_accuracy: 0.8280\n",
      "Epoch 35/90\n",
      "24/24 - 0s - loss: 0.2299 - accuracy: 0.9490 - val_loss: 0.5104 - val_accuracy: 0.8300\n",
      "Epoch 36/90\n",
      "24/24 - 0s - loss: 0.2194 - accuracy: 0.9490 - val_loss: 0.5016 - val_accuracy: 0.8320\n",
      "Epoch 37/90\n",
      "24/24 - 0s - loss: 0.2083 - accuracy: 0.9544 - val_loss: 0.4964 - val_accuracy: 0.8380\n",
      "Epoch 38/90\n",
      "24/24 - 0s - loss: 0.1960 - accuracy: 0.9584 - val_loss: 0.5047 - val_accuracy: 0.8340\n",
      "Epoch 39/90\n",
      "24/24 - 0s - loss: 0.1874 - accuracy: 0.9577 - val_loss: 0.4907 - val_accuracy: 0.8340\n",
      "Epoch 40/90\n",
      "24/24 - 0s - loss: 0.1769 - accuracy: 0.9604 - val_loss: 0.4905 - val_accuracy: 0.8400\n",
      "Epoch 41/90\n",
      "24/24 - 0s - loss: 0.1676 - accuracy: 0.9645 - val_loss: 0.4795 - val_accuracy: 0.8360\n",
      "Epoch 42/90\n",
      "24/24 - 0s - loss: 0.1581 - accuracy: 0.9678 - val_loss: 0.4820 - val_accuracy: 0.8380\n",
      "Epoch 43/90\n",
      "24/24 - 0s - loss: 0.1508 - accuracy: 0.9651 - val_loss: 0.4738 - val_accuracy: 0.8400\n",
      "Epoch 44/90\n",
      "24/24 - 0s - loss: 0.1420 - accuracy: 0.9698 - val_loss: 0.4806 - val_accuracy: 0.8420\n",
      "Epoch 45/90\n",
      "24/24 - 0s - loss: 0.1345 - accuracy: 0.9732 - val_loss: 0.4693 - val_accuracy: 0.8360\n",
      "Epoch 46/90\n",
      "24/24 - 0s - loss: 0.1272 - accuracy: 0.9765 - val_loss: 0.4640 - val_accuracy: 0.8560\n",
      "Epoch 47/90\n",
      "24/24 - 0s - loss: 0.1203 - accuracy: 0.9792 - val_loss: 0.4668 - val_accuracy: 0.8400\n",
      "Epoch 48/90\n",
      "24/24 - 0s - loss: 0.1128 - accuracy: 0.9799 - val_loss: 0.4637 - val_accuracy: 0.8440\n",
      "Epoch 49/90\n",
      "24/24 - 0s - loss: 0.1066 - accuracy: 0.9826 - val_loss: 0.4649 - val_accuracy: 0.8440\n",
      "Epoch 50/90\n",
      "24/24 - 0s - loss: 0.1006 - accuracy: 0.9826 - val_loss: 0.4580 - val_accuracy: 0.8500\n",
      "Epoch 51/90\n",
      "24/24 - 0s - loss: 0.0948 - accuracy: 0.9832 - val_loss: 0.4568 - val_accuracy: 0.8520\n",
      "Epoch 52/90\n",
      "24/24 - 0s - loss: 0.0899 - accuracy: 0.9846 - val_loss: 0.4563 - val_accuracy: 0.8560\n",
      "Epoch 53/90\n",
      "24/24 - 0s - loss: 0.0843 - accuracy: 0.9852 - val_loss: 0.4579 - val_accuracy: 0.8560\n",
      "Epoch 54/90\n",
      "24/24 - 0s - loss: 0.0797 - accuracy: 0.9859 - val_loss: 0.4651 - val_accuracy: 0.8560\n",
      "Epoch 55/90\n",
      "24/24 - 0s - loss: 0.0749 - accuracy: 0.9866 - val_loss: 0.4650 - val_accuracy: 0.8600\n",
      "Epoch 56/90\n",
      "24/24 - 0s - loss: 0.0701 - accuracy: 0.9879 - val_loss: 0.4583 - val_accuracy: 0.8560\n",
      "Epoch 57/90\n",
      "24/24 - 0s - loss: 0.0662 - accuracy: 0.9886 - val_loss: 0.4625 - val_accuracy: 0.8580\n",
      "Epoch 58/90\n",
      "24/24 - 0s - loss: 0.0615 - accuracy: 0.9920 - val_loss: 0.4737 - val_accuracy: 0.8580\n",
      "Epoch 59/90\n",
      "24/24 - 0s - loss: 0.0586 - accuracy: 0.9913 - val_loss: 0.4665 - val_accuracy: 0.8600\n",
      "Epoch 60/90\n",
      "24/24 - 0s - loss: 0.0544 - accuracy: 0.9940 - val_loss: 0.4620 - val_accuracy: 0.8640\n",
      "Epoch 61/90\n",
      "24/24 - 0s - loss: 0.0511 - accuracy: 0.9933 - val_loss: 0.4635 - val_accuracy: 0.8640\n",
      "Epoch 62/90\n",
      "24/24 - 0s - loss: 0.0482 - accuracy: 0.9940 - val_loss: 0.4656 - val_accuracy: 0.8620\n",
      "Epoch 63/90\n",
      "24/24 - 0s - loss: 0.0447 - accuracy: 0.9960 - val_loss: 0.4745 - val_accuracy: 0.8560\n",
      "Epoch 64/90\n",
      "24/24 - 0s - loss: 0.0424 - accuracy: 0.9966 - val_loss: 0.4679 - val_accuracy: 0.8620\n",
      "Epoch 65/90\n",
      "24/24 - 0s - loss: 0.0392 - accuracy: 0.9966 - val_loss: 0.4707 - val_accuracy: 0.8660\n",
      "Epoch 66/90\n",
      "24/24 - 0s - loss: 0.0366 - accuracy: 0.9987 - val_loss: 0.4613 - val_accuracy: 0.8600\n",
      "Epoch 67/90\n",
      "24/24 - 0s - loss: 0.0343 - accuracy: 0.9987 - val_loss: 0.4747 - val_accuracy: 0.8620\n",
      "Epoch 68/90\n",
      "24/24 - 0s - loss: 0.0318 - accuracy: 0.9987 - val_loss: 0.4723 - val_accuracy: 0.8700\n",
      "Epoch 69/90\n",
      "24/24 - 0s - loss: 0.0300 - accuracy: 0.9987 - val_loss: 0.4766 - val_accuracy: 0.8680\n",
      "Epoch 70/90\n",
      "24/24 - 0s - loss: 0.0275 - accuracy: 0.9987 - val_loss: 0.4871 - val_accuracy: 0.8640\n",
      "Epoch 71/90\n",
      "24/24 - 0s - loss: 0.0259 - accuracy: 0.9987 - val_loss: 0.4835 - val_accuracy: 0.8660\n",
      "Epoch 72/90\n",
      "24/24 - 0s - loss: 0.0241 - accuracy: 0.9993 - val_loss: 0.4814 - val_accuracy: 0.8680\n",
      "Epoch 73/90\n",
      "24/24 - 0s - loss: 0.0221 - accuracy: 0.9993 - val_loss: 0.4859 - val_accuracy: 0.8660\n",
      "Epoch 74/90\n",
      "24/24 - 0s - loss: 0.0208 - accuracy: 0.9993 - val_loss: 0.4880 - val_accuracy: 0.8640\n",
      "Epoch 75/90\n",
      "24/24 - 0s - loss: 0.0193 - accuracy: 0.9993 - val_loss: 0.4905 - val_accuracy: 0.8660\n",
      "Epoch 76/90\n",
      "24/24 - 0s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.8640\n",
      "Epoch 77/90\n",
      "24/24 - 0s - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.5003 - val_accuracy: 0.8680\n",
      "Epoch 78/90\n",
      "24/24 - 0s - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.8660\n",
      "Epoch 79/90\n",
      "24/24 - 0s - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.8640\n",
      "Epoch 80/90\n",
      "24/24 - 0s - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.8660\n",
      "Epoch 81/90\n",
      "24/24 - 0s - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5272 - val_accuracy: 0.8640\n",
      "Epoch 82/90\n",
      "24/24 - 0s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.8620\n",
      "Epoch 83/90\n",
      "24/24 - 0s - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.8640\n",
      "Epoch 84/90\n",
      "24/24 - 0s - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5262 - val_accuracy: 0.8640\n",
      "Epoch 85/90\n",
      "24/24 - 0s - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.8640\n",
      "Epoch 86/90\n",
      "24/24 - 0s - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.8620\n",
      "Epoch 87/90\n",
      "24/24 - 0s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5424 - val_accuracy: 0.8640\n",
      "Epoch 88/90\n",
      "24/24 - 0s - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 0.8600\n",
      "Epoch 89/90\n",
      "24/24 - 0s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.5389 - val_accuracy: 0.8600\n",
      "Epoch 90/90\n",
      "24/24 - 0s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.5543 - val_accuracy: 0.8620\n",
      "Epochs: 90, Batch size: 64, Validation accuracy: 0.8619999885559082\n"
     ]
    }
   ],
   "source": [
    "# Different configurations to try\n",
    "epochs_list = [30, 60, 90]\n",
    "batch_sizes = [16, 32, 64]\n",
    "#embedding_dim = 8\n",
    "# Dictionary to store the history of each configuration\n",
    "history_dict = {}\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    for batch_size in batch_sizes:\n",
    "        # Get a fresh instance of the model for each run\n",
    "        model = getModel()\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='rmsprop',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(x_train, y_train_one_hot,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            validation_data=(x_val, y_val_one_hot),\n",
    "                            verbose=2)  # Set verbose to 2 for less output\n",
    "\n",
    "        # Save the history of this configuration\n",
    "        history_dict[f\"epochs_{epochs}_batch_{batch_size}\"] = history.history\n",
    "\n",
    "        # Optionally, you can print out the final validation accuracy for each configuration\n",
    "        final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "        print(f\"Epochs: {epochs}, Batch size: {batch_size}, Validation accuracy: {final_val_accuracy}\")\n",
    "\n",
    "# Now you can analyze the history_dict to see which configuration performed best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7be3a190-677d-4588-a3e3-c74e8b8f707b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs_30_batch_16': {'loss': [1.4821833372116089,\n",
       "   1.3427579402923584,\n",
       "   1.1521575450897217,\n",
       "   0.9778053164482117,\n",
       "   0.8420357704162598,\n",
       "   0.741432249546051,\n",
       "   0.6606308817863464,\n",
       "   0.5966179370880127,\n",
       "   0.5415460467338562,\n",
       "   0.49424809217453003,\n",
       "   0.4541677236557007,\n",
       "   0.4182294011116028,\n",
       "   0.38693076372146606,\n",
       "   0.35990408062934875,\n",
       "   0.33397936820983887,\n",
       "   0.31063738465309143,\n",
       "   0.2890501916408539,\n",
       "   0.2683102488517761,\n",
       "   0.25106221437454224,\n",
       "   0.23295490443706512,\n",
       "   0.21729665994644165,\n",
       "   0.20126160979270935,\n",
       "   0.18747802078723907,\n",
       "   0.17355145514011383,\n",
       "   0.16145217418670654,\n",
       "   0.1488184779882431,\n",
       "   0.138723686337471,\n",
       "   0.1282721906900406,\n",
       "   0.118911013007164,\n",
       "   0.11031230539083481],\n",
       "  'accuracy': [0.48893359303474426,\n",
       "   0.49966466426849365,\n",
       "   0.6042923927307129,\n",
       "   0.7082495093345642,\n",
       "   0.751173734664917,\n",
       "   0.7706237435340881,\n",
       "   0.7954393029212952,\n",
       "   0.8101944923400879,\n",
       "   0.8242790102958679,\n",
       "   0.8464118242263794,\n",
       "   0.8665325045585632,\n",
       "   0.8759222030639648,\n",
       "   0.8866532444953918,\n",
       "   0.8947015404701233,\n",
       "   0.9067739844322205,\n",
       "   0.9114688038825989,\n",
       "   0.9248826503753662,\n",
       "   0.9289067983627319,\n",
       "   0.9322602152824402,\n",
       "   0.9403085112571716,\n",
       "   0.94500333070755,\n",
       "   0.9483568072319031,\n",
       "   0.9550637006759644,\n",
       "   0.9610999226570129,\n",
       "   0.9651240706443787,\n",
       "   0.9684775471687317,\n",
       "   0.9678068161010742,\n",
       "   0.9718309640884399,\n",
       "   0.9711602926254272,\n",
       "   0.9731723666191101],\n",
       "  'val_loss': [1.4312107563018799,\n",
       "   1.3065524101257324,\n",
       "   1.1044670343399048,\n",
       "   0.9689067602157593,\n",
       "   0.8632850050926208,\n",
       "   0.7916395664215088,\n",
       "   0.7407516241073608,\n",
       "   0.6895772218704224,\n",
       "   0.645634651184082,\n",
       "   0.6121677160263062,\n",
       "   0.5869377255439758,\n",
       "   0.5570701956748962,\n",
       "   0.5556264519691467,\n",
       "   0.5345099568367004,\n",
       "   0.5302020907402039,\n",
       "   0.5146514773368835,\n",
       "   0.5113373398780823,\n",
       "   0.5094251036643982,\n",
       "   0.4896739721298218,\n",
       "   0.49800950288772583,\n",
       "   0.4779529869556427,\n",
       "   0.4824557602405548,\n",
       "   0.47797927260398865,\n",
       "   0.47913241386413574,\n",
       "   0.4714494049549103,\n",
       "   0.48074623942375183,\n",
       "   0.4739442765712738,\n",
       "   0.4651520550251007,\n",
       "   0.48024114966392517,\n",
       "   0.4786941111087799],\n",
       "  'val_accuracy': [0.4699999988079071,\n",
       "   0.4959999918937683,\n",
       "   0.6320000290870667,\n",
       "   0.6880000233650208,\n",
       "   0.7300000190734863,\n",
       "   0.7480000257492065,\n",
       "   0.7580000162124634,\n",
       "   0.765999972820282,\n",
       "   0.7979999780654907,\n",
       "   0.8019999861717224,\n",
       "   0.8140000104904175,\n",
       "   0.8199999928474426,\n",
       "   0.8259999752044678,\n",
       "   0.8259999752044678,\n",
       "   0.8299999833106995,\n",
       "   0.8320000171661377,\n",
       "   0.8339999914169312,\n",
       "   0.8339999914169312,\n",
       "   0.8399999737739563,\n",
       "   0.8360000252723694,\n",
       "   0.8500000238418579,\n",
       "   0.8460000157356262,\n",
       "   0.8479999899864197,\n",
       "   0.8460000157356262,\n",
       "   0.8560000061988831,\n",
       "   0.843999981880188,\n",
       "   0.8579999804496765,\n",
       "   0.8500000238418579,\n",
       "   0.8519999980926514,\n",
       "   0.8539999723434448]},\n",
       " 'epochs_30_batch_32': {'loss': [1.525641918182373,\n",
       "   1.4192591905593872,\n",
       "   1.3192670345306396,\n",
       "   1.1930314302444458,\n",
       "   1.0669025182724,\n",
       "   0.953999400138855,\n",
       "   0.8592962622642517,\n",
       "   0.7808209657669067,\n",
       "   0.7120006680488586,\n",
       "   0.6543492674827576,\n",
       "   0.6010725498199463,\n",
       "   0.5567771196365356,\n",
       "   0.5160099267959595,\n",
       "   0.4782094955444336,\n",
       "   0.44632938504219055,\n",
       "   0.4172484874725342,\n",
       "   0.39013639092445374,\n",
       "   0.3671180307865143,\n",
       "   0.34356117248535156,\n",
       "   0.3231129050254822,\n",
       "   0.30350545048713684,\n",
       "   0.2869010269641876,\n",
       "   0.26831379532814026,\n",
       "   0.253677636384964,\n",
       "   0.23656196892261505,\n",
       "   0.22388845682144165,\n",
       "   0.2101147174835205,\n",
       "   0.1984669417142868,\n",
       "   0.18522115051746368,\n",
       "   0.17491525411605835],\n",
       "  'accuracy': [0.47820255160331726,\n",
       "   0.48893359303474426,\n",
       "   0.5077129602432251,\n",
       "   0.5707578659057617,\n",
       "   0.6512407660484314,\n",
       "   0.706908106803894,\n",
       "   0.7357478141784668,\n",
       "   0.7565392255783081,\n",
       "   0.7826961874961853,\n",
       "   0.7954393029212952,\n",
       "   0.8155600428581238,\n",
       "   0.8303152322769165,\n",
       "   0.8443997502326965,\n",
       "   0.8531187176704407,\n",
       "   0.8665325045585632,\n",
       "   0.8779342770576477,\n",
       "   0.8859825730323792,\n",
       "   0.8980550169944763,\n",
       "   0.9067739844322205,\n",
       "   0.9141515493392944,\n",
       "   0.920187771320343,\n",
       "   0.9268947243690491,\n",
       "   0.9322602152824402,\n",
       "   0.9362843632698059,\n",
       "   0.9416499137878418,\n",
       "   0.9456740617752075,\n",
       "   0.9476861357688904,\n",
       "   0.9543930292129517,\n",
       "   0.9570757746696472,\n",
       "   0.9557344317436218],\n",
       "  'val_loss': [1.4709211587905884,\n",
       "   1.395918607711792,\n",
       "   1.2889560461044312,\n",
       "   1.1848517656326294,\n",
       "   1.0644102096557617,\n",
       "   0.9818404912948608,\n",
       "   0.9023860096931458,\n",
       "   0.8320106863975525,\n",
       "   0.7846473455429077,\n",
       "   0.7331324815750122,\n",
       "   0.695446252822876,\n",
       "   0.6678646802902222,\n",
       "   0.6373410820960999,\n",
       "   0.6104020476341248,\n",
       "   0.5983918905258179,\n",
       "   0.5679450035095215,\n",
       "   0.5536542534828186,\n",
       "   0.5394300818443298,\n",
       "   0.5231085419654846,\n",
       "   0.5149297714233398,\n",
       "   0.5025195479393005,\n",
       "   0.4925025701522827,\n",
       "   0.4902881681919098,\n",
       "   0.48276546597480774,\n",
       "   0.47777530550956726,\n",
       "   0.46655258536338806,\n",
       "   0.47322869300842285,\n",
       "   0.4608611464500427,\n",
       "   0.4525032341480255,\n",
       "   0.45450010895729065],\n",
       "  'val_accuracy': [0.4699999988079071,\n",
       "   0.4699999988079071,\n",
       "   0.515999972820282,\n",
       "   0.5920000076293945,\n",
       "   0.6779999732971191,\n",
       "   0.6800000071525574,\n",
       "   0.7059999704360962,\n",
       "   0.722000002861023,\n",
       "   0.734000027179718,\n",
       "   0.7580000162124634,\n",
       "   0.7900000214576721,\n",
       "   0.777999997138977,\n",
       "   0.7860000133514404,\n",
       "   0.8059999942779541,\n",
       "   0.8100000023841858,\n",
       "   0.828000009059906,\n",
       "   0.8299999833106995,\n",
       "   0.8299999833106995,\n",
       "   0.8399999737739563,\n",
       "   0.8339999914169312,\n",
       "   0.843999981880188,\n",
       "   0.8360000252723694,\n",
       "   0.8320000171661377,\n",
       "   0.8339999914169312,\n",
       "   0.8339999914169312,\n",
       "   0.8339999914169312,\n",
       "   0.8420000076293945,\n",
       "   0.8420000076293945,\n",
       "   0.8379999995231628,\n",
       "   0.8379999995231628]},\n",
       " 'epochs_30_batch_64': {'loss': [1.567644476890564,\n",
       "   1.4546061754226685,\n",
       "   1.423774242401123,\n",
       "   1.3756518363952637,\n",
       "   1.3179564476013184,\n",
       "   1.2514711618423462,\n",
       "   1.179093837738037,\n",
       "   1.1099486351013184,\n",
       "   1.03938627243042,\n",
       "   0.971197247505188,\n",
       "   0.9061827659606934,\n",
       "   0.8481545448303223,\n",
       "   0.7932606935501099,\n",
       "   0.7435696721076965,\n",
       "   0.6979829668998718,\n",
       "   0.6550719738006592,\n",
       "   0.6188338398933411,\n",
       "   0.5830677151679993,\n",
       "   0.5490968823432922,\n",
       "   0.5203506350517273,\n",
       "   0.4934157431125641,\n",
       "   0.4654328227043152,\n",
       "   0.4432210624217987,\n",
       "   0.4195069372653961,\n",
       "   0.3965967297554016,\n",
       "   0.3770120441913605,\n",
       "   0.35915741324424744,\n",
       "   0.340710312128067,\n",
       "   0.3232208490371704,\n",
       "   0.30723094940185547],\n",
       "  'accuracy': [0.46277666091918945,\n",
       "   0.48893359303474426,\n",
       "   0.48893359303474426,\n",
       "   0.48893359303474426,\n",
       "   0.49564051628112793,\n",
       "   0.5224681496620178,\n",
       "   0.5720992684364319,\n",
       "   0.6244131326675415,\n",
       "   0.6666666865348816,\n",
       "   0.7109322547912598,\n",
       "   0.7303823232650757,\n",
       "   0.7417840361595154,\n",
       "   0.761904776096344,\n",
       "   0.7712944149971008,\n",
       "   0.786720335483551,\n",
       "   0.7914151549339294,\n",
       "   0.8061703443527222,\n",
       "   0.8155600428581238,\n",
       "   0.8289738297462463,\n",
       "   0.8437290191650391,\n",
       "   0.8457410931587219,\n",
       "   0.8578135371208191,\n",
       "   0.8698859810829163,\n",
       "   0.8819584250450134,\n",
       "   0.8873239159584045,\n",
       "   0.8973842859268188,\n",
       "   0.9034205079078674,\n",
       "   0.9134808778762817,\n",
       "   0.9188464283943176,\n",
       "   0.9248826503753662],\n",
       "  'val_loss': [1.4898327589035034,\n",
       "   1.4587663412094116,\n",
       "   1.4285928010940552,\n",
       "   1.4028421640396118,\n",
       "   1.329649567604065,\n",
       "   1.2715510129928589,\n",
       "   1.2205201387405396,\n",
       "   1.1581131219863892,\n",
       "   1.0931811332702637,\n",
       "   1.035339593887329,\n",
       "   0.9909176826477051,\n",
       "   0.9371812343597412,\n",
       "   0.8901230692863464,\n",
       "   0.8512277007102966,\n",
       "   0.8227260708808899,\n",
       "   0.7885149717330933,\n",
       "   0.7635937333106995,\n",
       "   0.7400922775268555,\n",
       "   0.711065411567688,\n",
       "   0.6924542188644409,\n",
       "   0.6816807389259338,\n",
       "   0.6479864120483398,\n",
       "   0.6391511559486389,\n",
       "   0.6297786235809326,\n",
       "   0.6192180514335632,\n",
       "   0.617603063583374,\n",
       "   0.5969169735908508,\n",
       "   0.58646559715271,\n",
       "   0.5809577703475952,\n",
       "   0.562522828578949],\n",
       "  'val_accuracy': [0.4699999988079071,\n",
       "   0.4699999988079071,\n",
       "   0.4699999988079071,\n",
       "   0.4699999988079071,\n",
       "   0.4959999918937683,\n",
       "   0.5099999904632568,\n",
       "   0.5299999713897705,\n",
       "   0.5979999899864197,\n",
       "   0.6660000085830688,\n",
       "   0.6779999732971191,\n",
       "   0.6840000152587891,\n",
       "   0.7080000042915344,\n",
       "   0.7160000205039978,\n",
       "   0.7279999852180481,\n",
       "   0.7279999852180481,\n",
       "   0.7400000095367432,\n",
       "   0.7379999756813049,\n",
       "   0.7480000257492065,\n",
       "   0.7699999809265137,\n",
       "   0.7799999713897705,\n",
       "   0.7699999809265137,\n",
       "   0.8019999861717224,\n",
       "   0.7960000038146973,\n",
       "   0.800000011920929,\n",
       "   0.8080000281333923,\n",
       "   0.8100000023841858,\n",
       "   0.8059999942779541,\n",
       "   0.8180000185966492,\n",
       "   0.8159999847412109,\n",
       "   0.8220000267028809]},\n",
       " 'epochs_60_batch_16': {'loss': [1.5006461143493652,\n",
       "   1.3494367599487305,\n",
       "   1.1510331630706787,\n",
       "   0.9583751559257507,\n",
       "   0.8125541806221008,\n",
       "   0.7053474187850952,\n",
       "   0.6254512071609497,\n",
       "   0.5621907711029053,\n",
       "   0.5089187622070312,\n",
       "   0.46272388100624084,\n",
       "   0.4211560785770416,\n",
       "   0.3855157792568207,\n",
       "   0.3555058240890503,\n",
       "   0.32819658517837524,\n",
       "   0.30341923236846924,\n",
       "   0.2796189486980438,\n",
       "   0.2590012848377228,\n",
       "   0.23895876109600067,\n",
       "   0.22015826404094696,\n",
       "   0.20483700931072235,\n",
       "   0.18881498277187347,\n",
       "   0.17518985271453857,\n",
       "   0.16024532914161682,\n",
       "   0.14893755316734314,\n",
       "   0.13577905297279358,\n",
       "   0.12487639486789703,\n",
       "   0.1163029745221138,\n",
       "   0.10723168402910233,\n",
       "   0.09876315295696259,\n",
       "   0.09009665250778198,\n",
       "   0.08279357105493546,\n",
       "   0.07575785368680954,\n",
       "   0.0701802521944046,\n",
       "   0.06434409320354462,\n",
       "   0.05863632261753082,\n",
       "   0.054163798689842224,\n",
       "   0.04954109713435173,\n",
       "   0.04574311152100563,\n",
       "   0.04150022938847542,\n",
       "   0.03811408951878548,\n",
       "   0.03434762731194496,\n",
       "   0.032109878957271576,\n",
       "   0.028989940881729126,\n",
       "   0.025708498433232307,\n",
       "   0.02434631809592247,\n",
       "   0.02177022397518158,\n",
       "   0.019952276721596718,\n",
       "   0.018027912825345993,\n",
       "   0.016536392271518707,\n",
       "   0.014504749327898026,\n",
       "   0.01354963332414627,\n",
       "   0.011953090317547321,\n",
       "   0.01074239332228899,\n",
       "   0.00965134147554636,\n",
       "   0.00861517433077097,\n",
       "   0.00772396195679903,\n",
       "   0.007119451183825731,\n",
       "   0.00618913397192955,\n",
       "   0.00539142033085227,\n",
       "   0.00508385244756937],\n",
       "  'accuracy': [0.4761904776096344,\n",
       "   0.5030180811882019,\n",
       "   0.5888665318489075,\n",
       "   0.7015426158905029,\n",
       "   0.7578806281089783,\n",
       "   0.7894030809402466,\n",
       "   0.8101944923400879,\n",
       "   0.8309859037399292,\n",
       "   0.8484238982200623,\n",
       "   0.8651911616325378,\n",
       "   0.8832998275756836,\n",
       "   0.8947015404701233,\n",
       "   0.9040912389755249,\n",
       "   0.9188464283943176,\n",
       "   0.9228705763816833,\n",
       "   0.9322602152824402,\n",
       "   0.9369550347328186,\n",
       "   0.94500333070755,\n",
       "   0.9463447332382202,\n",
       "   0.9483568072319031,\n",
       "   0.9557344317436218,\n",
       "   0.9577465057373047,\n",
       "   0.9637826681137085,\n",
       "   0.9657947421073914,\n",
       "   0.9725016951560974,\n",
       "   0.975184440612793,\n",
       "   0.9745137691497803,\n",
       "   0.9798792600631714,\n",
       "   0.9825620651245117,\n",
       "   0.9825620651245117,\n",
       "   0.9852448105812073,\n",
       "   0.9865862131118774,\n",
       "   0.9865862131118774,\n",
       "   0.9872568845748901,\n",
       "   0.9885982275009155,\n",
       "   0.9885982275009155,\n",
       "   0.9906103014945984,\n",
       "   0.9926223754882812,\n",
       "   0.9953051805496216,\n",
       "   0.9932931065559387,\n",
       "   0.9959758520126343,\n",
       "   0.9946344494819641,\n",
       "   0.9959758520126343,\n",
       "   0.9973172545433044,\n",
       "   0.996646523475647,\n",
       "   0.996646523475647,\n",
       "   0.9973172545433044,\n",
       "   0.9973172545433044,\n",
       "   0.9973172545433044,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'val_loss': [1.4472410678863525,\n",
       "   1.292754054069519,\n",
       "   1.0930266380310059,\n",
       "   0.9338040947914124,\n",
       "   0.8171365261077881,\n",
       "   0.7396458387374878,\n",
       "   0.6833223104476929,\n",
       "   0.6362442374229431,\n",
       "   0.6069052815437317,\n",
       "   0.5752005577087402,\n",
       "   0.5487675070762634,\n",
       "   0.5422075986862183,\n",
       "   0.5097042322158813,\n",
       "   0.5018559694290161,\n",
       "   0.4883062541484833,\n",
       "   0.47445911169052124,\n",
       "   0.4580343961715698,\n",
       "   0.4579453766345978,\n",
       "   0.4690350890159607,\n",
       "   0.4501822888851166,\n",
       "   0.44765177369117737,\n",
       "   0.44159746170043945,\n",
       "   0.4362446069717407,\n",
       "   0.4361352324485779,\n",
       "   0.4493177831172943,\n",
       "   0.4444355368614197,\n",
       "   0.4352290630340576,\n",
       "   0.43439847230911255,\n",
       "   0.4312717914581299,\n",
       "   0.4380590319633484,\n",
       "   0.4245252013206482,\n",
       "   0.4438900649547577,\n",
       "   0.42309969663619995,\n",
       "   0.44658052921295166,\n",
       "   0.4572002589702606,\n",
       "   0.4507673680782318,\n",
       "   0.44753509759902954,\n",
       "   0.44758662581443787,\n",
       "   0.45943471789360046,\n",
       "   0.44255316257476807,\n",
       "   0.46351367235183716,\n",
       "   0.45690423250198364,\n",
       "   0.4458353817462921,\n",
       "   0.4875091314315796,\n",
       "   0.4660821259021759,\n",
       "   0.4627130627632141,\n",
       "   0.48480507731437683,\n",
       "   0.5000026226043701,\n",
       "   0.4840736985206604,\n",
       "   0.484812468290329,\n",
       "   0.49524977803230286,\n",
       "   0.5083153247833252,\n",
       "   0.5077856779098511,\n",
       "   0.523366391658783,\n",
       "   0.5099523663520813,\n",
       "   0.541790246963501,\n",
       "   0.5135983824729919,\n",
       "   0.5188230872154236,\n",
       "   0.5303778052330017,\n",
       "   0.5296949744224548],\n",
       "  'val_accuracy': [0.4699999988079071,\n",
       "   0.49799999594688416,\n",
       "   0.6159999966621399,\n",
       "   0.7099999785423279,\n",
       "   0.7440000176429749,\n",
       "   0.7900000214576721,\n",
       "   0.7960000038146973,\n",
       "   0.8140000104904175,\n",
       "   0.8199999928474426,\n",
       "   0.8299999833106995,\n",
       "   0.8320000171661377,\n",
       "   0.8320000171661377,\n",
       "   0.8339999914169312,\n",
       "   0.8339999914169312,\n",
       "   0.8360000252723694,\n",
       "   0.8479999899864197,\n",
       "   0.8539999723434448,\n",
       "   0.8500000238418579,\n",
       "   0.8479999899864197,\n",
       "   0.8500000238418579,\n",
       "   0.8560000061988831,\n",
       "   0.8539999723434448,\n",
       "   0.8560000061988831,\n",
       "   0.8479999899864197,\n",
       "   0.8619999885559082,\n",
       "   0.8560000061988831,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8619999885559082,\n",
       "   0.8619999885559082,\n",
       "   0.8600000143051147,\n",
       "   0.8579999804496765,\n",
       "   0.8579999804496765,\n",
       "   0.8619999885559082,\n",
       "   0.8640000224113464,\n",
       "   0.8640000224113464,\n",
       "   0.8640000224113464,\n",
       "   0.8679999709129333,\n",
       "   0.8640000224113464,\n",
       "   0.8679999709129333,\n",
       "   0.8679999709129333,\n",
       "   0.8640000224113464,\n",
       "   0.8659999966621399,\n",
       "   0.8700000047683716,\n",
       "   0.8640000224113464,\n",
       "   0.8679999709129333,\n",
       "   0.8679999709129333,\n",
       "   0.8700000047683716,\n",
       "   0.8700000047683716,\n",
       "   0.8700000047683716,\n",
       "   0.8679999709129333,\n",
       "   0.8679999709129333,\n",
       "   0.8640000224113464,\n",
       "   0.8679999709129333,\n",
       "   0.8679999709129333,\n",
       "   0.8659999966621399,\n",
       "   0.871999979019165,\n",
       "   0.8740000128746033]},\n",
       " 'epochs_60_batch_32': {'loss': [1.509104609489441,\n",
       "   1.4157284498214722,\n",
       "   1.3133869171142578,\n",
       "   1.1824672222137451,\n",
       "   1.0581419467926025,\n",
       "   0.9441144466400146,\n",
       "   0.8508828282356262,\n",
       "   0.7710168361663818,\n",
       "   0.7017108201980591,\n",
       "   0.6431706547737122,\n",
       "   0.5892490148544312,\n",
       "   0.5437140464782715,\n",
       "   0.502327024936676,\n",
       "   0.4659978151321411,\n",
       "   0.4322068989276886,\n",
       "   0.4029199481010437,\n",
       "   0.3769857883453369,\n",
       "   0.35021117329597473,\n",
       "   0.3280177116394043,\n",
       "   0.3078310489654541,\n",
       "   0.2877815067768097,\n",
       "   0.27067649364471436,\n",
       "   0.25249046087265015,\n",
       "   0.23661023378372192,\n",
       "   0.2220582365989685,\n",
       "   0.20745043456554413,\n",
       "   0.19377051293849945,\n",
       "   0.18181222677230835,\n",
       "   0.1708090901374817,\n",
       "   0.15898418426513672,\n",
       "   0.1495828628540039,\n",
       "   0.13925153017044067,\n",
       "   0.1298607587814331,\n",
       "   0.12218032777309418,\n",
       "   0.11368165165185928,\n",
       "   0.10693074762821198,\n",
       "   0.09869859367609024,\n",
       "   0.09323492646217346,\n",
       "   0.08660995960235596,\n",
       "   0.08025949448347092,\n",
       "   0.07507172226905823,\n",
       "   0.070161834359169,\n",
       "   0.06433873623609543,\n",
       "   0.06047777086496353,\n",
       "   0.056114666163921356,\n",
       "   0.05189960449934006,\n",
       "   0.048120126128196716,\n",
       "   0.04434637352824211,\n",
       "   0.04105101153254509,\n",
       "   0.038120727986097336,\n",
       "   0.03513241931796074,\n",
       "   0.03234921768307686,\n",
       "   0.02939566597342491,\n",
       "   0.027388038113713264,\n",
       "   0.0254609864205122,\n",
       "   0.022981585934758186,\n",
       "   0.021190600469708443,\n",
       "   0.019430313259363174,\n",
       "   0.017699597403407097,\n",
       "   0.016399674117565155],\n",
       "  'accuracy': [0.4815559983253479,\n",
       "   0.48893359303474426,\n",
       "   0.509725034236908,\n",
       "   0.5747820138931274,\n",
       "   0.6626425385475159,\n",
       "   0.7223340272903442,\n",
       "   0.7471495866775513,\n",
       "   0.7686116695404053,\n",
       "   0.786720335483551,\n",
       "   0.8088530898094177,\n",
       "   0.8182427883148193,\n",
       "   0.8397048711776733,\n",
       "   0.849094569683075,\n",
       "   0.8571428656578064,\n",
       "   0.8732394576072693,\n",
       "   0.8819584250450134,\n",
       "   0.8900067210197449,\n",
       "   0.9014084339141846,\n",
       "   0.9034205079078674,\n",
       "   0.9154929518699646,\n",
       "   0.9208585023880005,\n",
       "   0.9248826503753662,\n",
       "   0.9315895438194275,\n",
       "   0.9382964372634888,\n",
       "   0.94500333070755,\n",
       "   0.9503688812255859,\n",
       "   0.9530516266822815,\n",
       "   0.9570757746696472,\n",
       "   0.9604292511940002,\n",
       "   0.9657947421073914,\n",
       "   0.9684775471687317,\n",
       "   0.9731723666191101,\n",
       "   0.975184440612793,\n",
       "   0.9765258431434631,\n",
       "   0.978537917137146,\n",
       "   0.9798792600631714,\n",
       "   0.9798792600631714,\n",
       "   0.9832327365875244,\n",
       "   0.9852448105812073,\n",
       "   0.9845741391181946,\n",
       "   0.9865862131118774,\n",
       "   0.9879275560379028,\n",
       "   0.989268958568573,\n",
       "   0.9906103014945984,\n",
       "   0.9919517040252686,\n",
       "   0.9926223754882812,\n",
       "   0.9919517040252686,\n",
       "   0.9926223754882812,\n",
       "   0.9939637780189514,\n",
       "   0.9953051805496216,\n",
       "   0.9953051805496216,\n",
       "   0.9959758520126343,\n",
       "   0.996646523475647,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9986585974693298,\n",
       "   0.9993293285369873,\n",
       "   0.9979879260063171],\n",
       "  'val_loss': [1.48003089427948,\n",
       "   1.412483811378479,\n",
       "   1.2910406589508057,\n",
       "   1.1793036460876465,\n",
       "   1.0641562938690186,\n",
       "   0.9700119495391846,\n",
       "   0.8896604776382446,\n",
       "   0.8271570801734924,\n",
       "   0.77154940366745,\n",
       "   0.7276648879051208,\n",
       "   0.6750723123550415,\n",
       "   0.6534972190856934,\n",
       "   0.6202729940414429,\n",
       "   0.5936394929885864,\n",
       "   0.5648249387741089,\n",
       "   0.5560116767883301,\n",
       "   0.53242027759552,\n",
       "   0.5289387702941895,\n",
       "   0.5145674347877502,\n",
       "   0.4903653562068939,\n",
       "   0.48545414209365845,\n",
       "   0.47913452982902527,\n",
       "   0.46396178007125854,\n",
       "   0.4600461721420288,\n",
       "   0.45446985960006714,\n",
       "   0.4490695893764496,\n",
       "   0.4331490099430084,\n",
       "   0.44115960597991943,\n",
       "   0.4344736337661743,\n",
       "   0.42395251989364624,\n",
       "   0.4190811812877655,\n",
       "   0.42570412158966064,\n",
       "   0.4303508996963501,\n",
       "   0.418184757232666,\n",
       "   0.421773761510849,\n",
       "   0.4175267219543457,\n",
       "   0.4249477982521057,\n",
       "   0.41551920771598816,\n",
       "   0.4186217188835144,\n",
       "   0.4192858934402466,\n",
       "   0.4190709590911865,\n",
       "   0.4201887547969818,\n",
       "   0.42548516392707825,\n",
       "   0.4189212918281555,\n",
       "   0.42223694920539856,\n",
       "   0.4322216808795929,\n",
       "   0.4139235019683838,\n",
       "   0.42479637265205383,\n",
       "   0.41448211669921875,\n",
       "   0.42590346932411194,\n",
       "   0.42798399925231934,\n",
       "   0.4407936632633209,\n",
       "   0.4608825445175171,\n",
       "   0.45696666836738586,\n",
       "   0.4562023878097534,\n",
       "   0.46056631207466125,\n",
       "   0.439937025308609,\n",
       "   0.46720826625823975,\n",
       "   0.4528859555721283,\n",
       "   0.4580117464065552],\n",
       "  'val_accuracy': [0.4699999988079071,\n",
       "   0.4699999988079071,\n",
       "   0.5180000066757202,\n",
       "   0.6000000238418579,\n",
       "   0.671999990940094,\n",
       "   0.7020000219345093,\n",
       "   0.7260000109672546,\n",
       "   0.7419999837875366,\n",
       "   0.7519999742507935,\n",
       "   0.7559999823570251,\n",
       "   0.7979999780654907,\n",
       "   0.7860000133514404,\n",
       "   0.8059999942779541,\n",
       "   0.8059999942779541,\n",
       "   0.8180000185966492,\n",
       "   0.8119999766349792,\n",
       "   0.8220000267028809,\n",
       "   0.8180000185966492,\n",
       "   0.8259999752044678,\n",
       "   0.828000009059906,\n",
       "   0.8240000009536743,\n",
       "   0.8299999833106995,\n",
       "   0.8360000252723694,\n",
       "   0.8420000076293945,\n",
       "   0.8379999995231628,\n",
       "   0.843999981880188,\n",
       "   0.8460000157356262,\n",
       "   0.8379999995231628,\n",
       "   0.8479999899864197,\n",
       "   0.843999981880188,\n",
       "   0.8519999980926514,\n",
       "   0.8600000143051147,\n",
       "   0.8579999804496765,\n",
       "   0.8539999723434448,\n",
       "   0.8539999723434448,\n",
       "   0.8560000061988831,\n",
       "   0.8579999804496765,\n",
       "   0.8560000061988831,\n",
       "   0.8640000224113464,\n",
       "   0.8659999966621399,\n",
       "   0.8619999885559082,\n",
       "   0.8619999885559082,\n",
       "   0.8659999966621399,\n",
       "   0.8619999885559082,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8619999885559082,\n",
       "   0.8640000224113464,\n",
       "   0.8619999885559082,\n",
       "   0.8619999885559082,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8640000224113464,\n",
       "   0.8600000143051147,\n",
       "   0.8640000224113464,\n",
       "   0.8579999804496765,\n",
       "   0.8579999804496765,\n",
       "   0.8619999885559082,\n",
       "   0.8600000143051147,\n",
       "   0.8619999885559082]},\n",
       " 'epochs_60_batch_64': {'loss': [1.5668563842773438,\n",
       "   1.4570575952529907,\n",
       "   1.426767349243164,\n",
       "   1.376853108406067,\n",
       "   1.3172606229782104,\n",
       "   1.2539246082305908,\n",
       "   1.183009147644043,\n",
       "   1.112243413925171,\n",
       "   1.0411909818649292,\n",
       "   0.9746353030204773,\n",
       "   0.9085698127746582,\n",
       "   0.8496717810630798,\n",
       "   0.7955388426780701,\n",
       "   0.7449251413345337,\n",
       "   0.6996733546257019,\n",
       "   0.6574230790138245,\n",
       "   0.6199158430099487,\n",
       "   0.5844228863716125,\n",
       "   0.5512703061103821,\n",
       "   0.5221986174583435,\n",
       "   0.49388715624809265,\n",
       "   0.46780791878700256,\n",
       "   0.44393736124038696,\n",
       "   0.42104804515838623,\n",
       "   0.39819562435150146,\n",
       "   0.3793136775493622,\n",
       "   0.35805708169937134,\n",
       "   0.34137099981307983,\n",
       "   0.3249646723270416,\n",
       "   0.30768802762031555,\n",
       "   0.2927938401699066,\n",
       "   0.2781859338283539,\n",
       "   0.26450181007385254,\n",
       "   0.2509618401527405,\n",
       "   0.23895631730556488,\n",
       "   0.226942777633667,\n",
       "   0.21505708992481232,\n",
       "   0.20378538966178894,\n",
       "   0.19416731595993042,\n",
       "   0.18388253450393677,\n",
       "   0.17316944897174835,\n",
       "   0.16425061225891113,\n",
       "   0.1560257077217102,\n",
       "   0.14774711430072784,\n",
       "   0.13964876532554626,\n",
       "   0.13222810626029968,\n",
       "   0.12501047551631927,\n",
       "   0.11820493638515472,\n",
       "   0.11176051944494247,\n",
       "   0.10566792637109756,\n",
       "   0.09977669268846512,\n",
       "   0.09423492103815079,\n",
       "   0.08911368250846863,\n",
       "   0.08349855244159698,\n",
       "   0.0790925920009613,\n",
       "   0.07478717714548111,\n",
       "   0.07030732929706573,\n",
       "   0.066353440284729,\n",
       "   0.06237480416893959,\n",
       "   0.058586958795785904],\n",
       "  'accuracy': [0.47417840361595154,\n",
       "   0.48893359303474426,\n",
       "   0.48893359303474426,\n",
       "   0.48960429430007935,\n",
       "   0.5003353357315063,\n",
       "   0.520456075668335,\n",
       "   0.5680751204490662,\n",
       "   0.6156941652297974,\n",
       "   0.6733735799789429,\n",
       "   0.6941649913787842,\n",
       "   0.7223340272903442,\n",
       "   0.7404426336288452,\n",
       "   0.7525150775909424,\n",
       "   0.7773306369781494,\n",
       "   0.7780013680458069,\n",
       "   0.7927565574645996,\n",
       "   0.7994634509086609,\n",
       "   0.8122065663337708,\n",
       "   0.8236083388328552,\n",
       "   0.8289738297462463,\n",
       "   0.8450704216957092,\n",
       "   0.8618376851081848,\n",
       "   0.8665325045585632,\n",
       "   0.8806170225143433,\n",
       "   0.8920187950134277,\n",
       "   0.9007377624511719,\n",
       "   0.909456729888916,\n",
       "   0.9134808778762817,\n",
       "   0.9175050258636475,\n",
       "   0.9255533218383789,\n",
       "   0.9282360672950745,\n",
       "   0.9382964372634888,\n",
       "   0.9396378397941589,\n",
       "   0.9409791827201843,\n",
       "   0.94500333070755,\n",
       "   0.9523809552192688,\n",
       "   0.9530516266822815,\n",
       "   0.9564051032066345,\n",
       "   0.9597585797309875,\n",
       "   0.9624413251876831,\n",
       "   0.9624413251876831,\n",
       "   0.9704896211624146,\n",
       "   0.9718309640884399,\n",
       "   0.9725016951560974,\n",
       "   0.9765258431434631,\n",
       "   0.9771965146064758,\n",
       "   0.978537917137146,\n",
       "   0.9805499911308289,\n",
       "   0.9825620651245117,\n",
       "   0.9832327365875244,\n",
       "   0.9839034080505371,\n",
       "   0.9845741391181946,\n",
       "   0.98591548204422,\n",
       "   0.9879275560379028,\n",
       "   0.9885982275009155,\n",
       "   0.9879275560379028,\n",
       "   0.9912810325622559,\n",
       "   0.9906103014945984,\n",
       "   0.9919517040252686,\n",
       "   0.9912810325622559],\n",
       "  'val_loss': [1.4957393407821655,\n",
       "   1.4638943672180176,\n",
       "   1.4204113483428955,\n",
       "   1.3837363719940186,\n",
       "   1.3542827367782593,\n",
       "   1.2657541036605835,\n",
       "   1.2046209573745728,\n",
       "   1.141789436340332,\n",
       "   1.0890469551086426,\n",
       "   1.021645188331604,\n",
       "   0.9613277912139893,\n",
       "   0.9156765937805176,\n",
       "   0.8639646768569946,\n",
       "   0.8382092118263245,\n",
       "   0.7933527827262878,\n",
       "   0.7809720635414124,\n",
       "   0.7291756272315979,\n",
       "   0.7113543748855591,\n",
       "   0.6805422306060791,\n",
       "   0.6606248617172241,\n",
       "   0.6515526175498962,\n",
       "   0.6260358691215515,\n",
       "   0.6183709502220154,\n",
       "   0.6008424758911133,\n",
       "   0.5910256505012512,\n",
       "   0.5784914493560791,\n",
       "   0.5757871866226196,\n",
       "   0.5667741894721985,\n",
       "   0.5460329651832581,\n",
       "   0.5531956553459167,\n",
       "   0.5343183875083923,\n",
       "   0.5285356044769287,\n",
       "   0.5192897915840149,\n",
       "   0.5079472064971924,\n",
       "   0.5177236199378967,\n",
       "   0.5025336146354675,\n",
       "   0.509242057800293,\n",
       "   0.49615421891212463,\n",
       "   0.49448031187057495,\n",
       "   0.4871315658092499,\n",
       "   0.4875754714012146,\n",
       "   0.48039761185646057,\n",
       "   0.47425907850265503,\n",
       "   0.46942222118377686,\n",
       "   0.4747260808944702,\n",
       "   0.46567925810813904,\n",
       "   0.46810564398765564,\n",
       "   0.46439099311828613,\n",
       "   0.45771825313568115,\n",
       "   0.46113887429237366,\n",
       "   0.45433157682418823,\n",
       "   0.4562545716762543,\n",
       "   0.45285218954086304,\n",
       "   0.45982974767684937,\n",
       "   0.45940831303596497,\n",
       "   0.46040552854537964,\n",
       "   0.46793338656425476,\n",
       "   0.4603196680545807,\n",
       "   0.4566503167152405,\n",
       "   0.44898679852485657],\n",
       "  'val_accuracy': [0.4699999988079071,\n",
       "   0.4699999988079071,\n",
       "   0.4699999988079071,\n",
       "   0.4699999988079071,\n",
       "   0.4699999988079071,\n",
       "   0.5519999861717224,\n",
       "   0.6039999723434448,\n",
       "   0.6060000061988831,\n",
       "   0.5960000157356262,\n",
       "   0.6819999814033508,\n",
       "   0.7020000219345093,\n",
       "   0.7020000219345093,\n",
       "   0.7379999756813049,\n",
       "   0.722000002861023,\n",
       "   0.7459999918937683,\n",
       "   0.7379999756813049,\n",
       "   0.7699999809265137,\n",
       "   0.7720000147819519,\n",
       "   0.7839999794960022,\n",
       "   0.7940000295639038,\n",
       "   0.7960000038146973,\n",
       "   0.7979999780654907,\n",
       "   0.7979999780654907,\n",
       "   0.8119999766349792,\n",
       "   0.8080000281333923,\n",
       "   0.8100000023841858,\n",
       "   0.8080000281333923,\n",
       "   0.8180000185966492,\n",
       "   0.8240000009536743,\n",
       "   0.8159999847412109,\n",
       "   0.8299999833106995,\n",
       "   0.8240000009536743,\n",
       "   0.8299999833106995,\n",
       "   0.8320000171661377,\n",
       "   0.8339999914169312,\n",
       "   0.8259999752044678,\n",
       "   0.8339999914169312,\n",
       "   0.8320000171661377,\n",
       "   0.8339999914169312,\n",
       "   0.828000009059906,\n",
       "   0.8339999914169312,\n",
       "   0.8399999737739563,\n",
       "   0.8379999995231628,\n",
       "   0.8339999914169312,\n",
       "   0.843999981880188,\n",
       "   0.8299999833106995,\n",
       "   0.8339999914169312,\n",
       "   0.8360000252723694,\n",
       "   0.8339999914169312,\n",
       "   0.8320000171661377,\n",
       "   0.8320000171661377,\n",
       "   0.8360000252723694,\n",
       "   0.8320000171661377,\n",
       "   0.8360000252723694,\n",
       "   0.8339999914169312,\n",
       "   0.8399999737739563,\n",
       "   0.8420000076293945,\n",
       "   0.8379999995231628,\n",
       "   0.8379999995231628,\n",
       "   0.8399999737739563]},\n",
       " 'epochs_90_batch_16': {'loss': [1.5038625001907349,\n",
       "   1.3520290851593018,\n",
       "   1.1589945554733276,\n",
       "   0.9836320281028748,\n",
       "   0.8507609963417053,\n",
       "   0.7525240778923035,\n",
       "   0.6723069548606873,\n",
       "   0.6072290539741516,\n",
       "   0.5513720512390137,\n",
       "   0.5040721893310547,\n",
       "   0.460490882396698,\n",
       "   0.42363405227661133,\n",
       "   0.3903217911720276,\n",
       "   0.35924187302589417,\n",
       "   0.3321062922477722,\n",
       "   0.306485116481781,\n",
       "   0.2832135856151581,\n",
       "   0.2624669373035431,\n",
       "   0.2429845929145813,\n",
       "   0.22542288899421692,\n",
       "   0.20860368013381958,\n",
       "   0.19341585040092468,\n",
       "   0.17980267107486725,\n",
       "   0.16526266932487488,\n",
       "   0.15323340892791748,\n",
       "   0.14212338626384735,\n",
       "   0.1310204416513443,\n",
       "   0.12336587905883789,\n",
       "   0.11330140382051468,\n",
       "   0.10574258863925934,\n",
       "   0.09744144231081009,\n",
       "   0.09046215564012527,\n",
       "   0.08415289968252182,\n",
       "   0.078536257147789,\n",
       "   0.07214967161417007,\n",
       "   0.06748300045728683,\n",
       "   0.0628834143280983,\n",
       "   0.05782104656100273,\n",
       "   0.053519830107688904,\n",
       "   0.04971092939376831,\n",
       "   0.04598677530884743,\n",
       "   0.042928509414196014,\n",
       "   0.039165981113910675,\n",
       "   0.03665519133210182,\n",
       "   0.03369095176458359,\n",
       "   0.031245537102222443,\n",
       "   0.02823135070502758,\n",
       "   0.026012064889073372,\n",
       "   0.0239143967628479,\n",
       "   0.021997632458806038,\n",
       "   0.02042282745242119,\n",
       "   0.018445901572704315,\n",
       "   0.016957862302660942,\n",
       "   0.015516410581767559,\n",
       "   0.014155035838484764,\n",
       "   0.012483582831919193,\n",
       "   0.011134765110909939,\n",
       "   0.009989652782678604,\n",
       "   0.009599654003977776,\n",
       "   0.00837597344070673,\n",
       "   0.007751996163278818,\n",
       "   0.006895820610225201,\n",
       "   0.005880383308976889,\n",
       "   0.005649009719491005,\n",
       "   0.004994711838662624,\n",
       "   0.004488310310989618,\n",
       "   0.00390801765024662,\n",
       "   0.003383494447916746,\n",
       "   0.003135014558210969,\n",
       "   0.0028595575131475925,\n",
       "   0.0026013231836259365,\n",
       "   0.0021867849864065647,\n",
       "   0.001993070589378476,\n",
       "   0.0016957890475168824,\n",
       "   0.0015173079445958138,\n",
       "   0.0014063488924875855,\n",
       "   0.001279404736123979,\n",
       "   0.0010883439099416137,\n",
       "   0.0008920707041397691,\n",
       "   0.0008235613931901753,\n",
       "   0.0007595557835884392,\n",
       "   0.0006290341843850911,\n",
       "   0.0005826391861774027,\n",
       "   0.0005047737504355609,\n",
       "   0.00043878520955331624,\n",
       "   0.00040104982326738536,\n",
       "   0.0003480335872154683,\n",
       "   0.00030504996539093554,\n",
       "   0.00023837551998440176,\n",
       "   0.00024391243641730398],\n",
       "  'accuracy': [0.4828973710536957,\n",
       "   0.49966466426849365,\n",
       "   0.5868544578552246,\n",
       "   0.7035546898841858,\n",
       "   0.7391012907028198,\n",
       "   0.7639168500900269,\n",
       "   0.7860496044158936,\n",
       "   0.8034875988960266,\n",
       "   0.8283031582832336,\n",
       "   0.8497652411460876,\n",
       "   0.8638497591018677,\n",
       "   0.8765928745269775,\n",
       "   0.8906773924827576,\n",
       "   0.8993963599205017,\n",
       "   0.9107981324195862,\n",
       "   0.9188464283943176,\n",
       "   0.9262239933013916,\n",
       "   0.9309188723564148,\n",
       "   0.9409791827201843,\n",
       "   0.9423205852508545,\n",
       "   0.9510395526885986,\n",
       "   0.9503688812255859,\n",
       "   0.9577465057373047,\n",
       "   0.9631119966506958,\n",
       "   0.9671361446380615,\n",
       "   0.9671361446380615,\n",
       "   0.9711602926254272,\n",
       "   0.9718309640884399,\n",
       "   0.9745137691497803,\n",
       "   0.975184440612793,\n",
       "   0.9792085886001587,\n",
       "   0.9792085886001587,\n",
       "   0.9812206625938416,\n",
       "   0.9818913340568542,\n",
       "   0.9845741391181946,\n",
       "   0.9839034080505371,\n",
       "   0.9852448105812073,\n",
       "   0.9879275560379028,\n",
       "   0.9885982275009155,\n",
       "   0.9906103014945984,\n",
       "   0.9906103014945984,\n",
       "   0.9912810325622559,\n",
       "   0.9932931065559387,\n",
       "   0.9919517040252686,\n",
       "   0.9932931065559387,\n",
       "   0.9946344494819641,\n",
       "   0.9953051805496216,\n",
       "   0.9973172545433044,\n",
       "   0.9973172545433044,\n",
       "   0.996646523475647,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9979879260063171,\n",
       "   0.9986585974693298,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9986585974693298,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   1.0,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'val_loss': [1.4532432556152344,\n",
       "   1.2888187170028687,\n",
       "   1.1203428506851196,\n",
       "   0.975835382938385,\n",
       "   0.8731215596199036,\n",
       "   0.7897934317588806,\n",
       "   0.7349376678466797,\n",
       "   0.6919111013412476,\n",
       "   0.6552512049674988,\n",
       "   0.6176348924636841,\n",
       "   0.5866842269897461,\n",
       "   0.5743078589439392,\n",
       "   0.5487317442893982,\n",
       "   0.5281938910484314,\n",
       "   0.5138224959373474,\n",
       "   0.5048488974571228,\n",
       "   0.49933096766471863,\n",
       "   0.491260290145874,\n",
       "   0.4786108434200287,\n",
       "   0.47815290093421936,\n",
       "   0.4730696976184845,\n",
       "   0.47214868664741516,\n",
       "   0.46252748370170593,\n",
       "   0.45991677045822144,\n",
       "   0.46343496441841125,\n",
       "   0.4533785581588745,\n",
       "   0.4660167396068573,\n",
       "   0.4611637592315674,\n",
       "   0.44858676195144653,\n",
       "   0.46068060398101807,\n",
       "   0.4510422348976135,\n",
       "   0.4485226273536682,\n",
       "   0.4608815312385559,\n",
       "   0.456351637840271,\n",
       "   0.46752116084098816,\n",
       "   0.46834561228752136,\n",
       "   0.46149274706840515,\n",
       "   0.4620308578014374,\n",
       "   0.4676784873008728,\n",
       "   0.46451619267463684,\n",
       "   0.4765666425228119,\n",
       "   0.45853668451309204,\n",
       "   0.47553113102912903,\n",
       "   0.48927322030067444,\n",
       "   0.4874058663845062,\n",
       "   0.48125332593917847,\n",
       "   0.5011543035507202,\n",
       "   0.4973728060722351,\n",
       "   0.49319228529930115,\n",
       "   0.5059527158737183,\n",
       "   0.5021271705627441,\n",
       "   0.516533613204956,\n",
       "   0.5238869190216064,\n",
       "   0.5338745713233948,\n",
       "   0.5156055688858032,\n",
       "   0.5240401029586792,\n",
       "   0.5375949144363403,\n",
       "   0.5398099422454834,\n",
       "   0.5464086532592773,\n",
       "   0.5628430843353271,\n",
       "   0.5577259063720703,\n",
       "   0.5636934041976929,\n",
       "   0.6107330322265625,\n",
       "   0.5655349493026733,\n",
       "   0.5711464285850525,\n",
       "   0.5924890637397766,\n",
       "   0.6000955104827881,\n",
       "   0.5873028635978699,\n",
       "   0.5991791486740112,\n",
       "   0.6326242089271545,\n",
       "   0.646704912185669,\n",
       "   0.6248265504837036,\n",
       "   0.6590000987052917,\n",
       "   0.6796478033065796,\n",
       "   0.6657188534736633,\n",
       "   0.6753066182136536,\n",
       "   0.6786732077598572,\n",
       "   0.6873103380203247,\n",
       "   0.6883994340896606,\n",
       "   0.7134222388267517,\n",
       "   0.7222524285316467,\n",
       "   0.7353675961494446,\n",
       "   0.7352824807167053,\n",
       "   0.7379094362258911,\n",
       "   0.7270087003707886,\n",
       "   0.7540830373764038,\n",
       "   0.7549285888671875,\n",
       "   0.7914139032363892,\n",
       "   0.771953821182251,\n",
       "   0.80860835313797],\n",
       "  'val_accuracy': [0.4699999988079071,\n",
       "   0.4959999918937683,\n",
       "   0.6520000100135803,\n",
       "   0.6700000166893005,\n",
       "   0.7239999771118164,\n",
       "   0.7459999918937683,\n",
       "   0.7599999904632568,\n",
       "   0.7639999985694885,\n",
       "   0.7940000295639038,\n",
       "   0.8059999942779541,\n",
       "   0.8180000185966492,\n",
       "   0.8140000104904175,\n",
       "   0.8240000009536743,\n",
       "   0.8320000171661377,\n",
       "   0.8360000252723694,\n",
       "   0.8379999995231628,\n",
       "   0.8299999833106995,\n",
       "   0.8399999737739563,\n",
       "   0.8420000076293945,\n",
       "   0.8379999995231628,\n",
       "   0.8379999995231628,\n",
       "   0.8360000252723694,\n",
       "   0.8360000252723694,\n",
       "   0.8399999737739563,\n",
       "   0.8399999737739563,\n",
       "   0.843999981880188,\n",
       "   0.8379999995231628,\n",
       "   0.8420000076293945,\n",
       "   0.8379999995231628,\n",
       "   0.843999981880188,\n",
       "   0.8420000076293945,\n",
       "   0.8500000238418579,\n",
       "   0.8460000157356262,\n",
       "   0.8460000157356262,\n",
       "   0.8500000238418579,\n",
       "   0.8479999899864197,\n",
       "   0.8539999723434448,\n",
       "   0.8500000238418579,\n",
       "   0.8479999899864197,\n",
       "   0.8479999899864197,\n",
       "   0.8519999980926514,\n",
       "   0.8479999899864197,\n",
       "   0.8519999980926514,\n",
       "   0.8539999723434448,\n",
       "   0.8460000157356262,\n",
       "   0.8519999980926514,\n",
       "   0.8500000238418579,\n",
       "   0.8460000157356262,\n",
       "   0.8539999723434448,\n",
       "   0.8460000157356262,\n",
       "   0.8519999980926514,\n",
       "   0.8500000238418579,\n",
       "   0.8479999899864197,\n",
       "   0.8460000157356262,\n",
       "   0.8600000143051147,\n",
       "   0.8519999980926514,\n",
       "   0.8479999899864197,\n",
       "   0.8519999980926514,\n",
       "   0.8500000238418579,\n",
       "   0.8460000157356262,\n",
       "   0.8479999899864197,\n",
       "   0.8420000076293945,\n",
       "   0.8399999737739563,\n",
       "   0.8479999899864197,\n",
       "   0.8420000076293945,\n",
       "   0.8420000076293945,\n",
       "   0.8479999899864197,\n",
       "   0.8519999980926514,\n",
       "   0.8479999899864197,\n",
       "   0.843999981880188,\n",
       "   0.843999981880188,\n",
       "   0.843999981880188,\n",
       "   0.8420000076293945,\n",
       "   0.8420000076293945,\n",
       "   0.8460000157356262,\n",
       "   0.843999981880188,\n",
       "   0.8460000157356262,\n",
       "   0.8460000157356262,\n",
       "   0.8420000076293945,\n",
       "   0.843999981880188,\n",
       "   0.8460000157356262,\n",
       "   0.8460000157356262,\n",
       "   0.8460000157356262,\n",
       "   0.8420000076293945,\n",
       "   0.843999981880188,\n",
       "   0.8460000157356262,\n",
       "   0.8460000157356262,\n",
       "   0.843999981880188,\n",
       "   0.8479999899864197,\n",
       "   0.843999981880188]},\n",
       " 'epochs_90_batch_32': {'loss': [1.5232279300689697,\n",
       "   1.4243978261947632,\n",
       "   1.3289121389389038,\n",
       "   1.2089852094650269,\n",
       "   1.0885564088821411,\n",
       "   0.9740027189254761,\n",
       "   0.8740010261535645,\n",
       "   0.7904440760612488,\n",
       "   0.7193167805671692,\n",
       "   0.6574074625968933,\n",
       "   0.6035719513893127,\n",
       "   0.5568165183067322,\n",
       "   0.5160699486732483,\n",
       "   0.4778602719306946,\n",
       "   0.44537338614463806,\n",
       "   0.41580238938331604,\n",
       "   0.3874814510345459,\n",
       "   0.3633492588996887,\n",
       "   0.3385937511920929,\n",
       "   0.3190416395664215,\n",
       "   0.29901015758514404,\n",
       "   0.2809223234653473,\n",
       "   0.26254940032958984,\n",
       "   0.24713046848773956,\n",
       "   0.23105329275131226,\n",
       "   0.2164873331785202,\n",
       "   0.20335082709789276,\n",
       "   0.19027042388916016,\n",
       "   0.17855104804039001,\n",
       "   0.16679824888706207,\n",
       "   0.15704911947250366,\n",
       "   0.146620512008667,\n",
       "   0.13704323768615723,\n",
       "   0.12812460958957672,\n",
       "   0.11998205631971359,\n",
       "   0.11187068372964859,\n",
       "   0.10367965698242188,\n",
       "   0.09735580533742905,\n",
       "   0.09044492989778519,\n",
       "   0.08460385352373123,\n",
       "   0.07901568710803986,\n",
       "   0.07289007306098938,\n",
       "   0.06824389845132828,\n",
       "   0.06319936364889145,\n",
       "   0.05867341533303261,\n",
       "   0.054387886077165604,\n",
       "   0.050435420125722885,\n",
       "   0.047168340533971786,\n",
       "   0.04352028667926788,\n",
       "   0.04010637849569321,\n",
       "   0.037069663405418396,\n",
       "   0.03402956202626228,\n",
       "   0.031482331454753876,\n",
       "   0.028759215027093887,\n",
       "   0.026651665568351746,\n",
       "   0.024073349311947823,\n",
       "   0.022464092820882797,\n",
       "   0.020526329055428505,\n",
       "   0.01844147779047489,\n",
       "   0.017390932887792587,\n",
       "   0.015485377050936222,\n",
       "   0.014177713543176651,\n",
       "   0.012999282218515873,\n",
       "   0.011842207051813602,\n",
       "   0.010717147961258888,\n",
       "   0.009575367905199528,\n",
       "   0.008777877315878868,\n",
       "   0.007933887653052807,\n",
       "   0.007253996096551418,\n",
       "   0.00657432246953249,\n",
       "   0.0059461696073412895,\n",
       "   0.005253555253148079,\n",
       "   0.004920559003949165,\n",
       "   0.004453950561583042,\n",
       "   0.003936452325433493,\n",
       "   0.00359284202568233,\n",
       "   0.003244478954002261,\n",
       "   0.002924732631072402,\n",
       "   0.0025911573320627213,\n",
       "   0.0023203608579933643,\n",
       "   0.002106891479343176,\n",
       "   0.0018989008385688066,\n",
       "   0.0017344281077384949,\n",
       "   0.001508646528236568,\n",
       "   0.0013834969140589237,\n",
       "   0.001223931205458939,\n",
       "   0.0011013030307367444,\n",
       "   0.000978065188974142,\n",
       "   0.0008814982720650733,\n",
       "   0.0007809890666976571],\n",
       "  'accuracy': [0.4802146255970001,\n",
       "   0.48893359303474426,\n",
       "   0.49966466426849365,\n",
       "   0.5606974959373474,\n",
       "   0.6277666091918945,\n",
       "   0.7015426158905029,\n",
       "   0.7451375126838684,\n",
       "   0.7625754475593567,\n",
       "   0.786720335483551,\n",
       "   0.7994634509086609,\n",
       "   0.8169013857841492,\n",
       "   0.8316566348075867,\n",
       "   0.8477531671524048,\n",
       "   0.8584842681884766,\n",
       "   0.8718980550765991,\n",
       "   0.8792756795883179,\n",
       "   0.8873239159584045,\n",
       "   0.8926894664764404,\n",
       "   0.9047619104385376,\n",
       "   0.9148222804069519,\n",
       "   0.9228705763816833,\n",
       "   0.9309188723564148,\n",
       "   0.9356136918067932,\n",
       "   0.9382964372634888,\n",
       "   0.9436619877815247,\n",
       "   0.9503688812255859,\n",
       "   0.9510395526885986,\n",
       "   0.953722357749939,\n",
       "   0.9624413251876831,\n",
       "   0.9664654731750488,\n",
       "   0.9657947421073914,\n",
       "   0.9711602926254272,\n",
       "   0.9738430380821228,\n",
       "   0.9778671860694885,\n",
       "   0.9792085886001587,\n",
       "   0.9825620651245117,\n",
       "   0.9845741391181946,\n",
       "   0.9845741391181946,\n",
       "   0.9872568845748901,\n",
       "   0.9872568845748901,\n",
       "   0.9912810325622559,\n",
       "   0.9912810325622559,\n",
       "   0.9919517040252686,\n",
       "   0.9919517040252686,\n",
       "   0.9926223754882812,\n",
       "   0.9926223754882812,\n",
       "   0.9939637780189514,\n",
       "   0.9932931065559387,\n",
       "   0.9939637780189514,\n",
       "   0.9939637780189514,\n",
       "   0.9946344494819641,\n",
       "   0.9946344494819641,\n",
       "   0.996646523475647,\n",
       "   0.9973172545433044,\n",
       "   0.9973172545433044,\n",
       "   0.9986585974693298,\n",
       "   0.9979879260063171,\n",
       "   0.9986585974693298,\n",
       "   1.0,\n",
       "   0.9993293285369873,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'val_loss': [1.4763765335083008,\n",
       "   1.413171410560608,\n",
       "   1.3056230545043945,\n",
       "   1.1996043920516968,\n",
       "   1.095712423324585,\n",
       "   0.9968782067298889,\n",
       "   0.9230102896690369,\n",
       "   0.8623771071434021,\n",
       "   0.7973231673240662,\n",
       "   0.7516511678695679,\n",
       "   0.7225112318992615,\n",
       "   0.6828696727752686,\n",
       "   0.6555414795875549,\n",
       "   0.6352733373641968,\n",
       "   0.6101850271224976,\n",
       "   0.5934609770774841,\n",
       "   0.579415500164032,\n",
       "   0.562722384929657,\n",
       "   0.5567101240158081,\n",
       "   0.5435934662818909,\n",
       "   0.528527021408081,\n",
       "   0.5249801278114319,\n",
       "   0.5105382204055786,\n",
       "   0.5040695667266846,\n",
       "   0.5002328157424927,\n",
       "   0.4988991618156433,\n",
       "   0.48390766978263855,\n",
       "   0.4815382659435272,\n",
       "   0.48478877544403076,\n",
       "   0.477146178483963,\n",
       "   0.4695683419704437,\n",
       "   0.47491469979286194,\n",
       "   0.4728672504425049,\n",
       "   0.4799053370952606,\n",
       "   0.47049909830093384,\n",
       "   0.47047972679138184,\n",
       "   0.46606212854385376,\n",
       "   0.47164440155029297,\n",
       "   0.46513035893440247,\n",
       "   0.4679329991340637,\n",
       "   0.4633122384548187,\n",
       "   0.4601622223854065,\n",
       "   0.46184203028678894,\n",
       "   0.46857064962387085,\n",
       "   0.47467681765556335,\n",
       "   0.4723539352416992,\n",
       "   0.47146230936050415,\n",
       "   0.47588256001472473,\n",
       "   0.4774813652038574,\n",
       "   0.4789661169052124,\n",
       "   0.48317956924438477,\n",
       "   0.4802132844924927,\n",
       "   0.4870070219039917,\n",
       "   0.4867657721042633,\n",
       "   0.48187607526779175,\n",
       "   0.4952949285507202,\n",
       "   0.5026378631591797,\n",
       "   0.4997401535511017,\n",
       "   0.5082157850265503,\n",
       "   0.5052810907363892,\n",
       "   0.5094373226165771,\n",
       "   0.5164989233016968,\n",
       "   0.5087887048721313,\n",
       "   0.5195873379707336,\n",
       "   0.5229746103286743,\n",
       "   0.5305680632591248,\n",
       "   0.5392432808876038,\n",
       "   0.5548343062400818,\n",
       "   0.5457379817962646,\n",
       "   0.5648112297058105,\n",
       "   0.558053731918335,\n",
       "   0.5676295161247253,\n",
       "   0.5813906788825989,\n",
       "   0.5750452876091003,\n",
       "   0.5803894996643066,\n",
       "   0.5924085974693298,\n",
       "   0.5947619080543518,\n",
       "   0.6016132831573486,\n",
       "   0.5969012379646301,\n",
       "   0.6194812655448914,\n",
       "   0.6282671689987183,\n",
       "   0.6233241558074951,\n",
       "   0.6368170380592346,\n",
       "   0.6521182060241699,\n",
       "   0.6270158886909485,\n",
       "   0.6549968123435974,\n",
       "   0.6470299363136292,\n",
       "   0.6648133993148804,\n",
       "   0.6808351874351501,\n",
       "   0.6857655644416809],\n",
       "  'val_accuracy': [0.4699999988079071,\n",
       "   0.4699999988079071,\n",
       "   0.5120000243186951,\n",
       "   0.5479999780654907,\n",
       "   0.6420000195503235,\n",
       "   0.7020000219345093,\n",
       "   0.722000002861023,\n",
       "   0.7319999933242798,\n",
       "   0.7459999918937683,\n",
       "   0.7620000243186951,\n",
       "   0.7580000162124634,\n",
       "   0.7739999890327454,\n",
       "   0.7879999876022339,\n",
       "   0.7960000038146973,\n",
       "   0.8040000200271606,\n",
       "   0.8080000281333923,\n",
       "   0.8100000023841858,\n",
       "   0.8259999752044678,\n",
       "   0.8180000185966492,\n",
       "   0.8259999752044678,\n",
       "   0.8259999752044678,\n",
       "   0.8259999752044678,\n",
       "   0.8299999833106995,\n",
       "   0.8339999914169312,\n",
       "   0.8299999833106995,\n",
       "   0.8360000252723694,\n",
       "   0.8379999995231628,\n",
       "   0.8339999914169312,\n",
       "   0.8379999995231628,\n",
       "   0.8399999737739563,\n",
       "   0.843999981880188,\n",
       "   0.8360000252723694,\n",
       "   0.8460000157356262,\n",
       "   0.8420000076293945,\n",
       "   0.8420000076293945,\n",
       "   0.8460000157356262,\n",
       "   0.8500000238418579,\n",
       "   0.8500000238418579,\n",
       "   0.8500000238418579,\n",
       "   0.8479999899864197,\n",
       "   0.8560000061988831,\n",
       "   0.8479999899864197,\n",
       "   0.8519999980926514,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8579999804496765,\n",
       "   0.8560000061988831,\n",
       "   0.8579999804496765,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8619999885559082,\n",
       "   0.8539999723434448,\n",
       "   0.8579999804496765,\n",
       "   0.8619999885559082,\n",
       "   0.8560000061988831,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8560000061988831,\n",
       "   0.8600000143051147,\n",
       "   0.8579999804496765,\n",
       "   0.8500000238418579,\n",
       "   0.8640000224113464,\n",
       "   0.8619999885559082,\n",
       "   0.8600000143051147,\n",
       "   0.8579999804496765,\n",
       "   0.8600000143051147,\n",
       "   0.8519999980926514,\n",
       "   0.8579999804496765,\n",
       "   0.8519999980926514,\n",
       "   0.8539999723434448,\n",
       "   0.8640000224113464,\n",
       "   0.8539999723434448,\n",
       "   0.8539999723434448,\n",
       "   0.8560000061988831,\n",
       "   0.8539999723434448,\n",
       "   0.8539999723434448,\n",
       "   0.8579999804496765,\n",
       "   0.8579999804496765,\n",
       "   0.8560000061988831,\n",
       "   0.8539999723434448,\n",
       "   0.8539999723434448,\n",
       "   0.8539999723434448,\n",
       "   0.8579999804496765,\n",
       "   0.8619999885559082,\n",
       "   0.8579999804496765,\n",
       "   0.8579999804496765,\n",
       "   0.8579999804496765,\n",
       "   0.8579999804496765,\n",
       "   0.8579999804496765]},\n",
       " 'epochs_90_batch_64': {'loss': [1.5688081979751587,\n",
       "   1.4537582397460938,\n",
       "   1.407118797302246,\n",
       "   1.3448597192764282,\n",
       "   1.2742785215377808,\n",
       "   1.1963785886764526,\n",
       "   1.118708848953247,\n",
       "   1.0448654890060425,\n",
       "   0.9737140536308289,\n",
       "   0.9079460501670837,\n",
       "   0.8505853414535522,\n",
       "   0.7936633229255676,\n",
       "   0.7473149299621582,\n",
       "   0.701988935470581,\n",
       "   0.6599516272544861,\n",
       "   0.6224083304405212,\n",
       "   0.5889248847961426,\n",
       "   0.5554840564727783,\n",
       "   0.5260518789291382,\n",
       "   0.49832683801651,\n",
       "   0.47326886653900146,\n",
       "   0.44765734672546387,\n",
       "   0.4244448244571686,\n",
       "   0.4034484326839447,\n",
       "   0.384553462266922,\n",
       "   0.36524292826652527,\n",
       "   0.3470187485218048,\n",
       "   0.32862308621406555,\n",
       "   0.31387993693351746,\n",
       "   0.2966991066932678,\n",
       "   0.2835647761821747,\n",
       "   0.2691958248615265,\n",
       "   0.2553149163722992,\n",
       "   0.24275921285152435,\n",
       "   0.22993740439414978,\n",
       "   0.219394713640213,\n",
       "   0.20834596455097198,\n",
       "   0.19600066542625427,\n",
       "   0.18743760883808136,\n",
       "   0.1769222915172577,\n",
       "   0.1676296442747116,\n",
       "   0.15806087851524353,\n",
       "   0.1508355289697647,\n",
       "   0.14198389649391174,\n",
       "   0.13447058200836182,\n",
       "   0.12720808386802673,\n",
       "   0.12034863978624344,\n",
       "   0.11276251077651978,\n",
       "   0.10659424960613251,\n",
       "   0.10055337101221085,\n",
       "   0.09479784965515137,\n",
       "   0.08987924456596375,\n",
       "   0.0842902883887291,\n",
       "   0.07970462739467621,\n",
       "   0.07485225051641464,\n",
       "   0.07014374434947968,\n",
       "   0.06622617691755295,\n",
       "   0.06150331720709801,\n",
       "   0.05858360230922699,\n",
       "   0.05437685549259186,\n",
       "   0.05113713815808296,\n",
       "   0.0482204407453537,\n",
       "   0.04472482204437256,\n",
       "   0.042408958077430725,\n",
       "   0.039181213825941086,\n",
       "   0.03656750172376633,\n",
       "   0.03426062688231468,\n",
       "   0.031841445714235306,\n",
       "   0.029966289177536964,\n",
       "   0.02752607688307762,\n",
       "   0.025900334119796753,\n",
       "   0.024099841713905334,\n",
       "   0.022063234820961952,\n",
       "   0.02075972780585289,\n",
       "   0.019328054040670395,\n",
       "   0.01772811822593212,\n",
       "   0.016348786652088165,\n",
       "   0.01545284315943718,\n",
       "   0.014085253700613976,\n",
       "   0.013239290565252304,\n",
       "   0.012065214104950428,\n",
       "   0.011261142790317535,\n",
       "   0.010189682245254517,\n",
       "   0.009588619694113731,\n",
       "   0.00872742012143135,\n",
       "   0.008112522773444653,\n",
       "   0.007536094170063734,\n",
       "   0.0068304454907774925,\n",
       "   0.0063603660091757774,\n",
       "   0.005848247092217207],\n",
       "  'accuracy': [0.45741114020347595,\n",
       "   0.48893359303474426,\n",
       "   0.48893359303474426,\n",
       "   0.49564051628112793,\n",
       "   0.5285043716430664,\n",
       "   0.5714285969734192,\n",
       "   0.5928906798362732,\n",
       "   0.6364855766296387,\n",
       "   0.6673373579978943,\n",
       "   0.7256874442100525,\n",
       "   0.7417840361595154,\n",
       "   0.7665995955467224,\n",
       "   0.7672702670097351,\n",
       "   0.7907444834709167,\n",
       "   0.8028169274330139,\n",
       "   0.8135479688644409,\n",
       "   0.8182427883148193,\n",
       "   0.8323273062705994,\n",
       "   0.8430583477020264,\n",
       "   0.852448046207428,\n",
       "   0.8651911616325378,\n",
       "   0.873910129070282,\n",
       "   0.8839704990386963,\n",
       "   0.8933601379394531,\n",
       "   0.9000670909881592,\n",
       "   0.9014084339141846,\n",
       "   0.9081153869628906,\n",
       "   0.9087860584259033,\n",
       "   0.9141515493392944,\n",
       "   0.9195170998573303,\n",
       "   0.9282360672950745,\n",
       "   0.9322602152824402,\n",
       "   0.9396378397941589,\n",
       "   0.9436619877815247,\n",
       "   0.9490274786949158,\n",
       "   0.9490274786949158,\n",
       "   0.9543930292129517,\n",
       "   0.9584171772003174,\n",
       "   0.9577465057373047,\n",
       "   0.9604292511940002,\n",
       "   0.964453399181366,\n",
       "   0.9678068161010742,\n",
       "   0.9651240706443787,\n",
       "   0.9698188900947571,\n",
       "   0.9731723666191101,\n",
       "   0.9765258431434631,\n",
       "   0.9792085886001587,\n",
       "   0.9798792600631714,\n",
       "   0.9825620651245117,\n",
       "   0.9825620651245117,\n",
       "   0.9832327365875244,\n",
       "   0.9845741391181946,\n",
       "   0.9852448105812073,\n",
       "   0.98591548204422,\n",
       "   0.9865862131118774,\n",
       "   0.9879275560379028,\n",
       "   0.9885982275009155,\n",
       "   0.9919517040252686,\n",
       "   0.9912810325622559,\n",
       "   0.9939637780189514,\n",
       "   0.9932931065559387,\n",
       "   0.9939637780189514,\n",
       "   0.9959758520126343,\n",
       "   0.996646523475647,\n",
       "   0.996646523475647,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9986585974693298,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   0.9993293285369873,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0],\n",
       "  'val_loss': [1.4926353693008423,\n",
       "   1.4516524076461792,\n",
       "   1.4094635248184204,\n",
       "   1.3536187410354614,\n",
       "   1.285827875137329,\n",
       "   1.2315984964370728,\n",
       "   1.1542896032333374,\n",
       "   1.0846315622329712,\n",
       "   1.023959755897522,\n",
       "   0.9831458330154419,\n",
       "   0.9264799952507019,\n",
       "   0.8994707465171814,\n",
       "   0.8498008847236633,\n",
       "   0.8091294169425964,\n",
       "   0.7801392078399658,\n",
       "   0.7422127723693848,\n",
       "   0.7196356654167175,\n",
       "   0.6967958807945251,\n",
       "   0.6823127269744873,\n",
       "   0.6634550094604492,\n",
       "   0.6448860764503479,\n",
       "   0.628239631652832,\n",
       "   0.6071380376815796,\n",
       "   0.6050005555152893,\n",
       "   0.583975613117218,\n",
       "   0.5713943839073181,\n",
       "   0.5668942928314209,\n",
       "   0.5612086057662964,\n",
       "   0.5466527938842773,\n",
       "   0.5368742942810059,\n",
       "   0.5333090424537659,\n",
       "   0.5281950831413269,\n",
       "   0.5199134349822998,\n",
       "   0.5155608057975769,\n",
       "   0.5104498267173767,\n",
       "   0.501613974571228,\n",
       "   0.496399462223053,\n",
       "   0.5047109723091125,\n",
       "   0.490669310092926,\n",
       "   0.49049830436706543,\n",
       "   0.47947821021080017,\n",
       "   0.4819616675376892,\n",
       "   0.4737550616264343,\n",
       "   0.4805941581726074,\n",
       "   0.46929094195365906,\n",
       "   0.4640488028526306,\n",
       "   0.46678006649017334,\n",
       "   0.46367156505584717,\n",
       "   0.46485260128974915,\n",
       "   0.45803284645080566,\n",
       "   0.4567607641220093,\n",
       "   0.45631757378578186,\n",
       "   0.4579290747642517,\n",
       "   0.4650825262069702,\n",
       "   0.4649839699268341,\n",
       "   0.45829179883003235,\n",
       "   0.46245095133781433,\n",
       "   0.47372522950172424,\n",
       "   0.46646007895469666,\n",
       "   0.46195846796035767,\n",
       "   0.46347400546073914,\n",
       "   0.4656311869621277,\n",
       "   0.4745350480079651,\n",
       "   0.46791163086891174,\n",
       "   0.47065746784210205,\n",
       "   0.46130818128585815,\n",
       "   0.4746715724468231,\n",
       "   0.47226402163505554,\n",
       "   0.4765882194042206,\n",
       "   0.4871489703655243,\n",
       "   0.4835231304168701,\n",
       "   0.48136991262435913,\n",
       "   0.48593151569366455,\n",
       "   0.48803600668907166,\n",
       "   0.49045494198799133,\n",
       "   0.4900954067707062,\n",
       "   0.5002880096435547,\n",
       "   0.4935981333255768,\n",
       "   0.5101898312568665,\n",
       "   0.49794092774391174,\n",
       "   0.5272470712661743,\n",
       "   0.5114192962646484,\n",
       "   0.5298232436180115,\n",
       "   0.5262336134910583,\n",
       "   0.5320459008216858,\n",
       "   0.5280224084854126,\n",
       "   0.5424282550811768,\n",
       "   0.5383555293083191,\n",
       "   0.538857638835907,\n",
       "   0.5543444156646729],\n",
       "  'val_accuracy': [0.4699999988079071,\n",
       "   0.4699999988079071,\n",
       "   0.4699999988079071,\n",
       "   0.47200000286102295,\n",
       "   0.5379999876022339,\n",
       "   0.5400000214576721,\n",
       "   0.5820000171661377,\n",
       "   0.6079999804496765,\n",
       "   0.671999990940094,\n",
       "   0.6499999761581421,\n",
       "   0.7020000219345093,\n",
       "   0.7080000042915344,\n",
       "   0.7319999933242798,\n",
       "   0.7480000257492065,\n",
       "   0.7519999742507935,\n",
       "   0.7739999890327454,\n",
       "   0.7900000214576721,\n",
       "   0.7900000214576721,\n",
       "   0.7820000052452087,\n",
       "   0.7900000214576721,\n",
       "   0.7919999957084656,\n",
       "   0.8019999861717224,\n",
       "   0.8059999942779541,\n",
       "   0.8080000281333923,\n",
       "   0.8080000281333923,\n",
       "   0.8180000185966492,\n",
       "   0.8180000185966492,\n",
       "   0.8100000023841858,\n",
       "   0.8199999928474426,\n",
       "   0.8220000267028809,\n",
       "   0.828000009059906,\n",
       "   0.8220000267028809,\n",
       "   0.8240000009536743,\n",
       "   0.828000009059906,\n",
       "   0.8299999833106995,\n",
       "   0.8320000171661377,\n",
       "   0.8379999995231628,\n",
       "   0.8339999914169312,\n",
       "   0.8339999914169312,\n",
       "   0.8399999737739563,\n",
       "   0.8360000252723694,\n",
       "   0.8379999995231628,\n",
       "   0.8399999737739563,\n",
       "   0.8420000076293945,\n",
       "   0.8360000252723694,\n",
       "   0.8560000061988831,\n",
       "   0.8399999737739563,\n",
       "   0.843999981880188,\n",
       "   0.843999981880188,\n",
       "   0.8500000238418579,\n",
       "   0.8519999980926514,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8560000061988831,\n",
       "   0.8600000143051147,\n",
       "   0.8560000061988831,\n",
       "   0.8579999804496765,\n",
       "   0.8579999804496765,\n",
       "   0.8600000143051147,\n",
       "   0.8640000224113464,\n",
       "   0.8640000224113464,\n",
       "   0.8619999885559082,\n",
       "   0.8560000061988831,\n",
       "   0.8619999885559082,\n",
       "   0.8659999966621399,\n",
       "   0.8600000143051147,\n",
       "   0.8619999885559082,\n",
       "   0.8700000047683716,\n",
       "   0.8679999709129333,\n",
       "   0.8640000224113464,\n",
       "   0.8659999966621399,\n",
       "   0.8679999709129333,\n",
       "   0.8659999966621399,\n",
       "   0.8640000224113464,\n",
       "   0.8659999966621399,\n",
       "   0.8640000224113464,\n",
       "   0.8679999709129333,\n",
       "   0.8659999966621399,\n",
       "   0.8640000224113464,\n",
       "   0.8659999966621399,\n",
       "   0.8640000224113464,\n",
       "   0.8619999885559082,\n",
       "   0.8640000224113464,\n",
       "   0.8640000224113464,\n",
       "   0.8640000224113464,\n",
       "   0.8619999885559082,\n",
       "   0.8640000224113464,\n",
       "   0.8600000143051147,\n",
       "   0.8600000143051147,\n",
       "   0.8619999885559082]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cee368-916f-44d6-8a6e-984d1842f3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3_7",
   "language": "python",
   "name": "python_3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
